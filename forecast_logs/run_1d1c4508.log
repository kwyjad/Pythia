üìä Forecast Run 1d1c4508
Timestamp: 2025-08-29T09:11:14.142615Z
============================================================

‚ùì Question: Will humans go extinct before 2100?
üîó URL: https://www.metaculus.com/questions/578

üìù Full Reasoning:
# SUMMARY
*Question*: Will humans go extinct before 2100?
*Final Prediction*: 2.2%
*Total Cost*: $0.0357
*Time Spent*: 0.64 minutes


## Report 1 Summary
### Forecasts
*Forecaster 1*: 3.0%
*Forecaster 2*: 2.2%
*Forecaster 3*: 1.0%
*Forecaster 4*: 2.2%
*Forecaster 5*: 2.2%


### Research Summary
The research presents a comprehensive analysis of expert estimates and prediction markets regarding the likelihood of human extinction by the year 2100. The median expert estimate for extinction is around **6%**, with similar probabilities suggested by superforecasters. While there is a **20%** chance of a catastrophic event causing significant population loss within five years, this does not equate to extinction. Prediction markets, such as Metaculus and Manifold Markets, indicate even lower probabilities of extinction, at **1-2%** and **4%**, respectively.

The study contrasts status quo forces, such as existing technological advancements and global cooperation, with change drivers like nuclear war, engineered pandemics, climate change, and rogue AI. These risks are acknowledged but are not viewed as imminent threats to human extinction. The research emphasizes that ongoing monitoring and discussions around AI risks suggest that potential extinction timelines are likely to extend beyond 2100. Additionally, it highlights that practical verification of absolute extinction is nearly impossible, yet forecasters are expected to predict in good faith. Overall, there is no current evidence indicating imminent extinction, and historical resilience against crises supports the belief in human survival.

Sources:
- Forecasting Research Institute study on expert and superforecaster estimates: **2023-01-15**
- Metaculus community estimates updated: **2023-10-01**
- Manifold Markets community estimates updated: **2023-10-01**
- Ongoing discussions on AI risks and extinction timelines noted in expert circles: **2023-09-20**


# RESEARCH
## Report 1 Research
### 1) Base Rates & Reference Class
- Median expert estimate of human extinction by 2100: **6%**.
- Superforecasters provide similar or slightly lower probabilities.
- **20%** chance of a catastrophic event causing significant population loss within five years, but not extinction.
- Prediction markets (Metaculus: **1-2%**, Manifold Markets: **4%**) indicate low extinction probabilities.

### 2) Status Quo Forces vs Change Drivers
- **Status Quo Forces**: Current civilization structures, technological advancements, and global cooperation efforts mitigate existential risks.
- **Change Drivers**: Risks from nuclear war, engineered pandemics, climate change, and rogue AI are acknowledged but not seen as imminent extinction threats.
- Ongoing research and monitoring of AI risks suggest timelines for potential extinction events extend beyond 2100.

### 3) Most Recent Credible Updates WITH DATES (YYYY-MM-DD)
- Forecasting Research Institute study on expert and superforecaster estimates: **2023-01-15**.
- Metaculus community estimates updated: **2023-10-01**.
- Manifold Markets community estimates updated: **2023-10-01**.
- Ongoing discussions on AI risks and extinction timelines noted in expert circles: **2023-09-20**.

### 4) Resolution Criteria Traps & Fine-Print Gotchas
- The question resolves **Yes** only if **no known biological humans** are alive anywhere in the observable universe by January 1, 2100.
- Any evidence of a single living human would resolve the question **No**.
- Practical verification of absolute extinction is acknowledged as nearly impossible, yet forecasters are expected to predict in good faith.

### 5) Disconfirming Evidence (Steelman)
- No current evidence suggests imminent human extinction; all major existential risks are considered manageable or unlikely to lead to total extinction by 2100.
- Historical resilience of humanity in the face of crises (e.g., pandemics, wars) supports the view that extinction is unlikely.
- Expert consensus and prediction markets consistently show low probabilities for extinction, reinforcing the belief in human survival.

# FORECASTS

## R1: Forecaster 1 Reasoning
<base_rate>0.06</base_rate>  
<likelihoods>  
The base rate for human extinction by 2100 is 6%, based on median expert estimates. Key evidence includes:  
- Prediction markets and superforecasters estimate lower probabilities (1-4%), suggesting a downward adjustment.  
- Status quo forces such as technological advancements and global cooperation reduce existential risks.  
- Change drivers like nuclear war, pandemics, and AI are acknowledged but not seen as imminent extinction threats.  
Overall, the likelihood ratio (LR) is less than 1 due to the weight of evidence suggesting lower risk than the base rate.  
</likelihoods>  
<bayes_likelihood_ratio>0.5</bayes_likelihood_ratio>  
<bayes_posterior>0.03</bayes_posterior>  

<stress_yes>  
Consider a scenario where rogue AI development accelerates unexpectedly, leading to a significant existential threat. This could increase the probability of extinction, but current monitoring and research suggest such timelines are beyond 2100.  
</stress_yes>  

<stress_no>  
Imagine a scenario where global cooperation strengthens significantly, leading to robust international frameworks for mitigating existential risks. This would further decrease the probability of human extinction by 2100.  
</stress_no>  

Probability: 3%


## R1: Forecaster 2 Reasoning
```xml
<base_rate>0.02</base_rate>
<likelihoods>
The base rate for human extinction by 2100 from prediction markets is low, around 1-2%. Expert estimates suggest a slightly higher probability of 6%, but these may be biased due to selection effects. Status quo forces such as technological advancements and global cooperation mitigate existential risks, while change drivers like nuclear war, pandemics, and AI are acknowledged but not seen as imminent threats. The likelihood ratio (LR) is slightly above 1, given that while existential risks exist, they are not currently seen as immediate extinction threats.
</likelihoods>
<bayes_likelihood_ratio>1.1</bayes_likelihood_ratio>
<bayes_posterior>0.022</bayes_posterior>
<stress_yes>
Consider a scenario where a new, highly aggressive AI technology is developed without proper safeguards, leading to uncontrolled outcomes. This could increase the probability of extinction, but current monitoring and regulatory efforts aim to prevent such scenarios.
</stress_yes>
<stress_no>
Imagine a future where significant advancements in global cooperation and technology effectively mitigate all major existential risks, such as through successful climate change interventions and nuclear disarmament. This would further decrease the probability of extinction by 2100.
</stress_no>
```

Probability: 2.2%


## R1: Forecaster 3 Reasoning
```xml
<base_rate>0.01</base_rate>
<likelihoods>
The base rate of 1% is informed by prediction markets and expert consensus, which suggest a low probability of human extinction by 2100. Key evidence includes the resilience of human civilization, ongoing global efforts to mitigate existential risks, and the lack of imminent threats that could lead to total extinction. The informal poll at the Global Catastrophic Risk Conference, which suggested a 19% probability, is considered an outlier due to selection bias. Therefore, the likelihood ratio remains close to 1, as no new evidence significantly shifts the odds.
</likelihoods>
<bayes_likelihood_ratio>1</bayes_likelihood_ratio>
<bayes_posterior>0.01</bayes_posterior>
<stress_yes>
Consider a scenario where a rogue AI or engineered pandemic rapidly escalates beyond control, leading to global collapse. While this is a conceivable risk, current evidence and expert analysis suggest such events are unlikely to result in complete extinction by 2100.
</stress_yes>
<stress_no>
Imagine a future where global cooperation and technological advancements continue to improve, effectively mitigating existential risks such as nuclear war and climate change. Historical resilience and ongoing efforts support the likelihood of human survival.
</stress_no>
```

Probability: 1%


## R1: Forecaster 4 Reasoning
```xml
<base_rate>0.02</base_rate>
<likelihoods>
The base rate is informed by prediction markets like Metaculus and Manifold Markets, which estimate a 1-4% chance of human extinction by 2100. Key evidence includes expert consensus and ongoing technological and societal advancements that mitigate existential risks. While there are acknowledged risks from nuclear war, pandemics, climate change, and AI, these are not seen as imminent extinction threats. Therefore, the likelihood ratio is slightly above 1, reflecting a small increase in probability due to these risks.
</likelihoods>
<bayes_likelihood_ratio>1.1</bayes_likelihood_ratio>
<bayes_posterior>0.022</bayes_posterior>
<stress_yes>
Consider a scenario where a major global conflict escalates into nuclear war, leading to widespread devastation. This could increase the probability of extinction, but historical resilience suggests survival is still likely.
</stress_yes>
<stress_no>
Imagine a future where global cooperation and technological advancements significantly reduce existential risks, such as through effective climate change mitigation and AI regulation. This would decrease the probability of extinction.
</stress_no>
```

Probability: 2.2%


## R1: Forecaster 5 Reasoning
```xml
<base_rate>0.02</base_rate>
<likelihoods>
The base rate of 2% is informed by prediction markets and expert consensus, which suggest a low probability of human extinction by 2100. Key evidence includes the resilience of human civilization, technological advancements, and global cooperation, which mitigate existential risks. Although there are potential threats like nuclear war, engineered pandemics, and AI, these are not seen as imminent extinction threats. The likelihood ratio is slightly above 1 due to the low probability of extinction events occurring within this timeframe.
</likelihoods>
<bayes_likelihood_ratio>1.1</bayes_likelihood_ratio>
<bayes_posterior>0.022</bayes_posterior>
<stress_yes>
Consider a scenario where a rogue AI develops capabilities to eliminate humanity, and international efforts to control it fail. This would increase the probability of extinction, but current assessments suggest such scenarios are unlikely to occur before 2100.
</stress_yes>
<stress_no>
Imagine a world where international cooperation strengthens, leading to effective mitigation of existential risks and technological advancements that further secure human survival. This would reinforce the low probability of extinction.
</stress_no>
```

Probability: 2.2%

------------------------------------------------------------

‚ùì Question: How old will the oldest living person be in 2100?
üîó URL: https://www.metaculus.com/questions/14333

üìù Full Reasoning:
# SUMMARY
*Question*: How old will the oldest living person be in 2100?
*Final Prediction*: Probability distribution:
- 0.00% chance of value below 0.0
- 0.43% chance of value below 50.0
- 0.87% chance of value below 100.0
- 91.50% chance of value below 150.0
- 99.00% chance of value below 200.0

*Total Cost*: $0.0324
*Time Spent*: 1.05 minutes


## Report 1 Summary
### Forecasts
*Forecaster 1*: Probability distribution:
- 1.00% chance of value below 115.0
- 10.00% chance of value below 120.0
- 25.00% chance of value below 125.0
- 50.00% chance of value below 130.0
- 75.00% chance of value below 135.0
- 90.00% chance of value below 140.0
- 99.00% chance of value below 150.0

*Forecaster 2*: Probability distribution:
- 1.00% chance of value below 115.0
- 10.00% chance of value below 120.0
- 25.00% chance of value below 123.0
- 50.00% chance of value below 125.0
- 75.00% chance of value below 130.0
- 90.00% chance of value below 135.0
- 99.00% chance of value below 140.0

*Forecaster 3*: Probability distribution:
- 1.00% chance of value below 115.0
- 10.00% chance of value below 120.0
- 25.00% chance of value below 125.0
- 50.00% chance of value below 130.0
- 75.00% chance of value below 135.0
- 90.00% chance of value below 140.0
- 99.00% chance of value below 150.0

*Forecaster 4*: Probability distribution:
- 1.00% chance of value below 115.0
- 10.00% chance of value below 120.0
- 25.00% chance of value below 122.0
- 50.00% chance of value below 125.0
- 75.00% chance of value below 130.0
- 90.00% chance of value below 135.0
- 99.00% chance of value below 145.0

*Forecaster 5*: Probability distribution:
- 1.00% chance of value below 115.0
- 10.00% chance of value below 120.0
- 25.00% chance of value below 125.0
- 50.00% chance of value below 130.0
- 75.00% chance of value below 135.0
- 90.00% chance of value below 140.0
- 99.00% chance of value below 150.0



### Research Summary
The research examines the potential age of the oldest living person in 2100 by analyzing historical data on human lifespan and current trends in aging. It notes that the oldest verified age ever recorded is 122 years, held by Jeanne Calment, and that this record has remained unbroken since her death in 1997. Despite advances in healthcare and biotechnology, the research indicates that lifespan trends have plateaued, with no verified cases of individuals living beyond 122 years. It highlights the distinction between status quo forces, which emphasize biological limits and historical records, and change drivers, which suggest that future medical advancements could potentially enhance lifespan, albeit with a 96% probability of progress being speculative.

The research also addresses the complexities and uncertainties surrounding predictions of lifespan enhancement, noting that while there is optimism about breakthroughs in aging research, many proposed treatments have not yet materialized. It emphasizes the lack of consensus on future outcomes and the possibility that advancements in medicine may not lead to an increase in maximum lifespan. The findings suggest that while there is hope for longevity breakthroughs, historical data and biological constraints present significant challenges to surpassing the current maximum age record.

Sources:
- Metaculus (2023) 
- Jeanne Calment (1997-08-04) 
- Ethel Caterham (2025-04-30)


# RESEARCH
## Report 1 Research
### 1) Base Rates & Reference Class
- Current oldest living person: Ethel Caterham, age 115 (as of 2025).
- Oldest verified age ever: Jeanne Calment, 122 years (1875-1997).
- Historical maximum lifespan has not been surpassed since 1997.
- No verified cases of humans living beyond 122 years.
- Lifespan trends show a plateau despite advances in healthcare.

### 2) Status Quo Forces vs Change Drivers
- **Status Quo Forces:**
- Historical record of maximum age (122 years) remains unbroken.
- Aging process and biological limits are well understood.
- **Change Drivers:**
- Advances in biotechnology and medicine may enhance lifespan.
- Speculation about longevity breakthroughs by 2100 (96% probability of progress).

### 3) Most Recent Credible Updates WITH DATES (YYYY-MM-DD)
- Ethel Caterham recognized as oldest living person: **2025-04-30** (age 115).
- Jeanne Calment's record remains unchallenged since **1997-08-04** (date of death).
- Forecast discussions on lifespan enhancement by **2023** (Metaculus).

### 4) Resolution Criteria Traps & Fine-Print Gotchas
- Current records are based on verified ages; unverified claims exist but are not included.
- Future predictions are speculative and lack consensus on specific outcomes.
- Advances in medicine may not translate to increased maximum lifespan.
- Aging research is complex, and breakthroughs may take longer than anticipated.

### 5) Disconfirming Evidence (Steelman)
- Historical data shows no trend of increasing maximum lifespan despite medical advancements.
- Jeanne Calment's record has stood for over two decades, indicating biological limits.
- Aging research often faces setbacks, and many proposed longevity treatments have not materialized.
- Skepticism exists regarding the feasibility of significantly extending human lifespan beyond current records.

# FORECASTS

## R1: Forecaster 1 Reasoning
To forecast the age of the oldest living person in 2100, we need to consider both historical data and potential future developments. The historical maximum lifespan has not exceeded 122 years, and despite advances in healthcare, there is no clear trend indicating a significant increase in the maximum lifespan. However, potential breakthroughs in biotechnology and medicine could alter this trajectory.

### Percentile Forecast
- **1st percentile**: 115 years
- **10th percentile**: 120 years
- **25th percentile**: 125 years
- **50th percentile**: 130 years
- **75th percentile**: 135 years
- **90th percentile**: 140 years
- **99th percentile**: 150 years

### Bayesian Block
- **Base Rate**: Current maximum verified age is 122 years.
- **Likelihoods**:
- **Status Quo**: High likelihood that the maximum lifespan remains around 122 years due to historical stability.
- **Change Drivers**: Moderate likelihood of breakthroughs extending lifespan, but uncertainty remains about the extent.
- **Parametric Proposal**:
```xml
<family>lognormal</family>
<params>mu=4.8, sigma=0.15</params>
```

This forecast reflects a cautious approach, acknowledging both the historical plateau in maximum lifespan and the potential for future advancements. The lognormal distribution is chosen to model the skewed nature of potential lifespan extensions, with a long tail representing the possibility of significant breakthroughs.


## R1: Forecaster 2 Reasoning
To forecast the age of the oldest living person in 2100, we need to consider both historical data and potential future advancements. The current maximum verified lifespan is 122 years, and there has been no verified increase in this maximum since Jeanne Calment's death in 1997. While advances in biotechnology and medicine could potentially extend human lifespan, historical trends suggest a plateau in maximum age.

### Numeric Forecast Percentiles
- **1st percentile:** 115 years
- **10th percentile:** 120 years
- **25th percentile:** 123 years
- **50th percentile:** 125 years
- **75th percentile:** 130 years
- **90th percentile:** 135 years
- **99th percentile:** 140 years

### Bayesian Block
- **Base Rate:** The historical maximum verified lifespan is 122 years.
- **Likelihoods:** 
- Likelihood of breaking the current record due to medical advancements: moderate, given the current plateau but potential for breakthroughs.
- Likelihood of significant breakthroughs by 2100: high, but uncertain impact on maximum lifespan.
- **Parametric Proposal:**
```xml
<family>lognormal</family>
<params>mu=4.8, sigma=0.1</params>
```

This forecast assumes a modest increase in the maximum age, reflecting both the historical plateau and the potential for future medical advancements. The lognormal distribution is chosen to model the skewness towards higher ages due to potential breakthroughs while acknowledging the current biological limits.


## R1: Forecaster 3 Reasoning
To forecast the age of the oldest living person in 2100, we need to consider both historical data and potential future developments. The historical data suggests a plateau in maximum lifespan, with Jeanne Calment's record of 122 years still standing. However, potential advances in medicine and biotechnology could lead to breakthroughs in longevity.

### Numeric Forecast Percentiles
Given the current data and potential for future advancements, here are the percentiles for the age of the oldest living person in 2100:

- 1st percentile: 115 years
- 10th percentile: 120 years
- 25th percentile: 125 years
- 50th percentile: 130 years
- 75th percentile: 135 years
- 90th percentile: 140 years
- 99th percentile: 150 years

### Bayesian Block
- **Base Rate**: The current maximum verified age is 122 years.
- **Likelihoods**:
- **Status Quo**: Historical data suggests a plateau at around 122 years.
- **Change Drivers**: Advances in biotechnology and medicine could potentially extend lifespan, though this is speculative.
- **Parametric Proposal**:
- <family>Lognormal</family>
- <params>meanlog = 4.8, sdlog = 0.1</params>

This forecast reflects a cautious optimism about future advancements in longevity, while acknowledging the historical stability of the maximum lifespan. The percentiles are skewed towards the higher end to account for potential breakthroughs, but remain conservative given the lack of current evidence for surpassing the 122-year record.


## R1: Forecaster 4 Reasoning
To forecast the age of the oldest living person in 2100, we need to consider both historical data and potential future developments. The historical maximum verified age is 122 years, and this has not been surpassed since Jeanne Calment's death in 1997. Despite advances in medicine, there is no clear trend indicating an increase in the maximum lifespan. However, there is speculation about potential breakthroughs in biotechnology and medicine by 2100.

### Numeric Forecast Percentiles
1st percentile: 115 years
10th percentile: 120 years
25th percentile: 122 years
50th percentile: 125 years
75th percentile: 130 years
90th percentile: 135 years
99th percentile: 145 years

### Bayesian Block
- **Base Rate**: The historical maximum age is 122 years.
- **Likelihoods**:
- Incremental advances in medicine and biotechnology suggest a modest increase in maximum lifespan.
- Historical data shows a plateau, indicating biological limits.
- **Parametric Proposal**:
```xml
<family>lognormal</family>
<params>mu=4.8, sigma=0.1</params>
```

This forecast assumes that while there may be some progress in extending the maximum lifespan, significant breakthroughs that drastically increase the maximum age are uncertain and speculative. The lognormal distribution is chosen to model the potential for right-skewed outcomes, where a few individuals might live significantly longer than the current maximum, but most will not exceed it by a large margin.


## R1: Forecaster 5 Reasoning
To forecast the age of the oldest living person in 2100, we must consider both the historical data and potential future developments in medicine and biotechnology. Given the current state of knowledge and trends, here is the forecast:

### Numeric Forecast Percentiles
- 1st percentile: 115 years
- 10th percentile: 120 years
- 25th percentile: 125 years
- 50th percentile: 130 years
- 75th percentile: 135 years
- 90th percentile: 140 years
- 99th percentile: 150 years

### Bayesian Block
- **Base Rate**: The current maximum verified age is 122 years, with no increases since 1997. This suggests a base rate centered around this historical maximum.
- **Likelihoods**:
- **Status Quo Forces**: The biological and historical data suggest a plateau in maximum lifespan, indicating a high likelihood that the maximum age will not significantly exceed 122 years without breakthroughs.
- **Change Drivers**: Advances in biotechnology and medicine could potentially increase maximum lifespan, but the extent and timing are uncertain.
- **Parametric Proposal**:
```xml
<family>lognormal</family>
<params>mu=4.85, sigma=0.1</params>
```
- The lognormal distribution is chosen to reflect the skewness towards higher ages due to potential breakthroughs, while still being anchored by historical data.

This forecast reflects a cautious optimism about future advancements, balanced by the historical evidence of biological limits. The percentiles suggest a gradual increase in the maximum age, with the median forecast indicating a modest increase over the current record.

------------------------------------------------------------

‚ùì Question: Before 2030, how many new AI labs will be leading labs within 2 years of their founding?
üîó URL: https://www.metaculus.com/questions/22427

üìù Full Reasoning:
# SUMMARY
*Question*: Before 2030, how many new AI labs will be leading labs within 2 years of their founding?
*Final Prediction*: 
- 0 or 1: 60.0%
- 2 or 3: 25.0%
- 4 or 5: 10.0%
- 6 or 7: 3.0%
- 8 or 9: 1.0%
- 10 or more: 1.0%

*Total Cost*: $0.0652
*Time Spent*: 1.46 minutes


## Report 1 Summary
### Forecasts
*Forecaster 1*: 
- 0 or 1: 60.0%
- 2 or 3: 25.0%
- 4 or 5: 10.0%
- 6 or 7: 3.0%
- 8 or 9: 1.0%
- 10 or more: 1.0%

*Forecaster 2*: 
- 0 or 1: 60.0%
- 2 or 3: 25.0%
- 4 or 5: 10.0%
- 6 or 7: 3.0%
- 8 or 9: 1.0%
- 10 or more: 1.0%

*Forecaster 3*: 
- 0 or 1: 60.0%
- 2 or 3: 25.0%
- 4 or 5: 10.0%
- 6 or 7: 3.0%
- 8 or 9: 1.0%
- 10 or more: 1.0%

*Forecaster 4*: 
- 0 or 1: 60.0%
- 2 or 3: 25.0%
- 4 or 5: 10.0%
- 6 or 7: 3.0%
- 8 or 9: 1.0%
- 10 or more: 1.0%

*Forecaster 5*: 
- 0 or 1: 60.0%
- 2 or 3: 25.0%
- 4 or 5: 10.0%
- 6 or 7: 3.0%
- 8 or 9: 1.0%
- 10 or more: 1.0%



### Research Summary
The research examines the historical challenges faced by new AI labs in becoming leading contenders within two years of their founding. It highlights that established labs such as OpenAI, Anthropic, Google DeepMind, Cohere, and Mistral AI dominate the current landscape, creating significant barriers for newcomers. Predictions indicate a stable number of leading labs, with an estimated 5.39 frontier labs expected by the end of 2025. Despite ongoing speculation about potential disruptors like DeepSeek and Thinking Machines, no new entrants have successfully displaced incumbents within the two-year timeframe.

The analysis also contrasts status quo forces, which include the substantial resources and market presence of established labs, with change drivers such as technological advancements that could enable new labs to disrupt the market. Recent updates indicate that as of August 2025, no new AI labs founded after April 2024 have entered the top five rankings on Chatbot Arena within two years. The research acknowledges that while the current consensus suggests a struggle for new labs to achieve top-tier status quickly, historical examples exist where startups have rapidly gained prominence, indicating that future developments could still alter the current assessment.

Sources used: 
- [manifold.markets](https://manifold.markets/Bayesian/which-company-has-best-ai-model-end-IZEIlPL8ZZ)


# RESEARCH
## Report 1 Research
### 1) Base Rates & Reference Class
- Historically, new AI labs face significant challenges in becoming top-tier contenders within 2 years of founding.
- Current predictions suggest a stable number of leading labs, with an estimate of about 5.39 frontier labs by the end of 2025.
- Established players (OpenAI, Anthropic, Google DeepMind, Cohere, Mistral AI) dominate the leaderboard, indicating high barriers to entry.

### 2) Status Quo Forces vs Change Drivers
- **Status Quo Forces:** 
- Established labs have significant resources, talent, and market presence, making it difficult for new entrants to compete.
- The current leaderboard is stable, with no new entrants displacing incumbents within 2 years.
- **Change Drivers:**
- Technological advancements and innovative approaches could potentially allow new labs to disrupt the market.
- Speculation exists around new entrants (e.g., DeepSeek, Thinking Machines) that could challenge the status quo, but none have yet succeeded.

### 3) Most Recent Credible Updates WITH DATES (YYYY-MM-DD)
- **2024-04-01:** Current top 5 AI labs by Chatbot Arena ELO are OpenAI, Anthropic, Google DeepMind, Cohere, and Mistral AI.
- **2025-08-01:** No new AI labs founded after April 2024 have entered the top 5 on Chatbot Arena within 2 years of their founding.
- **2025-08-01:** Ongoing speculation about new entrants, but established players continue to dominate the leaderboard ([manifold.markets](https://manifold.markets/Bayesian/which-company-has-best-ai-model-end-IZEIlPL8ZZ)).

### 4) Resolution Criteria Traps & Fine-Print Gotchas
- The question remains open until 2030, meaning future developments could alter the current assessment.
- If Chatbot Arena becomes unavailable, alternative sources will be used for resolution, which may introduce variability in outcomes.
- The definition of "top 5" is based on ELO ratings, which can fluctuate based on model performance and competition.

### 5) Disconfirming Evidence (Steelman)
- While the consensus is that new labs struggle to enter the top tier quickly, there are examples in tech history where startups have rapidly ascended to prominence (e.g., OpenAI's rapid rise).
- The potential for breakthrough innovations or unique approaches in AI could allow new labs to achieve top rankings faster than expected.
- Increased investment and interest in AI could lead to the emergence of new players that challenge existing leaders more effectively than past entrants.

# FORECASTS

## R1: Forecaster 1 Reasoning
To forecast the number of new AI labs that will become leading labs within 2 years of their founding before 2030, we need to consider both historical data and potential future developments.

### Base Rates & Reference Class
Historically, new AI labs face significant challenges in becoming top-tier contenders within 2 years of founding. The current landscape is dominated by established players, and predictions suggest a stable number of leading labs, with about 5.39 frontier labs by the end of 2025. This indicates high barriers to entry for new labs.

### Status Quo Forces vs Change Drivers
**Status Quo Forces:** Established labs have significant resources, talent, and market presence, making it difficult for new entrants to compete. The current leaderboard is stable, with no new entrants displacing incumbents within 2 years.

**Change Drivers:** Technological advancements and innovative approaches could potentially allow new labs to disrupt the market. Speculation exists around new entrants (e.g., DeepSeek, Thinking Machines) that could challenge the status quo, but none have yet succeeded.

### Most Recent Credible Updates
As of 2025-08-01, no new AI labs founded after April 2024 have entered the top 5 on Chatbot Arena within 2 years of their founding. Ongoing speculation about new entrants exists, but established players continue to dominate the leaderboard.

### Disconfirming Evidence
While the consensus is that new labs struggle to enter the top tier quickly, there are examples in tech history where startups have rapidly ascended to prominence. The potential for breakthrough innovations or unique approaches in AI could allow new labs to achieve top rankings faster than expected.

### Bayesian Analysis
Given the historical data and current trends, the base rate for new labs becoming leading labs within 2 years is low. However, considering the potential for technological breakthroughs and increased investment in AI, there is a non-zero probability for new labs to emerge as leaders.

1. **'0 or 1'**: High probability due to historical trends and current stability among top labs. Base rate suggests this is the most likely outcome.
2. **'2 or 3'**: Moderate probability, accounting for potential technological breakthroughs and increased investment in AI.
3. **'4 or 5'**: Lower probability, as significant disruption would be required for this many new labs to become leaders.
4. **'6 or 7'**: Very low probability, as it would require a major shift in the AI landscape.
5. **'8 or 9'**: Extremely low probability, unlikely given current trends.
6. **'10 or more'**: Negligible probability, as this would require a complete overhaul of the current AI ecosystem.

### Ranked List with Probabilities
1. **'0 or 1'**: 60%
2. **'2 or 3'**: 25%
3. **'4 or 5'**: 10%
4. **'6 or 7'**: 3%
5. **'8 or 9'**: 1%
6. **'10 or more'**: 1%

### Machine-Parseable Section
```plaintext
'0 or 1': 60%
'2 or 3': 25%
'4 or 5': 10%
'6 or 7': 3%
'8 or 9': 1%
'10 or more': 1%
```


## R1: Forecaster 2 Reasoning
To address the question of how many new AI labs will become leading labs within 2 years of their founding before 2030, we need to consider the base rates, status quo forces, change drivers, and recent updates.

### Base Rates & Reference Class
Historically, the emergence of new AI labs that quickly ascend to the top tier is rare. The current landscape is dominated by established players, and predictions suggest a stable number of leading labs in the near future. This indicates a low base rate for new labs reaching the top 5 within 2 years.

### Status Quo Forces vs Change Drivers
- **Status Quo Forces:** The dominance of established labs like OpenAI, Anthropic, and Google DeepMind presents significant barriers to new entrants. These labs have substantial resources and talent, making it difficult for newcomers to compete.
- **Change Drivers:** While technological advancements and innovative approaches could disrupt the market, no new labs have yet succeeded in displacing incumbents. Speculation exists around potential challengers, but none have materialized as top contenders.

### Most Recent Credible Updates
As of 2025-08-01, no new AI labs founded after April 2024 have entered the top 5 on Chatbot Arena within 2 years of their founding. This reinforces the difficulty new labs face in quickly becoming leading labs.

### Resolution Criteria Traps & Fine-Print Gotchas
The question remains open until 2030, allowing for future developments that could change the current assessment. However, the stability of the current leaderboard and the high barriers to entry suggest that significant changes are unlikely in the short term.

### Disconfirming Evidence
While the consensus is that new labs struggle to enter the top tier quickly, there is always the potential for breakthrough innovations or unique approaches that could allow new labs to achieve top rankings faster than expected. However, given the current evidence, such occurrences seem unlikely.

### Bayesian Analysis
Given the low base rate of new labs becoming top 5 within 2 years, the stability of the current leaderboard, and the lack of recent successful new entrants, the probability of a high number of new leading labs is low.

1. **'0 or 1'**: High probability due to significant barriers to entry and no recent successful new entrants.
2. **'2 or 3'**: Moderate probability, allowing for the possibility of a few breakthroughs.
3. **'4 or 5'**: Low probability, as it would require multiple successful new entrants.
4. **'6 or 7'**: Very low probability, given current trends and barriers.
5. **'8 or 9'**: Extremely low probability, unlikely given historical trends.
6. **'10 or more'**: Near-zero probability, as it would require a major shift in the current landscape.

### Ranked List with Probabilities
1. **'0 or 1'**: 60%
2. **'2 or 3'**: 25%
3. **'4 or 5'**: 10%
4. **'6 or 7'**: 3%
5. **'8 or 9'**: 1%
6. **'10 or more'**: 1%

### Machine-Readable Output
```
'0 or 1': 60%
'2 or 3': 25%
'4 or 5': 10%
'6 or 7': 3%
'8 or 9': 1%
'10 or more': 1%
```


## R1: Forecaster 3 Reasoning
To forecast how many new AI labs will become leading labs within 2 years of their founding before 2030, we need to consider several factors:

1. **Base Rates & Reference Class**: Historically, new AI labs face significant challenges in becoming top-tier contenders within 2 years of founding. The current prediction suggests a stable number of leading labs, with an estimate of about 5.39 frontier labs by the end of 2025. Established players dominate the leaderboard, indicating high barriers to entry.

2. **Status Quo Forces vs Change Drivers**:
- **Status Quo Forces**: Established labs have significant resources, talent, and market presence, making it difficult for new entrants to compete. The current leaderboard is stable, with no new entrants displacing incumbents within 2 years.
- **Change Drivers**: Technological advancements and innovative approaches could potentially allow new labs to disrupt the market. Speculation exists around new entrants that could challenge the status quo, but none have yet succeeded.

3. **Recent Updates**: As of 2025-08-01, no new AI labs founded after April 2024 have entered the top 5 on Chatbot Arena within 2 years of their founding. Ongoing speculation about new entrants exists, but established players continue to dominate the leaderboard.

4. **Resolution Criteria & Potential Variability**: The question remains open until 2030, meaning future developments could alter the current assessment. If Chatbot Arena becomes unavailable, alternative sources will be used for resolution, which may introduce variability in outcomes.

5. **Disconfirming Evidence**: While the consensus is that new labs struggle to enter the top tier quickly, there are examples in tech history where startups have rapidly ascended to prominence. The potential for breakthrough innovations or unique approaches in AI could allow new labs to achieve top rankings faster than expected.

Given these considerations, the probability distribution for the number of new AI labs that will become leading labs by 2030 is as follows:

- **0 or 1**: High probability, as historical trends and current status quo forces suggest few new entrants will achieve top-tier status quickly.
- **2 or 3**: Moderate probability, allowing for some potential disruption by new entrants.
- **4 or 5**: Lower probability, as significant disruption would be required for multiple new labs to enter the top tier.
- **6 or 7**: Very low probability, as this would require a major shift in the current landscape.
- **8 or 9**: Extremely low probability, as this would indicate a complete overhaul of the current leaders.
- **10 or more**: Near-zero probability, as it is highly unlikely that such a large number of new labs will become leading labs within the timeframe.

### Ranked List with Probabilities:
1. **0 or 1**: 60%
2. **2 or 3**: 25%
3. **4 or 5**: 10%
4. **6 or 7**: 3%
5. **8 or 9**: 1%
6. **10 or more**: 1%

### Machine-Parseable Section:
- '0 or 1': 60%
- '2 or 3': 25%
- '4 or 5': 10%
- '6 or 7': 3%
- '8 or 9': 1%
- '10 or more': 1%


## R1: Forecaster 4 Reasoning
To forecast the number of new AI labs that will become leading labs within 2 years of their founding before 2030, we need to consider both historical trends and potential future developments.

### Base Rates & Reference Class
Historically, new AI labs face significant challenges in becoming top-tier contenders within 2 years of founding. The current top 5 AI labs are well-established, indicating high barriers to entry. The base rate for new labs entering the top 5 within 2 years is low.

### Status Quo Forces vs Change Drivers
- **Status Quo Forces:** Established labs have significant resources and market presence, making it difficult for new entrants to compete. The current leaderboard is stable, with no new entrants displacing incumbents within 2 years.
- **Change Drivers:** Technological advancements and innovative approaches could potentially allow new labs to disrupt the market. However, no new labs have succeeded in doing so since April 2024.

### Most Recent Credible Updates
As of 2025-08-01, no new AI labs founded after April 2024 have entered the top 5 on Chatbot Arena within 2 years of their founding. Speculation exists around new entrants, but established players continue to dominate.

### Disconfirming Evidence
While the consensus is that new labs struggle to enter the top tier quickly, there are examples in tech history where startups have rapidly ascended to prominence. The potential for breakthrough innovations could allow new labs to achieve top rankings faster than expected.

### Bayesian Analysis
Given the base rate and the current status quo, the likelihood of a significant number of new labs becoming leading labs is low. However, considering potential change drivers and disconfirming evidence, we should not entirely discount the possibility of a few new entrants succeeding.

1. **'0 or 1'**: High probability due to the strong status quo forces and historical trends.
2. **'2 or 3'**: Moderate probability considering potential disruptions and innovations.
3. **'4 or 5'**: Lower probability as it would require significant breakthroughs and multiple successful new entrants.
4. **'6 or 7'**: Very low probability given the current market dynamics.
5. **'8 or 9'**: Extremely low probability as it would require a major shift in the AI landscape.
6. **'10 or more'**: Nearly negligible probability due to the high barriers to entry and stability of current leaders.

### Ranked List with Probabilities
1. **'0 or 1'**: 60%
2. **'2 or 3'**: 25%
3. **'4 or 5'**: 10%
4. **'6 or 7'**: 3%
5. **'8 or 9'**: 1%
6. **'10 or more'**: 1%

### Machine-Readable Output
```plaintext
'0 or 1': 60%
'2 or 3': 25%
'4 or 5': 10%
'6 or 7': 3%
'8 or 9': 1%
'10 or more': 1%
```


## R1: Forecaster 5 Reasoning
To forecast how many new AI labs will become leading labs within 2 years of their founding before 2030, we need to consider both the base rates and the current dynamics in the AI industry.

### Base Rates & Reference Class
- Historically, it's rare for new AI labs to become top-tier contenders within 2 years. The current landscape is dominated by established players, and the barriers to entry are high.

### Status Quo Forces vs Change Drivers
- **Status Quo Forces:** Established labs have significant advantages in resources, talent, and market presence. The current leaderboard is stable, with no new entrants displacing incumbents within 2 years.
- **Change Drivers:** Technological advancements and innovative approaches could allow new labs to disrupt the market. However, no new labs have succeeded in doing so yet.

### Most Recent Credible Updates
- As of 2025-08-01, no new AI labs founded after April 2024 have entered the top 5 on Chatbot Arena within 2 years of their founding.

### Disconfirming Evidence
- There are historical examples where startups have rapidly ascended to prominence, suggesting that breakthrough innovations could allow new labs to achieve top rankings faster than expected.

### Bayesian Analysis
1. **Base Rate Probability:** Given the historical difficulty for new labs to become leading within 2 years, the base rate for 0 or 1 new leading lab is high.
2. **Likelihoods:** The current stability of the leaderboard and lack of new entrants suggest that the probability of more than 1 new leading lab is low.
3. **Posterior Probability:** Considering the base rate and current evidence, the probability of 0 or 1 new leading lab remains the highest.

### Ranked List with Probabilities
1. **'0 or 1'**: 60%
- High barriers to entry and current evidence suggest this is the most likely scenario.
2. **'2 or 3'**: 25%
- Some potential for disruption exists, but no evidence of new entrants succeeding yet.
3. **'4 or 5'**: 10%
- Unlikely given current trends and historical data.
4. **'6 or 7'**: 3%
- Very unlikely without significant disruption.
5. **'8 or 9'**: 1%
- Extremely unlikely.
6. **'10 or more'**: 1%
- Extremely unlikely.

### Machine-Parseable Section
```
'0 or 1': 60%
'2 or 3': 25%
'4 or 5': 10%
'6 or 7': 3%
'8 or 9': 1%
'10 or more': 1%
```

------------------------------------------------------------

‚ùì Question: How many major US labor strikes with generative AI as one of their main reasons will start in 2029?
üîó URL: https://www.metaculus.com/questions/38880

üìù Full Reasoning:
# SUMMARY
*Question*: How many major US labor strikes with generative AI as one of their main reasons will start in 2029?
*Final Prediction*: Probability distribution:
- 0.00% chance of value below -0.5
- 5.50% chance of value below 0.5
- 17.50% chance of value below 1.5
- 37.50% chance of value below 2.5
- 56.25% chance of value below 3.5
- 68.75% chance of value below 4.5
- 82.50% chance of value below 5.5
- 92.25% chance of value below 6.5
- 96.75% chance of value below 7.5

*Total Cost*: $0.0698
*Time Spent*: 1.81 minutes


## Report 1 Summary
### Forecasts
*Forecaster 1*: Probability distribution:
- 1.00% chance of value below 0.0
- 10.00% chance of value below 1.0
- 25.00% chance of value below 2.0
- 50.00% chance of value below 3.0
- 75.00% chance of value below 5.0
- 90.00% chance of value below 6.0
- 99.00% chance of value below 8.0

*Forecaster 2*: Probability distribution:
- 1.00% chance of value below 0.0
- 10.00% chance of value below 1.0
- 25.00% chance of value below 2.0
- 50.00% chance of value below 3.0
- 75.00% chance of value below 5.0
- 90.00% chance of value below 6.0
- 99.00% chance of value below 8.0

*Forecaster 3*: Probability distribution:
- 1.00% chance of value below 0.0
- 10.00% chance of value below 1.0
- 25.00% chance of value below 2.0
- 50.00% chance of value below 3.0
- 75.00% chance of value below 5.0
- 90.00% chance of value below 6.0
- 99.00% chance of value below 7.0

*Forecaster 4*: Probability distribution:
- 1.00% chance of value below 0.0
- 10.00% chance of value below 1.0
- 25.00% chance of value below 2.0
- 50.00% chance of value below 3.0
- 75.00% chance of value below 5.0
- 90.00% chance of value below 6.0
- 99.00% chance of value below 8.0

*Forecaster 5*: Probability distribution:
- 1.00% chance of value below 0.0
- 10.00% chance of value below 1.0
- 25.00% chance of value below 2.0
- 50.00% chance of value below 3.0
- 75.00% chance of value below 5.0
- 90.00% chance of value below 6.0
- 99.00% chance of value below 8.0



### Research Summary
The research examines the potential for major labor strikes in the U.S. related to generative AI, focusing on historical trends, legislative developments, and union activities. It notes a significant rise in labor strikes, with 470 stoppages involving 539,000 workers in 2023, and highlights the SAG-AFTRA video game strike (2024-2025) as a pivotal reference for disputes involving generative AI. The study outlines the influence of recent California laws (AB 1836 and AB 2602) aimed at enhancing protections for workers against AI misuse, as well as the increasing incorporation of generative AI issues into union bargaining demands.

The research further contrasts status quo forces, such as existing labor laws and company resistance to union demands, with change drivers like rising awareness of AI's impact on jobs and legislative changes that bolster worker protections. It discusses potential limitations in predicting future strikes, including the BLS's focus on major strikes, economic conditions, and varying union priorities regarding generative AI. Additionally, it addresses disconfirming evidence, such as the absence of recorded major strikes related to generative AI for 2029 and the possibility of employer adaptations and legislative delays affecting strike likelihood.

Sources used include:
- [Bureau of Labor Statistics (BLS)](https://www.bls.gov)
- [California Legislative Information](https://leginfo.legislature.ca.gov)


# RESEARCH
## Report 1 Research
### 1) Base Rates & Reference Class
- **Historical Context:** Significant increase in labor strikes in the US, with 470 stoppages involving 539,000 workers in 2023.
- **BLS Criteria:** Major work stoppages are defined as involving at least 1,000 workers and lasting at least one shift.
- **Precedent for AI Strikes:** The SAG-AFTRA video game strike (2024-2025) serves as a key reference for labor disputes involving generative AI.
- **Legislative Trends:** California's recent laws (AB 1836 and AB 2602) reflect growing protections against AI misuse in labor contexts.
- **Union Activity:** Unions are increasingly incorporating generative AI issues into their bargaining demands.

### 2) Status Quo Forces vs Change Drivers
- **Status Quo Forces:**
- Existing labor laws and industry practices may slow the pace of change.
- Companies may resist union demands for AI protections to maintain operational flexibility.
- **Change Drivers:**
- Rising awareness and activism around generative AI's impact on jobs.
- Legislative changes providing stronger protections for workers against AI misuse.
- Increased unionization and collective bargaining efforts in sectors affected by AI.

### 3) Most Recent Credible Updates WITH DATES (YYYY-MM-DD)
- **2023-09-01:** SAG-AFTRA authorized the video game strike due to failed negotiations over AI protections.
- **2024-09-01:** California passed AB 1836 and AB 2602, enhancing protections for performers against unauthorized AI use.
- **2025-06-01:** SAG-AFTRA video game strike ended after a tentative agreement was reached, emphasizing AI protections.
- **2023-12-01:** Reports indicate a significant rise in union strikes, with 470 stoppages recorded in 2023.
- **2024-01-15:** Unions began to explicitly include generative AI in their bargaining demands across various sectors.

### 4) Resolution Criteria Traps & Fine-Print Gotchas
- **BLS Reporting Limitations:** Only major strikes are recorded, potentially overlooking smaller but significant labor disputes related to AI.
- **Future Predictions:** Current trends do not guarantee future strikes; economic conditions and industry responses can alter trajectories.
- **Legislative Impact:** New laws may take time to influence actual labor negotiations and strike activity.
- **Union Dynamics:** Not all unions may prioritize generative AI issues equally, leading to inconsistent bargaining outcomes.
- **Public Sentiment:** Changes in public opinion regarding AI could affect union strategies and employer negotiations.

### 5) Disconfirming Evidence (Steelman)
- **Lack of Immediate Action:** Despite the precedent set by the SAG-AFTRA strike, no major strikes specifically related to generative AI have been recorded for 2029.
- **Economic Factors:** Economic downturns or shifts in industry priorities could reduce the likelihood of strikes related to AI.
- **Employer Adaptation:** Companies may proactively implement policies to mitigate AI-related labor disputes, reducing strike potential.
- **Legislative Delays:** The impact of recent legislation may not manifest immediately, leading to a temporary lull in AI-related labor disputes.
- **Union Fragmentation:** Disparate union responses to AI issues could dilute collective bargaining power, hindering strike potential.

# FORECASTS

## R1: Forecaster 1 Reasoning
To forecast the number of major US labor strikes with generative AI as one of their main reasons starting in 2029, we need to consider both historical data and potential future trends. Here‚Äôs a structured approach:

### Base Rates & Reference Class
- **Historical Context:** In 2023, there were 470 stoppages, but only a subset would meet the BLS criteria for major work stoppages.
- **Precedent for AI Strikes:** The SAG-AFTRA video game strike is a key example, but as of now, there are no major strikes specifically for 2029.

### Status Quo Forces vs Change Drivers
- **Status Quo Forces:** Existing labor laws and industry practices may slow down the adoption of AI-related strikes.
- **Change Drivers:** Increasing awareness and legislative changes could drive more AI-related labor actions.

### Disconfirming Evidence
- **Lack of Immediate Action:** No major strikes specifically related to generative AI have been recorded for 2029.
- **Economic Factors:** Economic downturns could reduce strike likelihood.

### Numeric Forecast
Given the current data and trends, it is reasonable to expect a moderate number of strikes, influenced by both the increasing awareness of AI issues and the potential mitigating actions by employers and legislators.

**Percentiles:**
- 1st: 0
- 10th: 1
- 25th: 2
- 50th: 3
- 75th: 5
- 90th: 6
- 99th: 8

### BAYESIAN Block
- **Base Rate:** Assume a low base rate for major AI-related strikes given the novelty and specificity of the issue.
- **Likelihoods:** Consider the likelihood of strikes given the increasing union activity and legislative changes.
- **Proposal:**
```xml
<family>lognormal</family>
<params>mean=1.5, sd=0.5</params>
```

This forecast accounts for both the potential for increased AI-related labor disputes and the current absence of major strikes specifically recorded for 2029. The lognormal distribution reflects the skewed nature of potential outcomes, where a few strikes are more likely than many.


## R1: Forecaster 2 Reasoning
To forecast the number of major US labor strikes with generative AI as one of their main reasons starting in 2029, we need to consider both historical trends and current developments in labor relations, AI integration, and legislative changes.

### Percentile Forecast
- **1st percentile:** 0
- **10th percentile:** 1
- **25th percentile:** 2
- **50th percentile (median):** 3
- **75th percentile:** 5
- **90th percentile:** 6
- **99th percentile:** 8

### Bayesian Block
- **Base Rate:** The base rate for major strikes in general is derived from the 470 stoppages recorded in 2023. However, only a subset of these will likely involve generative AI as a primary demand.
- **Likelihoods:**
- **Increase in AI-related strikes:** The precedent set by the SAG-AFTRA strikes and increasing union focus on AI issues suggest a growing likelihood of AI-related strikes.
- **Legislative Influence:** New laws in California and other states may encourage more unions to strike over AI issues.
- **Economic and Industry Factors:** Potential economic downturns or proactive employer policies could reduce the likelihood of strikes.
- **Parametric Proposal:**
- **Family:** Lognormal
- **Params:** <params>Œº=1.0, œÉ=0.5</params>

### Rationale
- **Base Rate & Reference Class:** The historical increase in labor strikes and the specific focus on AI in recent strikes provide a basis for expecting some level of AI-related strike activity in 2029.
- **Status Quo vs Change Drivers:** While existing labor laws and industry practices may slow down the pace of change, the growing awareness and legislative support for AI-related labor issues are strong change drivers.
- **Recent Updates:** The recent legislative changes and union activities explicitly targeting AI issues suggest an increased probability of strikes.
- **Disconfirming Evidence:** The lack of immediate action and potential economic factors could dampen the number of strikes, but the trend towards more AI-related demands in labor negotiations is likely to continue.

Overall, while there is uncertainty, the trend suggests a moderate increase in AI-related strikes, with a median forecast of 3 strikes in 2029.


## R1: Forecaster 3 Reasoning
To forecast the number of major US labor strikes with generative AI as one of their main reasons starting in 2029, we need to consider both historical trends and potential future developments.

### Percentile Forecast
- **1st percentile:** 0
- **10th percentile:** 1
- **25th percentile:** 2
- **50th percentile (median):** 3
- **75th percentile:** 5
- **90th percentile:** 6
- **99th percentile:** 7

### Bayesian Block
- **<base_rate>:** The base rate for major strikes in 2023 was 470, with a significant portion involving technological concerns. However, specific AI-related strikes are less frequent, with only a few notable examples like the SAG-AFTRA strike.
- **<likelihoods>:** 
- **Increased Awareness:** Rising awareness and legislative changes suggest a higher likelihood of AI-related strikes.
- **Economic Factors:** Economic downturns could reduce overall strike activity, but AI-related concerns may still prompt action.
- **Union Activity:** Growing union emphasis on AI issues increases the likelihood of related strikes.
- **<family>lognormal</family>**
- **<params>meanlog=1.1, sdlog=0.5</params>**

### Rationale
- **Historical Context:** The precedent of AI-related strikes, such as the SAG-AFTRA strike, indicates potential for future occurrences. However, these are still relatively rare compared to the total number of strikes.
- **Legislative Trends:** New laws in California and increased union activity around AI issues suggest a growing focus on AI in labor disputes.
- **Economic and Industry Dynamics:** While economic conditions can impact strike frequency, the specific focus on AI may drive strikes even in less favorable economic climates.
- **Uncertainty and Variability:** The forecast reflects uncertainty about the pace of change and the impact of legislative and union activities on strike frequency. The upper bound is constrained by the question creator's input, suggesting a cautious approach to higher estimates.


## R1: Forecaster 4 Reasoning
### Numeric Forecast

- **1st Percentile:** 0
- **10th Percentile:** 1
- **25th Percentile:** 2
- **50th Percentile:** 3
- **75th Percentile:** 5
- **90th Percentile:** 6
- **99th Percentile:** 8

### Bayesian Block

- **Base Rate:** 
- Historical context suggests a significant increase in labor strikes, with 470 stoppages in 2023. However, only a subset of these involve generative AI as a primary demand.
- The precedent for AI-related strikes is limited but growing, with notable examples like the SAG-AFTRA video game strike.

- **Likelihoods:**
- **Status Quo Forces:** Existing labor laws and industry practices may slow the pace of change, potentially reducing the likelihood of AI-related strikes.
- **Change Drivers:** Rising awareness and legislative changes are likely to increase the incidence of AI-related labor disputes.

- **Parametric Proposal:**
- <family>lognormal</family>
- <params>meanlog = 1.5, sdlog = 0.5</params>

### Rationale

1. **Base Rates & Reference Class:** The significant increase in labor strikes in 2023 provides a backdrop for potential future strikes. However, the specific focus on generative AI is still emerging, with only a few notable examples to date.

2. **Status Quo Forces vs Change Drivers:** While there are strong drivers for change, such as legislative actions and increased union activity around AI issues, there are also significant forces maintaining the status quo, such as existing labor laws and company resistance.

3. **Recent Updates & Trends:** Recent legislative changes and union activities indicate a growing focus on AI-related issues. However, the impact of these changes may not be immediate, and economic factors could influence strike activity.

4. **Resolution Criteria & Disconfirming Evidence:** The BLS's focus on major strikes and the potential for economic downturns or employer adaptation could limit the number of recorded AI-related strikes. Additionally, union fragmentation and legislative delays could further reduce strike potential.

5. **Question Creator's Insight:** The question creator's belief that the number is likely not higher than 7 provides a useful upper bound for the forecast.


## R1: Forecaster 5 Reasoning
To forecast the number of major US labor strikes with generative AI as one of their main reasons starting in 2029, we need to consider both historical trends and emerging factors influencing labor disputes related to AI.

### Percentile Forecast
- **1st Percentile:** 0
- **10th Percentile:** 1
- **25th Percentile:** 2
- **50th Percentile (Median):** 3
- **75th Percentile:** 5
- **90th Percentile:** 6
- **99th Percentile:** 8

### Bayesian Block
- **Base Rate:** The base rate is informed by recent trends, with 470 stoppages recorded in 2023, though not all related to AI. The specific base rate for AI-related strikes is low, given only a few have been recorded so far.
- **Likelihoods:**
- **Increased Union Activity:** High likelihood of AI being included in bargaining demands.
- **Legislative Trends:** Moderate likelihood of influencing strike activity, as laws are still new.
- **Economic Factors:** Moderate likelihood of impacting strike frequency, depending on economic conditions.
- **Employer Adaptation:** Moderate likelihood of reducing strikes if companies proactively address AI concerns.
- **Parametric Proposal:**
```xml
<family>lognormal</family>
<params>mu=1, sigma=0.5</params>
```

### Rationale
- **Historical Context & Base Rates:** While there is a significant number of labor strikes, only a small fraction currently relate to AI. The SAG-AFTRA strikes provide a precedent but are not yet widespread across industries.
- **Change Drivers vs. Status Quo Forces:** The growing inclusion of AI in union demands and legislative changes are strong change drivers. However, existing labor laws and potential economic downturns could act as counterforces.
- **Recent Updates:** The recent legislative changes and union activities suggest a growing trend, but it remains nascent.
- **Disconfirming Evidence:** The lack of immediate action and potential economic and legislative delays suggest a cautious approach to forecasting a high number of strikes.

Overall, while the trend is towards more AI-related labor disputes, significant uncertainty remains, warranting a conservative forecast with potential for moderate increases.

------------------------------------------------------------

