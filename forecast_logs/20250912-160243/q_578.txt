# Will humans go extinct before 2100? (QID: 578)

- Type: binary

- URL: https://www.metaculus.com/questions/578/

- Classifier: xrisk | strategic=False (score=0.00)

## Research (summary)

CALIBRATION GUIDANCE (auto-generated weekly):
BINARY CALIBRATION
- No resolved binary questions (with pre-resolution forecasts) yet.
- Advice: keep using base rates + small evidence-weighted updates; avoid big swings.

MULTIPLE-CHOICE CALIBRATION (Top-1)
- No resolved MCQ questions (with pre-resolution forecasts) yet.

NUMERIC CALIBRATION (PIT-lite + CRPS)
- No resolved numeric questions (with pre-resolution forecasts) yet.
- When numeric results exist, we’ll check p10/p50/p90 coverage and CRPS.

General takeaway: apply **small** nudges only where gaps are consistent with decent sample sizes (≥10).
— end calibration —

### Reference class & base rates
- **Global Catastrophic Risks**: Historical base rate of extinction-level events is extremely low; no known human extinction events in recorded history.
- **Species Extinction Rates**: Current species extinction rates are estimated at 0.01% to 0.1% per year, but humans have unique adaptive capabilities.
- **Nuclear War/Climate Change**: No historical precedent for human extinction from these, but they are considered significant risks.

### Recent developments (timeline bullets)
- [2023-06-15] ↓ — Increased international cooperation on climate change mitigation reduces existential risk.
- [2023-03-10] ↑ — AI advancements raise concerns about potential uncontrollable scenarios.
- [2022-11-05] ↓ — Successful asteroid deflection test enhances planetary defense capabilities.

### Mechanisms & drivers (causal levers)
- **Technological Advancements**: Moderate; can both mitigate and exacerbate risks.
- **Climate Change**: Moderate; ongoing efforts to curb emissions may reduce risk.
- **Nuclear Proliferation**: Large; geopolitical tensions could increase extinction risk.
- **Pandemics**: Moderate; improved global health responses can mitigate risk.
- **Space Colonization**: Small; potential long-term buffer against Earth-bound risks.

### Differences vs. the base rate (what’s unusual now)
- **Technological Growth**: Rapid advancements in AI and biotechnology present new risks and opportunities.
- **Global Connectivity**: Increased interdependence can both spread and mitigate risks.
- **Policy Focus**: Growing emphasis on existential risk reduction in policy circles.
- **Public Awareness**: Greater awareness and discourse on existential risks compared to historical norms.

### Bayesian update sketch (for the statistician)
- **Prior**: Low probability of extinction by 2100, equivalent n = 10.
- **Evidence mapping**:
  - ↑ AI risks (moderate)
  - ↓ Climate cooperation (small)
  - ↓ Planetary defense (small)
  - ↑ Nuclear tensions (moderate)
- **Net effect**: Posterior should move slightly up due to increased AI and nuclear risks, but mitigated by climate and defense efforts.

### Indicators to watch (leading signals; next weeks/months)
- **UP indicators**:
  - Escalation in geopolitical tensions.
  - Breakthroughs in AI capabilities without safety measures.
  - Major climate policy failures.
- **DOWN indicators**:
  - Successful international treaties on nuclear disarmament.
  - Advances in AI safety protocols.
  - Increased investment in space colonization.

### Caveats & pitfalls
- **Uncertainty in AI development**: Unpredictable trajectory and impact.
- **Data gaps**: Limited historical data on extinction-level events.
- **Deception risks**: Potential misinformation on existential threats.
- **Regime changes**: Political shifts can alter risk landscapes.
- **Definitional gotchas**: Ambiguities in defining "human" and "extinction."

Final Research Summary: While the base rate for human extinction by 2100 is low, recent developments in AI and geopolitical tensions suggest a slight increase in risk. However, advancements in climate policy and planetary defense provide mitigating factors.

### Sources (autofetched)
- Deep future: Why we'll still be here (newscientist.com) — https://www.newscientist.com/article/mg21328541-800-deep-future-why-well-still-be-here/
- In Order to Ensure Our Surviv

## Per-model

- **OpenRouter-Default** ok=True time=10572ms parsed=0.1

- **Claude-3.7-Sonnet (OR)** ok=True time=24943ms parsed=0.11

- **Gemini** ok=False time=170ms parsed=0.0

- **Grok** ok=False time=174ms parsed=0.0

## Ensembles (with research)

- main=0.1410 | no_gtmc1=0.1410 | uniform=0.1410 | simple=0.1050

## Ablation (no research)

- main=0.0628 | uniform=0.0628 | simple=0.0175