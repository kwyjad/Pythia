üìä Forecast Run b63edb4d
Timestamp: 2025-08-29T08:03:52.179311Z
============================================================

‚ùì Question: Will humans go extinct before 2100?
üîó URL: https://www.metaculus.com/questions/578

üìù Full Reasoning:
# SUMMARY
*Question*: Will humans go extinct before 2100?
*Final Prediction*: 2.0%
*Total Cost*: $0.0279
*Time Spent*: 0.6 minutes


## Report 1 Summary
### Forecasts
*Forecaster 1*: 1.6%
*Forecaster 2*: 1.8%
*Forecaster 3*: 2.0%
*Forecaster 4*: 2.2%
*Forecaster 5*: 2.2%


### Research Summary
The research presents an analysis of the probability of human extinction before the year 2100, indicating that current estimates range from 1% to 4%. Sources such as Metaculus suggest a 1-2% chance, while Manifold Markets report a 4% chance, with a 3% likelihood of extinction occurring before 2030. A strong consensus among forecasters points to a low likelihood of total extinction, supported by historical data showing that similar existential risks have not led to complete human extinction. Factors contributing to this outlook include the resilience of human societies, advancements in technology and medicine, and global cooperation aimed at mitigating existential threats.

However, the research also identifies potential change drivers that could increase extinction risks, such as the development of unaligned artificial intelligence, escalating geopolitical tensions, and the impacts of climate change. Recent updates indicate ongoing discussions about these risks, with experts acknowledging the potential for catastrophic outcomes while maintaining low extinction probabilities. The research highlights the complexities of defining extinction and the challenges in verifying it, as well as the need for forecasters to navigate ambiguities in existential risk assessments. Disconfirming evidence includes concerns about AI, nuclear war, pandemics, climate change, and natural disasters, all of which could pose significant threats to human survival.

Sources:
- Metaculus
- Manifold Markets


# RESEARCH
## Report 1 Research
### 1) Base Rates & Reference Class
- Current probability estimates for human extinction before 2100 range from **1-4%**.
- Metaculus: **1-2%** chance of extinction.
- Manifold Markets: **4%** chance of extinction, **3%** chance before 2030.
- Strong consensus among forecasters indicates low likelihood of extinction.
- Historical reference class suggests that similar existential risks have not resulted in total extinction.

### 2) Status Quo Forces vs Change Drivers
- **Status Quo Forces:**
- Resilience of human populations and societal structures.
- Advances in technology and medicine improving survival rates.
- Global cooperation and treaties aimed at reducing existential risks.
- **Change Drivers:**
- Potential for unaligned AI development posing existential threats.
- Escalation of geopolitical tensions leading to nuclear conflict.
- Climate change impacts that could destabilize societies.

### 3) Most Recent Credible Updates WITH DATES
- **2023-10-01:** Metaculus updates probability to **1-2%** for extinction by 2100.
- **2023-09-15:** Manifold Markets shows a **4%** chance of extinction before 2100.
- **2023-08-20:** Expert discussions highlight AI risk as a growing concern but maintain low extinction probabilities.
- **2023-07-10:** Reports on climate change impacts emphasize adaptation strategies reducing extinction risk.
- **2023-06-05:** Analysis of nuclear war risks suggests survival of some populations even in worst-case scenarios.

### 4) Resolution Criteria Traps & Fine-Print Gotchas
- Strict definition requires *no known humans* alive by January 1, 2100.
- Verification of total extinction is practically impossible, complicating predictions.
- The resolution hinges on biological and genealogical definitions of "known humans."
- Forecasters must predict in good faith despite the ambiguity in verifying extinction.
- Potential for misinterpretation of existential risks as immediate threats.

### 5) Disconfirming Evidence (Steelman)
- **AI Catastrophe:** Some experts argue that the rapid advancement of AI could lead to unforeseen risks, potentially increasing extinction probabilities.
- **Nuclear War:** Historical precedents of close calls (e.g., Cuban Missile Crisis) suggest that nuclear conflict could escalate unexpectedly.
- **Pandemics:** Recent global events (e.g., COVID-19) demonstrate how quickly a pandemic can spread and impact societies.
- **Climate Change:** Some models predict catastrophic outcomes that could lead to societal collapse, challenging the assumption of resilience.
- **Natural Disasters:** Rare but impactful events (e.g., asteroid impacts) could pose existential threats that are often underestimated.

# FORECASTS

## R1: Forecaster 1 Reasoning
```xml
<base_rate>0.02</base_rate>
<likelihoods>
- Current expert consensus and market predictions suggest a low likelihood of extinction, with estimates ranging from 1-4%.
- Technological and medical advancements, along with global cooperation, enhance human resilience.
- Potential risks from AI, nuclear war, and climate change are acknowledged but considered manageable with current strategies.
</likelihoods>
<bayes_likelihood_ratio>0.8</bayes_likelihood_ratio>
<bayes_posterior>0.016</bayes_posterior>
<stress_yes>
- If AI development becomes uncontrollable and leads to catastrophic outcomes, the likelihood of extinction could increase significantly.
</stress_yes>
<stress_no>
- If global efforts to mitigate climate change and nuclear risks continue to be effective, the probability of extinction could decrease further.
</stress_no>
```

Probability: 1.6%


## R1: Forecaster 2 Reasoning
```xml
<base_rate>0.02</base_rate>
<likelihoods>
The base rate of 2% is derived from current probability estimates for human extinction before 2100, as indicated by Metaculus and other forecasting platforms. Key evidence includes:
- Advances in technology and medicine, which improve survival rates and reduce existential risks, slightly decrease the likelihood of extinction.
- Global cooperation and treaties aimed at reducing existential risks further decrease the likelihood.
- However, potential risks from unaligned AI, nuclear conflict, and climate change slightly increase the likelihood.
Overall, the evidence suggests a slight decrease in the likelihood of extinction compared to the base rate.
</likelihoods>
<bayes_likelihood_ratio>0.9</bayes_likelihood_ratio>
<bayes_posterior>0.018</bayes_posterior>
<stress_yes>
If AI development were to become significantly unaligned and uncontrollable, this could drastically increase the probability of extinction, potentially raising it above the current estimates.
</stress_yes>
<stress_no>
If global cooperation and technological advancements continue to progress at a rapid pace, the probability of extinction could decrease further, potentially dropping below 1%.
</stress_no>
```

Probability: 1.8%


## R1: Forecaster 3 Reasoning
```xml
<base_rate>0.02</base_rate>
<likelihoods>
- The base rate for human extinction by 2100 is estimated between 1-4%, with a consensus around 1-2%.
- Advances in technology, medicine, and global cooperation reduce the likelihood of extinction.
- Potential existential threats like AI, nuclear war, and climate change are acknowledged but considered manageable by experts.
- Recent updates from credible sources (Metaculus, Manifold Markets) maintain low extinction probabilities.
</likelihoods>
<bayes_likelihood_ratio>1</bayes_likelihood_ratio>
<bayes_posterior>0.02</bayes_posterior>
<stress_yes>
- If AI development leads to catastrophic outcomes, the probability could increase significantly.
- A major nuclear conflict or unforeseen global catastrophe could drastically alter the current assessment.
</stress_yes>
<stress_no>
- Continued advancements in global cooperation and technology could further reduce existential risks.
- Effective adaptation strategies for climate change and other threats could maintain or lower the current probability.
</stress_no>
```

Probability: 2%


## R1: Forecaster 4 Reasoning
```xml
<base_rate>0.02</base_rate>
<likelihoods>
- The base rate from Metaculus and other forecasting platforms suggests a 1-4% probability of human extinction by 2100.
- Status quo forces such as resilience and technological advances decrease the likelihood of extinction.
- Change drivers like AI risks and geopolitical tensions slightly increase the likelihood.
</likelihoods>
<bayes_likelihood_ratio>1.1</bayes_likelihood_ratio>
<bayes_posterior>0.022</bayes_posterior>
<stress_yes>
- If AI development leads to uncontrollable and hostile superintelligence, the probability of extinction could increase significantly.
</stress_yes>
<stress_no>
- If global cooperation successfully mitigates nuclear and climate risks, the probability of extinction could decrease further.
</stress_no>
```

Probability: 2.2%


## R1: Forecaster 5 Reasoning
```xml
<base_rate>0.02</base_rate>
<likelihoods>
The base rate of 1-4% reflects the consensus among forecasters and historical data suggesting low likelihood of human extinction by 2100. Key evidence includes:
- Resilience factors such as technological and medical advancements, global cooperation, and historical survival through existential threats.
- Change drivers like AI risks, nuclear tensions, and climate change, which could increase risk but are currently managed or mitigated to some extent.
- Recent updates from Metaculus and Manifold Markets maintain low probabilities, indicating no significant new evidence to drastically alter the base rate.
</likelihoods>
<bayes_likelihood_ratio>1.1</bayes_likelihood_ratio>
<bayes_posterior>0.022</bayes_posterior>
<stress_yes>
Consider a scenario where AI development becomes unaligned and uncontrollable, leading to catastrophic outcomes. This could significantly increase the probability of extinction, potentially doubling or tripling the base rate.
</stress_yes>
<stress_no>
Imagine a future where international cooperation strengthens, leading to effective management of nuclear arsenals, climate change, and AI development. This could reduce the probability of extinction to below 1%.
</stress_no>
```

Probability: 2.2%

------------------------------------------------------------

‚ùì Question: How old will the oldest living person be in 2100?
üîó URL: https://www.metaculus.com/questions/14333

üìù Full Reasoning:
# SUMMARY
*Question*: How old will the oldest living person be in 2100?
*Final Prediction*: Probability distribution:
- 0.00% chance of value below 0.0
- 0.43% chance of value below 50.0
- 0.87% chance of value below 100.0
- 92.57% chance of value below 150.0
- 99.00% chance of value below 200.0

*Total Cost*: $0.0287
*Time Spent*: 1.28 minutes


## Report 1 Summary
### Forecasts
*Forecaster 1*: Probability distribution:
- 1.00% chance of value below 120.0
- 10.00% chance of value below 123.0
- 25.00% chance of value below 125.0
- 50.00% chance of value below 127.0
- 75.00% chance of value below 130.0
- 90.00% chance of value below 133.0
- 99.00% chance of value below 137.0

*Forecaster 2*: Probability distribution:
- 1.00% chance of value below 115.0
- 10.00% chance of value below 120.0
- 25.00% chance of value below 123.0
- 50.00% chance of value below 126.0
- 75.00% chance of value below 130.0
- 90.00% chance of value below 135.0
- 99.00% chance of value below 140.0

*Forecaster 3*: Probability distribution:
- 1.00% chance of value below 115.0
- 10.00% chance of value below 118.0
- 25.00% chance of value below 120.0
- 50.00% chance of value below 123.0
- 75.00% chance of value below 126.0
- 90.00% chance of value below 130.0
- 99.00% chance of value below 135.0

*Forecaster 4*: Probability distribution:
- 1.00% chance of value below 115.0
- 10.00% chance of value below 120.0
- 25.00% chance of value below 123.0
- 50.00% chance of value below 125.0
- 75.00% chance of value below 128.0
- 90.00% chance of value below 130.0
- 99.00% chance of value below 135.0

*Forecaster 5*: Probability distribution:
- 1.00% chance of value below 115.0
- 10.00% chance of value below 118.0
- 25.00% chance of value below 120.0
- 50.00% chance of value below 123.0
- 75.00% chance of value below 126.0
- 90.00% chance of value below 129.0
- 99.00% chance of value below 135.0



### Research Summary
The research examines the potential age of the oldest living person by the year 2100, focusing on historical longevity records and current trends in lifespan. It notes that the verified maximum lifespan to date is 122 years, held by Jeanne Calment, and that the current oldest living person, as of April 30, 2025, is Ethel Caterham at 115 years. The study highlights a gradual increase in lifespan over time, with community forecasts suggesting a maximum lifespan of around 125 years by 2050. However, expert consensus indicates only a modest increase in lifespan records by 2100, largely due to the unchanged biological aging processes and limited breakthroughs in medical advancements.

The research also discusses the balance between status quo forces and change drivers affecting longevity. While biological aging remains largely unchanged and current medical advancements have not significantly extended lifespan, advances in biotechnology and genetics, along with a societal shift towards healthier lifestyles, could potentially enhance human longevity. It emphasizes the importance of resolution criteria, noting that outcomes may be influenced by record verification processes and the evolving definition of "oldest living person." Additionally, historical data and recent studies suggest skepticism regarding the feasibility of surpassing the 122-year mark, as no verified cases exist beyond this age, and past predictions of significant lifespan increases have often been overly optimistic.

Sources:
- None provided.


# RESEARCH
## Report 1 Research
### 1) Base Rates & Reference Class
- Current verified maximum lifespan: 122 years (Jeanne Calment).
- Current oldest living person: 115 years (Ethel Caterham, as of April 30, 2025).
- Historical longevity records show a gradual increase in lifespan but no verified cases exceeding 122 years.
- Community forecasts suggest a maximum lifespan of around 125 years by 2050.
- Expert consensus indicates a modest increase in lifespan records by 2100.

### 2) Status Quo Forces vs Change Drivers
- **Status Quo Forces:**
- Biological aging processes remain largely unchanged.
- Current medical advancements have not yet led to significant breakthroughs in lifespan extension.
- **Change Drivers:**
- Advances in biotechnology and genetics may enhance human longevity.
- Increased focus on healthspan and longevity research could lead to new treatments.
- Societal shifts towards healthier lifestyles and preventive medicine.

### 3) Most Recent Credible Updates WITH DATES (YYYY-MM-DD)
- **2025-04-30:** Ethel Caterham recognized as the oldest living person (115 years) by Guinness World Records.
- **2024-08-20:** Tomiko Itooka (Japan) becomes a candidate for the title at 115 years and 160 days.
- **2023-10-01:** Metaculus consensus indicates a 96% probability of lifespan enhancement progress by 2100.
- **2023-09-15:** Reports suggest ongoing research into genetic factors influencing longevity.
- **2023-07-10:** New studies published on the impact of diet and exercise on aging.

### 4) Resolution Criteria Traps & Fine-Print Gotchas
- Resolution based on Guinness World Records as of January 1, 2100; potential delays in record verification could affect outcomes.
- If no verified oldest living person exists, a credible alternative will be used, which may introduce subjectivity.
- Lifespan projections may not account for unforeseen medical advancements or societal changes.
- Changes in record-keeping practices or criteria by Guinness World Records could alter resolution outcomes.
- The definition of "oldest living person" may vary, affecting the final determination.

### 5) Disconfirming Evidence (Steelman)
- Historical data shows that while lifespans have increased, no one has lived beyond 122 years, suggesting a biological limit.
- Recent studies indicate that aging is a complex process that may not be easily altered by current medical interventions.
- Skepticism exists regarding the feasibility of achieving lifespans beyond 125 years, as many experts highlight the challenges of aging.
- Past predictions about significant increases in lifespan have often been overly optimistic and unfulfilled.
- The lack of verified cases of individuals living beyond 122 years raises doubts about future breakthroughs in longevity.

# FORECASTS

## R1: Forecaster 1 Reasoning
To forecast the age of the oldest living person in 2100, we need to consider historical data, current trends, and potential future advancements. The current verified maximum lifespan is 122 years, and the oldest living person is 115 years. While there are potential drivers for change, such as advances in biotechnology and genetics, historical data and expert consensus suggest only modest increases in lifespan records by 2100.

### Numeric Forecast Percentiles
- **1st percentile:** 120 years
- **10th percentile:** 123 years
- **25th percentile:** 125 years
- **50th percentile:** 127 years
- **75th percentile:** 130 years
- **90th percentile:** 133 years
- **99th percentile:** 137 years

### Bayesian Block
- **Base Rate:** Current maximum verified lifespan is 122 years.
- **Likelihoods:** 
- Modest increase in maximum lifespan due to medical and technological advancements.
- Historical trends showing gradual increases in lifespan.
- **Parametric Proposal:**
- <family>Lognormal</family>
- <params>meanlog: 4.85, sdlog: 0.05</params>

This forecast accounts for the potential for modest increases in lifespan due to advancements in health and technology, while also considering the historical constraints and biological limits observed so far.


## R1: Forecaster 2 Reasoning
To forecast the age of the oldest living person in 2100, we need to consider the historical data, current trends, and potential future advancements. The current verified maximum lifespan is 122 years, and the oldest living person as of 2025 is 115 years old. While there are potential drivers for change, such as advances in biotechnology and genetics, the historical trend shows a gradual increase in maximum lifespan without significant breakthroughs.

### Numeric Forecast (Percentiles)
- 1st percentile: 115 years
- 10th percentile: 120 years
- 25th percentile: 123 years
- 50th percentile: 126 years
- 75th percentile: 130 years
- 90th percentile: 135 years
- 99th percentile: 140 years

### BAYESIAN Block
- **Base Rate**: The current verified maximum lifespan is 122 years.
- **Likelihoods**:
- Gradual increase in lifespan records suggests a modest increase by 2100.
- Advances in biotechnology and genetics could lead to breakthroughs, but historical data shows no verified cases beyond 122 years.
- **Parametric Proposal**:
```xml
<family>lognormal</family>
<params>mu=4.8, sigma=0.1</params>
```

This forecast considers the historical base rate and the potential for future advancements, while also acknowledging the biological and societal constraints on human lifespan. The percentiles reflect a cautious optimism about future increases in the maximum lifespan, with the median (50th percentile) suggesting a modest increase to 126 years by 2100.


## R1: Forecaster 3 Reasoning
### Numeric Forecast Percentiles

1st percentile: 115 years  
10th percentile: 118 years  
25th percentile: 120 years  
50th percentile: 123 years  
75th percentile: 126 years  
90th percentile: 130 years  
99th percentile: 135 years  

### Bayesian Block

- **Base Rate:**  
The current verified maximum lifespan is 122 years, with no verified cases exceeding this age. Historical trends suggest a gradual increase in lifespan, with community forecasts and expert consensus indicating a modest increase by 2100.

- **Likelihoods:**  
- **Status Quo Forces:** Biological aging processes remain largely unchanged, and current medical advancements have not yet led to significant breakthroughs in lifespan extension.
- **Change Drivers:** Advances in biotechnology and genetics, along with increased focus on healthspan and longevity research, could enhance human longevity. Societal shifts towards healthier lifestyles and preventive medicine may also contribute.

- **Parametric Proposal:**  
<family>Lognormal</family>  
<params>meanlog = 4.8, sdlog = 0.1</params>  

This lognormal distribution reflects a modest increase in the maximum lifespan, with a median slightly above the current maximum of 122 years, accounting for potential advancements in medical and genetic research while recognizing the historical stability of maximum lifespan records.


## R1: Forecaster 4 Reasoning
To forecast the age of the oldest living person in 2100, we need to consider both historical data and potential future developments in medicine and longevity research. The current verified maximum lifespan is 122 years, and there is a consensus that modest increases in lifespan records are possible by 2100. However, significant breakthroughs have not yet been realized, and biological aging processes remain largely unchanged.

### Percentile Forecast
- **1st percentile:** 115 years
- **10th percentile:** 120 years
- **25th percentile:** 123 years
- **50th percentile:** 125 years
- **75th percentile:** 128 years
- **90th percentile:** 130 years
- **99th percentile:** 135 years

### Bayesian Block
- **<base_rate>:** 122 years (current maximum verified lifespan)
- **<likelihoods>:**
- Incremental increases due to medical and technological advancements
- Potential breakthroughs in biotechnology and genetics
- Societal shifts towards healthier lifestyles
- **<family>lognormal</family>**
- **<params>meanlog = 4.8, sdlog = 0.05</params>**

This forecast assumes a gradual increase in the maximum lifespan, with the possibility of reaching up to 135 years by 2100 due to advancements in medicine and technology. The lognormal distribution is chosen to reflect the skewness towards higher ages while acknowledging the biological constraints and historical data.


## R1: Forecaster 5 Reasoning
### Numeric Forecast Percentiles
- 1st percentile: 115 years
- 10th percentile: 118 years
- 25th percentile: 120 years
- 50th percentile: 123 years
- 75th percentile: 126 years
- 90th percentile: 129 years
- 99th percentile: 135 years

### Bayesian Block
- **Base Rate:** 
- Current verified maximum lifespan: 122 years (Jeanne Calment)
- Current oldest living person: 115 years (Ethel Caterham, as of April 30, 2025)

- **Likelihoods:**
- Advances in biotechnology and genetics could extend lifespan modestly.
- Historical data shows gradual increases but no breakthroughs beyond 122 years.
- Expert consensus suggests modest increases in lifespan records by 2100.

- **Parametric Proposal:**
- <family>Lognormal</family>
- <params>meanlog = 4.8, sdlog = 0.05</params>

### Rationale
The forecast reflects a modest increase in the maximum lifespan, considering both the historical base rate and potential advancements in medical science and biotechnology. The lognormal distribution is chosen to model the skewed nature of longevity data, where most individuals do not reach extreme ages, but a small number might. The percentiles reflect a conservative approach, acknowledging both the status quo and potential for change.

------------------------------------------------------------

‚ùì Question: Before 2030, how many new AI labs will be leading labs within 2 years of their founding?
üîó URL: https://www.metaculus.com/questions/22427

üìù Full Reasoning:
# SUMMARY
*Question*: Before 2030, how many new AI labs will be leading labs within 2 years of their founding?
*Final Prediction*: 
- 0 or 1: 66.0%
- 2 or 3: 22.0%
- 4 or 5: 7.2%
- 6 or 7: 3.0%
- 8 or 9: 1.1%
- 10 or more: 0.7%

*Total Cost*: $0.0446
*Time Spent*: 1.9 minutes


## Report 1 Summary
### Forecasts
*Forecaster 1*: 
- 0 or 1: 70.0%
- 2 or 3: 20.0%
- 4 or 5: 6.0%
- 6 or 7: 3.0%
- 8 or 9: 1.0%
- 10 or more: 0.0%

*Forecaster 2*: 
- 0 or 1: 60.0%
- 2 or 3: 25.0%
- 4 or 5: 10.0%
- 6 or 7: 3.0%
- 8 or 9: 1.0%
- 10 or more: 1.0%

*Forecaster 3*: 
- 0 or 1: 60.0%
- 2 or 3: 25.0%
- 4 or 5: 10.0%
- 6 or 7: 3.0%
- 8 or 9: 1.5%
- 10 or more: 0.5%

*Forecaster 4*: 
- 0 or 1: 70.0%
- 2 or 3: 20.0%
- 4 or 5: 5.0%
- 6 or 7: 3.0%
- 8 or 9: 1.0%
- 10 or more: 1.0%

*Forecaster 5*: 
- 0 or 1: 70.0%
- 2 or 3: 20.0%
- 4 or 5: 5.0%
- 6 or 7: 3.0%
- 8 or 9: 1.0%
- 10 or more: 1.0%



### Research Summary
The research examines the landscape of AI labs and the factors influencing the emergence of new leaders in the field before 2030. It identifies the top AI labs as of August 2025, which include Google (DeepMind), OpenAI, Anthropic, Cohere, and Mistral AI. Notably, no labs founded after April 2024 have made it into the top five within two years of their establishment, indicating a historical trend where established players dominate the AI sector, making it challenging for new entrants to ascend rapidly.

The study outlines the forces at play, distinguishing between status quo forces that create high barriers to entry‚Äîsuch as the need for high-quality models, substantial compute resources, and talent acquisition‚Äîand change drivers that could allow new labs to innovate or disrupt the market. Despite some speculation about the potential of emerging labs, expert commentary as of August 2025 suggests a low likelihood of new entrants breaking into the top five soon. The research also highlights the importance of defining criteria for what constitutes a "top lab" and acknowledges that while there is potential for new labs to leverage unique technologies or market shifts, such occurrences are rare in the AI domain.

Sources used: 
- Chatbot Arena ELO
- Expert commentary (August 2025)


# RESEARCH
## Report 1 Research
### 1) Base Rates & Reference Class
- Top AI labs as of August 2025: Google (DeepMind), OpenAI, Anthropic, Cohere, Mistral AI.
- No new labs founded after April 2024 have entered the top five within two years.
- Historical trend: Established players dominate the AI landscape, making rapid ascension for new entrants rare.

### 2) Status Quo Forces vs Change Drivers
- **Status Quo Forces:**
- High barriers to entry: Model quality, compute resources, and talent acquisition are critical.
- Consolidation around well-funded organizations limits competition.
- **Change Drivers:**
- Potential for new entrants to innovate or disrupt existing models.
- Market speculation about emerging labs, though current sentiment remains skeptical.

### 3) Most Recent Credible Updates WITH DATES (YYYY-MM-DD)
- August 2025: Current top AI labs confirmed by leaderboards and prediction markets.
- April 2024: Last new lab founded before the cutoff; Mistral AI was noted as a recent leader.
- August 2025: Expert commentary suggests low likelihood of new labs entering the top five soon.

### 4) Resolution Criteria Traps & Fine-Print Gotchas
- Definition of "top 5 lab" is based on Chatbot Arena ELO, which may change over time.
- The two-year timeframe is strict; labs must be evaluated based on their founding date.
- Speculation about new entrants does not equate to actual performance or ranking.

### 5) Disconfirming Evidence (Steelman)
- New labs could potentially leverage unique technologies or partnerships to accelerate growth.
- Unforeseen market shifts or breakthroughs in AI could enable a rapid rise of a new contender.
- Historical examples exist where new entrants have disrupted established markets, though rare in AI.

# FORECASTS

## R1: Forecaster 1 Reasoning
To forecast how many new AI labs will become leading labs within two years of their founding by 2030, we need to consider several factors:

### Base Rate Analysis
- Historically, the top AI labs have been dominated by established players like Google, OpenAI, and others.
- No new labs founded after April 2024 have entered the top five within two years, suggesting a low base rate for rapid ascension.

### Status Quo Forces vs Change Drivers
- **Status Quo Forces:** High barriers to entry, such as the need for significant compute resources and talent, favor established labs.
- **Change Drivers:** Potential for innovation or disruption exists, but current market sentiment and expert commentary suggest skepticism about new entrants quickly becoming leaders.

### Recent Updates
- As of August 2025, no new labs have entered the top five, and expert commentary indicates a low likelihood of this changing soon.

### Disconfirming Evidence
- While rare, there is a possibility that new labs could leverage unique technologies or partnerships to rise quickly.
- Unforeseen breakthroughs in AI could enable a new lab to become a leader rapidly.

### Bayesian Analysis
Given the base rate and current evidence, the probability of a new AI lab becoming a leading lab within two years of its founding by 2030 is low. However, we should account for the small chance of disruptive innovation.

1. **'0 or 1':** High probability due to historical trends and current expert sentiment.
2. **'2 or 3':** Possible but less likely; would require significant disruption or innovation.
3. **'4 or 5':** Unlikely given current market dynamics and barriers to entry.
4. **'6 or 7':** Very unlikely; would require multiple disruptions or breakthroughs.
5. **'8 or 9':** Extremely unlikely; unprecedented in the current AI landscape.
6. **'10 or more':** Almost impossible; would require a complete shift in the AI industry.

### Ranked List with Probabilities
1. **'0 or 1':** 70%
2. **'2 or 3':** 20%
3. **'4 or 5':** 6%
4. **'6 or 7':** 3%
5. **'8 or 9':** 1%
6. **'10 or more':** 0%

### Machine-Readable Output
```
'0 or 1': 70%
'2 or 3': 20%
'4 or 5': 6%
'6 or 7': 3%
'8 or 9': 1%
'10 or more': 0%
```


## R1: Forecaster 2 Reasoning
To forecast the number of new AI labs that will become leading labs within 2 years of their founding by 2030, we need to consider the base rates, the forces maintaining the status quo, potential change drivers, and any recent credible updates.

### Analysis

1. **Base Rates & Reference Class**:
- Historically, the top AI labs have been dominated by a few established players.
- No new labs founded after April 2024 have entered the top five within two years, indicating a low base rate for rapid ascension.

2. **Status Quo Forces vs Change Drivers**:
- **Status Quo Forces**: High barriers to entry, such as the need for substantial compute resources, talent, and model quality, favor established labs.
- **Change Drivers**: While there is potential for innovation and disruption, the current sentiment and expert commentary suggest skepticism about new entrants quickly reaching the top.

3. **Recent Credible Updates**:
- As of August 2025, the top AI labs remain unchanged, with no new entrants since April 2024.
- Expert commentary in August 2025 indicates a low likelihood of new labs entering the top five soon.

4. **Resolution Criteria Traps & Fine-Print Gotchas**:
- The definition of a "top 5 lab" is based on Chatbot Arena ELO, which could change, but the two-year timeframe is strict.

5. **Disconfirming Evidence**:
- While there is potential for new labs to leverage unique technologies or partnerships, historical trends in AI suggest this is rare.

### Bayesian Checklist

- **Base Rate Probability**: Given the historical trend and current status, the base rate for new labs becoming leading within two years is low.
- **Likelihoods**:
- Current trends and expert opinions suggest a low likelihood of rapid ascension for new labs.
- **Bayesian Posterior**: The combination of low base rates and current expert opinion leads to a low probability of many new labs becoming leading within two years.

### Ranked List with Probabilities

1. **'0 or 1'**: 60%
- Given the high barriers to entry and historical dominance by established players, it's most likely that very few, if any, new labs will become leading within two years.

2. **'2 or 3'**: 25%
- While less likely, there is a possibility that a couple of new labs could leverage unique advantages to ascend rapidly.

3. **'4 or 5'**: 10%
- This scenario is unlikely given the current market dynamics and historical trends.

4. **'6 or 7'**: 3%
- Highly unlikely without significant market disruption or breakthroughs.

5. **'8 or 9'**: 1%
- Extremely unlikely given the current state of the AI landscape.

6. **'10 or more'**: 1%
- This scenario would require unprecedented changes in the AI industry.

### Machine-Parseable Section

```
'0 or 1': 60%
'2 or 3': 25%
'4 or 5': 10%
'6 or 7': 3%
'8 or 9': 1%
'10 or more': 1%
```


## R1: Forecaster 3 Reasoning
To forecast the number of new AI labs that will become leading labs within two years of their founding before 2030, we need to consider the base rates, status quo forces, change drivers, and any recent credible updates.

### Bayesian Analysis

#### Base Rates
- Historically, the top AI labs have been dominated by a few established players. No new labs founded after April 2024 have entered the top five within two years.
- The base rate for new labs becoming leading labs is low, given the high barriers to entry and the dominance of established players.

#### Likelihoods
- **0 or 1**: High likelihood due to historical trends and current expert sentiment suggesting low probability of rapid ascension for new entrants.
- **2 or 3**: Moderate likelihood if a few new labs manage to leverage unique technologies or partnerships.
- **4 or 5**: Low likelihood given the current market dynamics and high barriers to entry.
- **6 or 7**: Very low likelihood due to the significant challenges new labs would face in becoming leading labs.
- **8 or 9**: Extremely low likelihood as it would require a major shift in the AI landscape.
- **10 or more**: Near-zero likelihood given the current trends and historical data.

#### Posterior Probabilities
- **0 or 1**: Given the base rate and current trends, this remains the most probable outcome.
- **2 or 3**: Possible but less likely than 0 or 1 due to the high barriers to entry.
- **4 or 5**: Unlikely given the current dominance of established players.
- **6 or 7**: Highly unlikely due to the need for significant disruption.
- **8 or 9**: Extremely unlikely without a major shift in the AI landscape.
- **10 or more**: Near-zero probability given the historical and current context.

### Ranked List with Probabilities
1. **0 or 1**: 60%
2. **2 or 3**: 25%
3. **4 or 5**: 10%
4. **6 or 7**: 3%
5. **8 or 9**: 1.5%
6. **10 or more**: 0.5%

### Machine-Parseable Section
- 0 or 1: 60%
- 2 or 3: 25%
- 4 or 5: 10%
- 6 or 7: 3%
- 8 or 9: 1.5%
- 10 or more: 0.5%


## R1: Forecaster 4 Reasoning
To forecast how many new AI labs will become leading labs within two years of their founding before 2030, we need to consider the historical trends, current market dynamics, and potential for disruption in the AI landscape.

### Bayesian Analysis

1. **Base Rate**: Historically, the AI landscape has been dominated by established players. Since April 2024, no new labs have entered the top five within two years of their founding. This suggests a low base rate for new entrants achieving this status quickly.

2. **Likelihoods**:
- **0 or 1**: Given the high barriers to entry and the dominance of established labs, this is the most likely scenario. The historical trend supports this, with no new labs achieving top-five status within two years recently.
- **2 or 3**: While possible, this would require significant innovation or disruption, which is not currently evident in the market.
- **4 or 5**: Unlikely given the current market conditions and historical trends.
- **6 or 7**: Very unlikely without a major shift in the AI landscape or a breakthrough technology.
- **8 or 9**: Extremely unlikely as it would require a complete overhaul of the current competitive dynamics.
- **10 or more**: Practically impossible within the given timeframe and market conditions.

3. **Bayesian Posterior**:
- Given the base rate and likelihoods, the posterior probabilities heavily favor the "0 or 1" option.

### Ranked List with Probabilities

1. **0 or 1**: 70%
2. **2 or 3**: 20%
3. **4 or 5**: 5%
4. **6 or 7**: 3%
5. **8 or 9**: 1%
6. **10 or more**: 1%

### Machine-Parseable Section

```plaintext
0 or 1: 70%
2 or 3: 20%
4 or 5: 5%
6 or 7: 3%
8 or 9: 1%
10 or more: 1%
```


## R1: Forecaster 5 Reasoning
### Bayesian Analysis

#### Base Rates & Reference Class
- Historically, the top AI labs have been dominated by established players, with few new entrants breaking into the top five within two years of their founding. Given this, the base rate for new labs becoming leading labs within two years is low.

#### Likelihoods
- **Status Quo Forces:** The high barriers to entry and consolidation around well-funded organizations suggest that the likelihood of new labs becoming leading labs is low.
- **Change Drivers:** While there is potential for innovation and disruption, the current sentiment and expert commentary suggest skepticism about new entrants quickly ascending to the top.

#### Bayesian Update
- Given the base rate and the current evidence, the probability of 0 or 1 new labs becoming leading labs is high. The likelihood of more than 1 new lab achieving this status decreases significantly.

### Ranked List with Probabilities
1. **'0 or 1'**: 70%
- The base rate and current evidence strongly suggest that few, if any, new labs will become leading labs within two years of their founding.
2. **'2 or 3'**: 20%
- While possible, the barriers to entry and current market dynamics make this less likely.
3. **'4 or 5'**: 5%
- This would require significant disruption or innovation, which is not currently anticipated.
4. **'6 or 7'**: 3%
- Highly unlikely given the current landscape and historical trends.
5. **'8 or 9'**: 1%
- Extremely unlikely without major unforeseen changes in the AI industry.
6. **'10 or more'**: 1%
- Almost impossible under current conditions and historical precedents.

### Machine-Readable Output
```
'0 or 1': 70%
'2 or 3': 20%
'4 or 5': 5%
'6 or 7': 3%
'8 or 9': 1%
'10 or more': 1%
```

------------------------------------------------------------

‚ùì Question: How many major US labor strikes with generative AI as one of their main reasons will start in 2029?
üîó URL: https://www.metaculus.com/questions/38880

üìù Full Reasoning:
# SUMMARY
*Question*: How many major US labor strikes with generative AI as one of their main reasons will start in 2029?
*Final Prediction*: Probability distribution:
- 0.00% chance of value below -0.5
- 5.50% chance of value below 0.5
- 17.50% chance of value below 1.5
- 37.50% chance of value below 2.5
- 56.25% chance of value below 3.5
- 68.75% chance of value below 4.5
- 78.75% chance of value below 5.5
- 86.25% chance of value below 6.5
- 91.50% chance of value below 7.5

*Total Cost*: $0.0391
*Time Spent*: 2.59 minutes


## Report 1 Summary
### Forecasts
*Forecaster 1*: Probability distribution:
- 1.00% chance of value below 0.0
- 10.00% chance of value below 1.0
- 25.00% chance of value below 2.0
- 50.00% chance of value below 3.0
- 75.00% chance of value below 5.0
- 90.00% chance of value below 7.0
- 99.00% chance of value below 10.0

*Forecaster 2*: Probability distribution:
- 1.00% chance of value below 0.0
- 10.00% chance of value below 1.0
- 25.00% chance of value below 2.0
- 50.00% chance of value below 3.0
- 75.00% chance of value below 5.0
- 90.00% chance of value below 7.0
- 99.00% chance of value below 10.0

*Forecaster 3*: Probability distribution:
- 1.00% chance of value below 0.0
- 10.00% chance of value below 1.0
- 25.00% chance of value below 2.0
- 50.00% chance of value below 3.0
- 75.00% chance of value below 5.0
- 90.00% chance of value below 7.0
- 99.00% chance of value below 10.0

*Forecaster 4*: Probability distribution:
- 1.00% chance of value below 0.0
- 10.00% chance of value below 1.0
- 25.00% chance of value below 2.0
- 50.00% chance of value below 3.0
- 75.00% chance of value below 5.0
- 90.00% chance of value below 6.0
- 99.00% chance of value below 8.0

*Forecaster 5*: Probability distribution:
- 1.00% chance of value below 0.0
- 10.00% chance of value below 1.0
- 25.00% chance of value below 2.0
- 50.00% chance of value below 3.0
- 75.00% chance of value below 5.0
- 90.00% chance of value below 7.0
- 99.00% chance of value below 10.0



### Research Summary
The research examines the potential for major labor strikes in the U.S. in 2029, specifically focusing on generative AI as a central issue. It begins by analyzing historical strike data, noting a significant increase in labor actions in 2023, with 470 strikes involving 539,000 workers. The Bureau of Labor Statistics (BLS) records only major strikes with 1,000 or more workers, and recent strikes, particularly in the entertainment sector, have begun to highlight generative AI as a key concern. The SAG-AFTRA video game strike in 2024 is cited as a precedent that may influence future labor actions related to AI, suggesting that as AI adoption grows, the likelihood of strikes across various sectors may increase.

The research also discusses the dynamics between status quo forces and change drivers. While traditional labor relations and existing contracts may resist rapid changes related to AI, there is a rising awareness of job displacement risks and increased union activism that could drive strikes over modern issues. However, limitations such as the BLS's criteria for counting strikes, the necessity for generative AI to be a primary demand, and the absence of data for 2029 make predictions uncertain. Additionally, skepticism regarding the actual impact of generative AI on jobs, historical resistance to change within labor movements, and broader economic factors could influence the frequency and focus of future strikes.

Sources used in the research include:
- SAG-AFTRA: [sagaftra.org](https://www.sagaftra.org/contracts-industry-resources/contracts/interactive-media-video-game-strike)
- Labor Action Tracker: [gjopen.com](https://www.gjopen.com/questions/3792-how-many-workers-in-the-us-will-be-involved-in-any-work-stoppages-in-2025-according-to-the-labor-action-tracker-lat)
- Bureau of Labor Statistics: [bls.gov](https://www.bls.gov/wsp/factsheets/different-ways-to-measure-a-stoppage.htm)


# RESEARCH
## Report 1 Research
### 1) Base Rates & Reference Class
- **Historical Strike Data:** In 2023, 470 work stoppages involved 539,000 workers; a significant increase from 2022.
- **BLS Criteria:** Only major strikes (1,000+ workers) are recorded by the Bureau of Labor Statistics.
- **Generative AI Focus:** Recent strikes, particularly in entertainment, have begun to include generative AI as a central issue.
- **Precedent for Future Strikes:** The SAG-AFTRA video game strike in 2024 serves as a reference for potential future strikes involving generative AI.
- **Potential Growth:** As AI adoption increases, the likelihood of strikes in various sectors may rise.

### 2) Status Quo Forces vs Change Drivers
- **Status Quo Forces:**
- Traditional labor relations and existing contracts may resist rapid changes.
- Current union structures and negotiation processes may not fully address AI-related concerns.
- **Change Drivers:**
- Rising awareness and concern over job displacement due to AI.
- Increased union activism and willingness to strike over modern issues, including technology impacts.
- Legislative and regulatory pressures surrounding AI and workers' rights.

### 3) Most Recent Credible Updates WITH DATES (YYYY-MM-DD)
- **2024-10-01:** SAG-AFTRA video game strike commenced, highlighting generative AI as a key demand [[sagaftra.org](https://www.sagaftra.org/contracts-industry-resources/contracts/interactive-media-video-game-strike)].
- **2023-12-15:** Labor Action Tracker reported a total of 470 strikes in 2023, indicating a growing trend in labor actions [[gjopen.com](https://www.gjopen.com/questions/3792-how-many-workers-in-the-us-will-be-involved-in-any-work-stoppages-in-2025-according-to-the-labor-action-tracker-lat)].
- **2023-11-20:** BLS updated criteria for major work stoppages, emphasizing the need for large-scale participation [[bls.gov](https://www.bls.gov/wsp/factsheets/different-ways-to-measure-a-stoppage.htm)].

### 4) Resolution Criteria Traps & Fine-Print Gotchas
- **BLS Limitations:** Only strikes with 1,000+ workers are counted; smaller strikes may still be significant but won't be recorded.
- **Generative AI as a Primary Demand:** For a strike to qualify, generative AI must be explicitly stated as a main issue, which may not always be the case.
- **Future Data Absence:** As of mid-2025, there is no data for strikes in 2029, making predictions speculative.
- **Sector-Specific Trends:** While generative AI is currently prominent in entertainment, its relevance in other sectors may not yet be established.

### 5) Disconfirming Evidence (Steelman)
- **Skepticism on AI Impact:** Some experts argue that the actual impact of generative AI on job displacement may be overstated, leading to fewer strikes than anticipated.
- **Historical Resistance to Change:** Labor movements have historically been slow to adapt to new technologies, which may limit the urgency of AI-related strikes.
- **Economic Factors:** Broader economic conditions (e.g., recession, inflation) could overshadow AI concerns, leading to fewer strikes focused on technology.
- **Union Dynamics:** Not all unions may prioritize generative AI issues, focusing instead on traditional labor concerns, which could dilute the momentum for strikes centered on AI.

# FORECASTS

## R1: Forecaster 1 Reasoning
To forecast the number of major US labor strikes with generative AI as one of their main reasons starting in 2029, we need to consider several factors. The base rate of major strikes involving AI is currently low, but the trend is increasing, particularly in sectors like entertainment. Given the increasing adoption of AI and the precedent set by recent strikes, it's reasonable to expect some growth in AI-related labor actions.

### Percentile Forecast
- **1st percentile:** 0
- **10th percentile:** 1
- **25th percentile:** 2
- **50th percentile:** 3
- **75th percentile:** 5
- **90th percentile:** 7
- **99th percentile:** 10

### BAYESIAN Block
- **<base_rate>:** The base rate of major strikes with AI as a primary demand is currently low, but increasing.
- **<likelihoods>:** 
- Increased AI adoption and union activism raise the likelihood of AI-related strikes.
- Economic and sector-specific factors could either amplify or dampen this trend.
- **<family>lognormal</family>**
- **<params>meanlog=1.0, sdlog=0.5</params>**

This forecast reflects a moderate increase in AI-related strikes, considering both the potential for growth in AI adoption and the historical resistance to rapid change in labor movements. The lognormal distribution accounts for the skewed nature of the data, where a few high-impact strikes could occur amidst a generally low base rate.


## R1: Forecaster 2 Reasoning
To forecast the number of major US labor strikes with generative AI as one of their main reasons starting in 2029, we need to consider both historical data and potential future trends. The base rate of major strikes involving generative AI is currently low, but there is a growing trend in labor actions related to AI, particularly in the entertainment sector.

### Percentiles Forecast
- **1st percentile:** 0
- **10th percentile:** 1
- **25th percentile:** 2
- **50th percentile (median):** 3
- **75th percentile:** 5
- **90th percentile:** 7
- **99th percentile:** 10

### Bayesian Block
- **<base_rate>:** The base rate for major strikes involving generative AI is derived from recent trends in the entertainment sector, where AI has become a focal point. Given the novelty of AI-related strikes, a base rate of approximately 1-2 strikes per year in relevant sectors is reasonable.

- **<likelihoods>:** 
- **Increased AI Adoption:** As AI becomes more prevalent, the likelihood of strikes related to AI increases, particularly in sectors like entertainment, technology, and manufacturing.
- **Union Activism:** Growing union activism and awareness of AI-related issues increase the likelihood of strikes.
- **Economic Conditions:** Economic stability could either facilitate or hinder strike actions, depending on how it affects worker leverage.

- **<family>lognormal</family>**
- **<params>meanlog=1.1, sdlog=0.5</params>**

This lognormal distribution reflects a skew towards a small number of strikes, with a long tail accounting for the possibility of more widespread labor actions as AI becomes more integrated into various industries. The median of 3 strikes reflects a moderate increase from current levels, while allowing for a range of outcomes depending on the pace of AI adoption and labor responses.


## R1: Forecaster 3 Reasoning
To forecast the number of major US labor strikes with generative AI as one of their main reasons starting in 2029, we need to consider the current trends and potential future developments. Given the increasing adoption of AI and the recent strikes that have included AI-related demands, there is a reasonable expectation for some strikes to occur. However, the uncertainty around the exact number is high due to the speculative nature of future predictions and the evolving landscape of labor relations and AI technology.

### Percentile Forecast
- **1st percentile:** 0
- **10th percentile:** 1
- **25th percentile:** 2
- **50th percentile (median):** 3
- **75th percentile:** 5
- **90th percentile:** 7
- **99th percentile:** 10

### Bayesian Block
- **<base_rate>:** The base rate is informed by recent trends, such as the 2023 and 2024 strikes, and the increasing focus on AI in labor disputes. Given the historical data, a base rate of 1-2 strikes per year involving generative AI as a primary demand seems plausible.
- **<likelihoods>:** 
- **Increased AI Adoption:** Likelihood of more sectors being affected by AI, leading to more strikes.
- **Union Activism:** Likelihood of unions becoming more proactive in addressing AI-related issues.
- **Economic Conditions:** Likelihood of economic factors influencing the number of strikes.
- **<family>lognormal</family>**
- **<params>meanlog=1.2, sdlog=0.5</params>**

This forecast reflects a moderate expectation of increased labor strikes involving generative AI, with a central tendency around 3 strikes, but with considerable uncertainty allowing for a range from 0 to 10 strikes. The lognormal distribution is chosen to capture the skewness and potential for a small number of high-impact events.


## R1: Forecaster 4 Reasoning
To forecast the number of major US labor strikes with generative AI as one of their main reasons starting in 2029, we need to consider both historical data and future trends. Here's a structured approach:

### Percentile Forecast
- **1st Percentile:** 0
- **10th Percentile:** 1
- **25th Percentile:** 2
- **50th Percentile (Median):** 3
- **75th Percentile:** 5
- **90th Percentile:** 6
- **99th Percentile:** 8

### Bayesian Analysis
- **Base Rate:** Historically, the number of major strikes recorded by the BLS is relatively low, with a significant increase in 2023 but still not overwhelmingly high.
- **Likelihoods:**
- **Increase in AI Adoption:** As AI becomes more prevalent, the likelihood of AI-related strikes increases.
- **Sector-Specific Trends:** Entertainment and tech sectors are more likely to experience AI-related strikes.
- **Union Activism:** Growing union activism around modern issues, including AI, suggests a higher likelihood of strikes.
- **Disconfirming Evidence:**
- **Economic Conditions:** Broader economic issues might overshadow AI concerns.
- **Resistance to Change:** Historical resistance to new technologies could slow the pace of AI-related strikes.

### Parametric Proposal
```xml
<family>lognormal</family>
<params>mu=1.1, sigma=0.5</params>
```

This lognormal distribution reflects the potential for a few strikes, with a long tail suggesting the possibility of more strikes if AI-related concerns become more prominent across various sectors. The median value of 3 reflects a moderate expectation, given the current trends and historical data.


## R1: Forecaster 5 Reasoning
To forecast the number of major US labor strikes with generative AI as one of their main reasons in 2029, we need to consider both historical data and potential future trends. Here's a structured approach:

### Percentile Forecast
- **1st Percentile:** 0
- **10th Percentile:** 1
- **25th Percentile:** 2
- **50th Percentile:** 3
- **75th Percentile:** 5
- **90th Percentile:** 7
- **99th Percentile:** 10

### Bayesian Analysis
- **Base Rate:** Given the recent increase in strikes and the specific focus on AI in some sectors, a base rate of 1-2 strikes per year involving AI as a primary demand seems reasonable for the near future. However, this is speculative for 2029.

- **Likelihoods:**
- **Increased AI Adoption:** Likelihood of more strikes increases as AI becomes more prevalent in various industries.
- **Union Activism:** Likelihood increases with growing union activism around modern issues.
- **Economic Conditions:** Economic downturns could either increase strikes due to job insecurity or decrease them due to fear of job loss.

- **Parametric Proposal:**
```xml
<family>lognormal</family>
<params>meanlog=1.0, sdlog=0.5</params>
```

This proposal reflects the skewed nature of the potential outcomes, with a higher probability of a small number of strikes but a long tail allowing for the possibility of more if conditions align. The lognormal distribution is chosen to capture the asymmetric nature of the forecast, where a few strikes are more likely, but a larger number is possible under certain conditions.

------------------------------------------------------------

