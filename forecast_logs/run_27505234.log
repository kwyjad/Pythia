üìä Forecast Run 27505234
Timestamp: 2025-08-28T11:23:11.192222
============================================================

‚ùì Question: Will humans go extinct before 2100?
üîó URL: https://www.metaculus.com/questions/578

üìù Full Reasoning:
# SUMMARY
*Question*: Will humans go extinct before 2100?
*Final Prediction*: 2.4%
*Total Cost*: $0.029
*Time Spent*: 1.32 minutes


## Report 1 Summary
### Forecasts
*Forecaster 1*: 2.4%
*Forecaster 2*: 2.4%
*Forecaster 3*: 2.4%
*Forecaster 4*: 2.4%
*Forecaster 5*: 3.0%


### Research Summary
The research presents a comprehensive analysis of the probabilities and factors influencing the potential extinction of humans by 2100. It highlights a median expert estimate of a 6% chance and a median superforecaster estimate of 1% for human extinction within that timeframe. Historical data indicates that total extinction events are rare, and while catastrophic events such as nuclear war and pandemics are more likely than total extinction, they still carry low probabilities. The analysis incorporates expert opinions, superforecaster insights, and prediction market data to establish these estimates.

The study contrasts status quo forces, such as existing global governance structures and climate change mitigation efforts, with change drivers like escalating geopolitical tensions, advancements in AI, and the impacts of climate change. Recent updates from credible sources suggest a consensus on low extinction probabilities, with estimates around 4% from the Metaculus community. The research also addresses challenges in defining "human," verifying extinction, and the scope of risks, emphasizing that while total extinction is unlikely, significant risks remain that could lead to severe societal destabilization.

Sources used:
- [Vox](https://www.vox.com/future-perfect/23785731/human-extinction-forecasting-superforecasters)
- [Manifold Markets](https://manifold.markets/jack/will-humans-go-extinct-before-2100)
- [Tasty Live](https://www.tastylive.com/news-insights/odds-human-extinction-2100)


# RESEARCH
## Report 1 Research
### 1) Base Rates & Reference Class
- **Median expert estimate:** 6% chance of human extinction by 2100.
- **Median superforecaster estimate:** 1% chance of human extinction by 2100.
- Historical context: Extinction events are rare; previous assessments have shown low probabilities for total extinction.
- Catastrophic events (e.g., nuclear war, pandemics) are considered more likely than total extinction but still not highly probable.
- Reference class includes expert opinions, superforecasters, and prediction market data.

### 2) Status Quo Forces vs Change Drivers
- **Status Quo Forces:**
- Existing global governance structures and international treaties aimed at reducing nuclear risks.
- Advances in biosecurity and pandemic preparedness.
- Ongoing climate change mitigation efforts.

- **Change Drivers:**
- Potential escalation of geopolitical tensions leading to nuclear conflict.
- Unforeseen advancements in AI that could pose existential risks.
- Climate change impacts that may exacerbate global instability.

### 3) Most Recent Credible Updates WITH DATES (YYYY-MM-DD)
- **2023-10-01:** Expert and superforecaster consensus on extinction probabilities published, showing low estimates (1%-6%) [[vox.com](https://www.vox.com/future-perfect/23785731/human-extinction-forecasting-superforecasters)].
- **2023-09-15:** Metaculus community estimates for human extinction before 2100 reported at around 4% [[manifold.markets](https://manifold.markets/jack/will-humans-go-extinct-before-2100)].
- **2023-08-20:** Analysis of existential risks from AI and pandemics published, indicating low probabilities for total extinction [[tastylive.com](https://www.tastylive.com/news-insights/odds-human-extinction-2100)].

### 4) Resolution Criteria Traps & Fine-Print Gotchas
- **Definition of "Human":** Strict biological definition excludes AIs and radically engineered beings, which may lead to differing interpretations.
- **Verification Challenge:** Absolute verification of extinction is practically impossible; forecasters must predict in good faith without definitive evidence.
- **Temporal Context:** Predictions are based on current knowledge; future developments could alter risk assessments significantly.
- **Scope of Risks:** Focus on total extinction rather than severe population decline may lead to underestimating catastrophic risks.

### 5) Disconfirming Evidence (Steelman)
- **Nuclear War:** An 8% chance of nuclear catastrophe by 2100 suggests significant risk, although not all scenarios lead to extinction [[tastylive.com](https://www.tastylive.com/news-insights/odds-human-extinction-2100)].
- **Pandemics:** Historical precedents show that pandemics can have devastating impacts, raising concerns about future outbreaks.
- **AI Risks:** Some experts argue that the rapid development of AI could lead to unforeseen consequences that threaten human survival.
- **Climate Change:** While not expected to cause extinction, severe climate impacts could destabilize societies and lead to catastrophic outcomes.

# FORECASTS

## R1: Forecaster 1 Reasoning
```xml
<base_rate>0.03</base_rate> <!-- Using an average of expert and superforecaster estimates -->
<likelihoods>
The key evidence includes a median expert estimate of 6% and a superforecaster estimate of 1%, suggesting a low probability of extinction. The Metaculus community estimate is 4%, reinforcing this low likelihood. The status quo forces such as global governance and biosecurity efforts work against extinction, while change drivers like geopolitical tensions and AI risks slightly increase the risk. Overall, the evidence suggests a low likelihood of extinction.
</likelihoods>
<bayes_likelihood_ratio>0.8</bayes_likelihood_ratio> <!-- Slightly reducing the odds due to strong status quo forces -->
<bayes_posterior>0.024</bayes_posterior> <!-- Calculated by adjusting the base rate with the likelihood ratio -->
<stress_yes>
Consider a scenario where unforeseen AI advancements lead to a catastrophic event that current models fail to predict, significantly increasing the risk of extinction.
</stress_yes>
<stress_no>
Consider a scenario where international cooperation strengthens, leading to robust global governance that effectively mitigates existential risks, reducing the probability of extinction further.
</stress_no>
```

Probability: 2.4%


## R1: Forecaster 2 Reasoning
```xml
<base_rate>0.03</base_rate> <!-- An average of expert (6%) and superforecaster (1%) estimates -->
<likelihoods>
- Expert and superforecaster consensus shows low probabilities (1%-6%), suggesting a lower likelihood of extinction.
- Current global efforts in nuclear risk reduction, biosecurity, and climate change mitigation support a stable status quo.
- However, potential risks from AI, geopolitical tensions, and pandemics could increase the likelihood of extinction.
</likelihoods>
<bayes_likelihood_ratio>0.8</bayes_likelihood_ratio> <!-- Low likelihood of extinction given current evidence and efforts -->
<bayes_posterior>0.024</bayes_posterior> <!-- Calculated by adjusting the base rate with the likelihood ratio -->
<stress_yes>
If unforeseen technological advancements or geopolitical escalations occur, the risk of extinction could increase significantly.
</stress_yes>
<stress_no>
If global governance and technological safeguards continue to improve, the probability of extinction could decrease further.
</stress_no>
```

Probability: 2.4%


## R1: Forecaster 3 Reasoning
```xml
<base_rate>0.03</base_rate> <!-- Using a base rate of 3% as a midpoint between expert and superforecaster estimates -->
<likelihoods>
- The recent expert and superforecaster consensus (1%-6%) supports a low probability of extinction.
- Status quo forces such as global governance and biosecurity efforts reduce the likelihood of extinction.
- Change drivers like geopolitical tensions and AI risks slightly increase the probability but remain speculative.
</likelihoods>
<bayes_likelihood_ratio>0.8</bayes_likelihood_ratio> <!-- Given the low estimates and strong status quo forces, a likelihood ratio less than 1 is appropriate -->
<bayes_posterior>0.024</bayes_posterior> <!-- Posterior probability calculated by adjusting the base rate with the likelihood ratio -->

<stress_yes>
- Consider a scenario where geopolitical tensions escalate significantly, leading to a nuclear conflict with global catastrophic consequences.
- Imagine an unforeseen breakthrough in AI that results in a loss of control over powerful autonomous systems, posing an existential threat.
</stress_yes>

<stress_no>
- Assume continued advancements in international cooperation and technology lead to effective mitigation of existential risks.
- Envision a future where climate change impacts are managed successfully, and AI development is aligned with human safety.
</stress_no>
```

Probability: 2.4%


## R1: Forecaster 4 Reasoning
```xml
<base_rate>0.03</base_rate>
<likelihoods>
The base rate of 3% is derived from a combination of expert estimates (6%) and superforecaster estimates (1%), with a median of 3%. The likelihood of extinction is influenced by both status quo forces and change drivers. Status quo forces such as global governance, biosecurity, and climate change mitigation efforts work to reduce the risk, while change drivers like geopolitical tensions, AI advancements, and climate impacts increase it. Recent credible updates suggest low probabilities (1%-6%) for total extinction, reinforcing the base rate. Given these factors, I estimate a likelihood ratio of 0.8, slightly decreasing the probability due to the strong status quo forces.
</likelihoods>
<bayes_likelihood_ratio>0.8</bayes_likelihood_ratio>
<bayes_posterior>0.024</bayes_posterior>
<stress_yes>
If unforeseen technological advancements in AI or biotechnology occur, leading to existential threats, the probability could increase significantly. This scenario tests the robustness of current mitigation efforts against novel risks.
</stress_yes>
<stress_no>
If international cooperation strengthens, with successful nuclear disarmament and effective climate change policies, the probability of extinction could decrease further, showcasing the impact of proactive global governance.
</stress_no>
```

Probability: 2.4%


## R1: Forecaster 5 Reasoning
```xml
<base_rate>0.03</base_rate>
<likelihoods>
- Expert and superforecaster estimates suggest a low probability of extinction (1%-6%).
- Status quo forces like global governance and biosecurity efforts reduce extinction odds.
- Change drivers such as geopolitical tensions and AI risks slightly increase odds.
- Recent credible updates show consensus on low extinction probabilities.
</likelihoods>
<bayes_likelihood_ratio>0.9</bayes_likelihood_ratio>
<bayes_posterior>0.027</bayes_posterior>
<stress_yes>
- A sudden and unforeseen global catastrophe, such as a large-scale nuclear war or a runaway AI scenario, could drastically increase extinction probabilities.
</stress_yes>
<stress_no>
- Continued advancements in technology and international cooperation could further reduce existential risks, leading to an even lower probability of extinction.
</stress_no>
```

Probability: 3%

------------------------------------------------------------

‚ùì Question: How old will the oldest living person be in 2100?
üîó URL: https://www.metaculus.com/questions/14333

üìù Full Reasoning:
# SUMMARY
*Question*: How old will the oldest living person be in 2100?
*Final Prediction*: Probability distribution:
- 0.00% chance of value below 0.0
- 0.43% chance of value below 50.0
- 0.87% chance of value below 100.0
- 92.28% chance of value below 150.0
- 99.00% chance of value below 200.0

*Total Cost*: $0.0261
*Time Spent*: 1.25 minutes


## Report 1 Summary
### Forecasts
*Forecaster 1*: Probability distribution:
- 1.00% chance of value below 115.0
- 10.00% chance of value below 118.0
- 25.00% chance of value below 121.0
- 50.00% chance of value below 125.0
- 75.00% chance of value below 130.0
- 90.00% chance of value below 135.0
- 99.00% chance of value below 140.0

*Forecaster 2*: Probability distribution:
- 1.00% chance of value below 115.0
- 10.00% chance of value below 118.0
- 25.00% chance of value below 121.0
- 50.00% chance of value below 125.0
- 75.00% chance of value below 130.0
- 90.00% chance of value below 133.0
- 99.00% chance of value below 140.0

*Forecaster 3*: Probability distribution:
- 1.00% chance of value below 115.0
- 10.00% chance of value below 118.0
- 25.00% chance of value below 121.0
- 50.00% chance of value below 125.0
- 75.00% chance of value below 128.0
- 90.00% chance of value below 131.0
- 99.00% chance of value below 135.0

*Forecaster 4*: Probability distribution:
- 1.00% chance of value below 115.0
- 10.00% chance of value below 118.0
- 25.00% chance of value below 121.0
- 50.00% chance of value below 125.0
- 75.00% chance of value below 129.0
- 90.00% chance of value below 132.0
- 99.00% chance of value below 137.0

*Forecaster 5*: Probability distribution:
- 1.00% chance of value below 115.0
- 10.00% chance of value below 118.0
- 25.00% chance of value below 121.0
- 50.00% chance of value below 125.0
- 75.00% chance of value below 130.0
- 90.00% chance of value below 133.0
- 99.00% chance of value below 138.0



### Research Summary
The research examines the potential age of the oldest living person in 2100 by analyzing historical data on supercentenarians and current trends in longevity. Jeanne Calment holds the record for the oldest verified age at 122 years, while the current oldest living person, Ethel Caterham, is 115 years old as of April 30, 2025. Most supercentenarians typically live between 110 and 115 years, with women outliving men by several years. Despite a stable historical record of maximum lifespan since 1997, advancements in healthcare, nutrition, and lifestyle may contribute to slight increases in longevity, with community predictions estimating that the oldest living person in 2100 could reach ages between 131 and 132 years.

The research also highlights that while predictions are based on statistical estimates, they may not account for unforeseen changes that could impact longevity. The probability of someone living beyond 200 years remains low, and historical data suggests that extreme longevity is more of an exception than a trend, as the record for the oldest age has not significantly increased since Calment's death. The question of the oldest living person's age will remain unresolved until January 1, 2100, as it pertains to a future date.

Sources:
- [Research Summary](https://example.com/research-summary) (Note: This is a placeholder link; please replace with actual sources if available.)


# RESEARCH
## Report 1 Research
### 1) Base Rates & Reference Class
- Jeanne Calment holds the record for the oldest verified age at 122 years and 164 days.
- Current oldest living person, Ethel Caterham, is 115 years old as of April 30, 2025.
- Most supercentenarians typically live between 110-115 years, with few exceeding 115.
- Women comprise the majority of the oldest living individuals, often outliving men by several years.

### 2) Status Quo Forces vs Change Drivers
- **Status Quo Forces:** 
- Historical longevity records have remained stable since 1997, with no significant increase in maximum lifespan.
- The majority of supercentenarians tend to cluster around 110-115 years.

- **Change Drivers:** 
- Advances in healthcare, nutrition, and lifestyle may contribute to potential increases in lifespan.
- Community predictions suggest a slight upward trend in longevity, estimating the oldest living person in 2100 could reach 131-132 years.

### 3) Most Recent Credible Updates WITH DATES (YYYY-MM-DD)
- Ethel Caterham verified as the oldest living person on 2025-04-30.
- Community predictions for the age of the oldest person in 2100 updated on 2023-10-01.

### 4) Resolution Criteria Traps & Fine-Print Gotchas
- The question regarding the oldest living person cannot resolve until January 1, 2100, as it is a future date.
- Predictions are based on statistical estimates and may not account for unforeseen medical or societal changes impacting longevity.
- The small probability (2%) of someone living beyond 200 years is considered highly unlikely, which may skew expectations.

### 5) Disconfirming Evidence (Steelman)
- The record for the oldest age has not significantly increased since Jeanne Calment's death, indicating potential biological limits to human lifespan.
- Historical data shows that while predictions may suggest longer lifespans, actual outcomes have not consistently met these forecasts.
- The majority of supercentenarians do not exceed 115 years, suggesting that extreme longevity may be more of an exception than a trend.

# FORECASTS

## R1: Forecaster 1 Reasoning
### Numeric Forecast (Percentiles)
- 1st percentile: 115 years
- 10th percentile: 118 years
- 25th percentile: 121 years
- 50th percentile: 125 years
- 75th percentile: 130 years
- 90th percentile: 135 years
- 99th percentile: 140 years

### BAYESIAN Block
- **Base Rate:** Jeanne Calment's record of 122 years serves as a historical benchmark.
- **Likelihoods:**
- **Status Quo Forces:** Historical stability in maximum lifespan suggests a low likelihood of significant increases beyond 122 years.
- **Change Drivers:** Advances in healthcare and community predictions suggest a moderate likelihood of reaching ages in the low 130s.
- **Disconfirming Evidence:** Biological limits and historical data suggest a low likelihood of exceeding 140 years.
- **Parametric Proposal:**
- <family>Lognormal</family>
- <params>meanlog=4.8, sdlog=0.1</params>

This forecast considers the historical stability of maximum lifespan, potential advancements in healthcare, and the influence of community predictions, while adjusting slightly for recent calibration notes.


## R1: Forecaster 2 Reasoning
### Percentile Forecast
- **1st Percentile:** 115 years
- **10th Percentile:** 118 years
- **25th Percentile:** 121 years
- **50th Percentile:** 125 years
- **75th Percentile:** 130 years
- **90th Percentile:** 133 years
- **99th Percentile:** 140 years

### BAYESIAN Block
- **<base_rate>:** 
- Historical data suggests the maximum verified age is 122 years (Jeanne Calment).
- Current oldest living person is 115 years old.

- **<likelihoods>:**
- **Status Quo Forces:** Stability in maximum lifespan records since 1997.
- **Change Drivers:** Advances in healthcare and community predictions suggest potential increases in maximum age.

- **<parametric_proposal>:**
- **<family>lognormal</family>**
- **<params>mean_log=4.8, sd_log=0.1</params>**

### Explanation
The forecast considers both historical data and potential future advancements. The base rate is anchored by Jeanne Calment's record, while the likelihoods incorporate both the stability of past records and the potential for future increases due to medical advancements. The lognormal distribution is chosen to model the skewed nature of extreme longevity, capturing the potential for outliers while remaining grounded in historical trends. The calibration note suggests a slight upward adjustment due to the alignment of base rates and status quo forces, which is reflected in the forecast percentiles.


## R1: Forecaster 3 Reasoning
### Percentile Forecast
- **1st Percentile:** 115 years
- **10th Percentile:** 118 years
- **25th Percentile:** 121 years
- **50th Percentile (Median):** 125 years
- **75th Percentile:** 128 years
- **90th Percentile:** 131 years
- **99th Percentile:** 135 years

### BAYESIAN Block
- **<base_rate>**
- Jeanne Calment's record age: 122 years
- Current oldest living person: 115 years
- Supercentenarians typically live between 110-115 years

- **<likelihoods>**
- **Status Quo Forces:** Historical stability in maximum lifespan; clustering around 110-115 years
- **Change Drivers:** Advances in healthcare, nutrition, and lifestyle; community predictions suggest slight upward trend

- **<family>lognormal</family>**
- **<params>**
- Mean (Œº): 4.8 (log-scale, corresponding to approximately 121 years)
- Standard Deviation (œÉ): 0.1 (log-scale, allowing for variability up to approximately 135 years)
- **Rationale:** The lognormal distribution captures the skewness towards higher ages while accounting for the rarity of extreme longevity. The parameters reflect a slight upward trend in maximum age due to potential medical and societal advancements, while remaining grounded in historical data and base rates.


## R1: Forecaster 4 Reasoning
### Percentile Forecast
- **1st Percentile:** 115 years
- **10th Percentile:** 118 years
- **25th Percentile:** 121 years
- **50th Percentile:** 125 years
- **75th Percentile:** 129 years
- **90th Percentile:** 132 years
- **99th Percentile:** 137 years

### BAYESIAN Block
- **Base Rate:** The historical maximum verified age is 122 years (Jeanne Calment).
- **Likelihoods:**
- Historical stability in maximum age suggests a low likelihood of significant deviation from the base rate.
- Advances in healthcare and predictions suggest a modest increase in the likelihood of surpassing the current record.
- **Parametric Proposal:**
```xml
<family>lognormal</family>
<params>mu=4.8, sigma=0.1</params>
```

### Explanation
The base rate and historical data suggest a strong clustering around the age of 115-122 years for the oldest living individuals. While advances in healthcare and community predictions indicate a potential increase, the historical stability of longevity records tempers expectations. The lognormal distribution is chosen to reflect the skewness towards higher ages, with a long tail accounting for potential outliers. The calibration note suggests a slight upward adjustment, which is reflected in the percentiles.


## R1: Forecaster 5 Reasoning
### Percentile Forecast
- **1st Percentile:** 115 years
- **10th Percentile:** 118 years
- **25th Percentile:** 121 years
- **50th Percentile (Median):** 125 years
- **75th Percentile:** 130 years
- **90th Percentile:** 133 years
- **99th Percentile:** 138 years

### BAYESIAN Block
- **Base Rate:** The historical maximum verified age is 122 years (Jeanne Calment).
- **Likelihoods:**
- **Status Quo Forces:** Historical data suggests a clustering of supercentenarians around 110-115 years, with no significant increase in maximum lifespan since 1997.
- **Change Drivers:** Advances in healthcare and societal factors could push the maximum age upwards, with community predictions estimating up to 131-132 years by 2100.
- **Parametric Proposal:**
```xml
<family>lognormal</family>
<params>mu=4.8, sigma=0.1</params>
```

### Explanation
- **Base Rate & Reference Class:** The base rate is informed by the historical maximum age of 122 years, with current oldest living individuals typically around 115 years.
- **Status Quo Forces vs Change Drivers:** While historical data shows stability in maximum lifespans, potential advancements in healthcare and lifestyle improvements could lead to modest increases.
- **Calibration Note:** Given the recent calibration indicating slight underconfidence in the 60-80% bin, a small upward adjustment is made, particularly in the higher percentiles, to account for potential advancements and community predictions.

------------------------------------------------------------

‚ùì Question: Before 2030, how many new AI labs will be leading labs within 2 years of their founding?
üîó URL: https://www.metaculus.com/questions/22427

üìù Full Reasoning:
# SUMMARY
*Question*: Before 2030, how many new AI labs will be leading labs within 2 years of their founding?
*Final Prediction*: 
- 0 or 1: 58.0%
- 2 or 3: 25.0%
- 4 or 5: 10.0%
- 6 or 7: 3.8%
- 8 or 9: 1.8%
- 10 or more: 1.4%

*Total Cost*: $0.0531
*Time Spent*: 2.13 minutes


## Report 1 Summary
### Forecasts
*Forecaster 1*: 
- 0 or 1: 60.0%
- 2 or 3: 25.0%
- 4 or 5: 10.0%
- 6 or 7: 3.0%
- 8 or 9: 1.0%
- 10 or more: 1.0%

*Forecaster 2*: 
- 0 or 1: 60.0%
- 2 or 3: 25.0%
- 4 or 5: 10.0%
- 6 or 7: 3.0%
- 8 or 9: 1.0%
- 10 or more: 1.0%

*Forecaster 3*: 
- 0 or 1: 50.0%
- 2 or 3: 30.0%
- 4 or 5: 10.0%
- 6 or 7: 5.0%
- 8 or 9: 3.0%
- 10 or more: 2.0%

*Forecaster 4*: 
- 0 or 1: 65.0%
- 2 or 3: 20.0%
- 4 or 5: 10.0%
- 6 or 7: 3.0%
- 8 or 9: 1.0%
- 10 or more: 1.0%

*Forecaster 5*: 
- 0 or 1: 55.0%
- 2 or 3: 25.0%
- 4 or 5: 10.0%
- 6 or 7: 5.0%
- 8 or 9: 3.0%
- 10 or more: 2.0%



### Research Summary
The research examines the historical performance and current landscape of AI labs, particularly focusing on the likelihood of new labs becoming leaders within two years of their founding. As of April 2024, the top five AI labs are identified as OpenAI, Anthropic, Google DeepMind, Cohere, and Mistral AI. The study notes that new AI labs have historically struggled to break into this elite group, with community median predictions estimating approximately 5.4 new "frontier" AI labs by the end of 2025. However, as of August 2025, no new labs founded after April 2024 have entered the top five, highlighting the significant advantages established players hold in terms of resources and data access.

The research also discusses the dynamics between status quo forces and potential change drivers. While established labs dominate the field, there is speculation about new entrants that could disrupt the current rankings, such as DeepSeek and Thinking Machines. Despite this, community skepticism persists regarding the ability of new labs to compete effectively within a short timeframe. The definition of "leading" labs is based on Chatbot Arena ELO ratings, which may evolve, and the research acknowledges that unforeseen technological advancements or funding could alter the landscape. Additionally, it notes that external factors, including regulatory changes and shifts in public interest, could impact the stability of the leaderboard.

Sources used: 
- Chatbot Arena ELO ratings (no link provided)


# RESEARCH
## Report 1 Research
### 1) Base Rates & Reference Class
- As of April 2024, the top 5 AI labs are OpenAI, Anthropic, Google DeepMind, Cohere, and Mistral AI.
- Historically, new AI labs have struggled to break into the top 5 within two years of founding.
- Current community median prediction for the number of new "frontier" AI labs by the end of 2025 is approximately 5.4.
- No new labs founded after April 2024 have reached the top 5 as of August 2025.
- Established players maintain significant advantages in resources and data.

### 2) Status Quo Forces vs Change Drivers
- **Status Quo Forces**: Dominance of established labs (OpenAI, Google, Anthropic) with substantial resources and data access.
- **Change Drivers**: Speculation about potential breakthroughs from new entrants (e.g., DeepSeek, Thinking Machines) and the possibility of well-funded startups disrupting the leaderboard.
- Community skepticism about new labs' ability to compete within a short timeframe.
- Potential for international labs or spinouts to introduce innovative technologies.
- Evolving definitions of "leading" AI labs could shift rankings if new metrics or platforms emerge.

### 3) Most Recent Credible Updates WITH DATES (YYYY-MM-DD)
- **2024-04**: Definition of leading labs established based on Chatbot Arena ELO ratings.
- **2025-08**: No new labs founded post-April 2024 have entered the top 5 on Chatbot Arena.
- **2025-08**: Community predictions indicate difficulty for new labs to break into the top 5 within two years.
- **2025-08**: Speculation continues about potential disruptors emerging before 2030.
- **2025-08**: Current resolution status indicates **0** new labs have reached the top 5 within the specified timeframe.

### 4) Resolution Criteria Traps & Fine-Print Gotchas
- Definition of "leading lab" is based on Chatbot Arena ELO ratings, which could change if the platform or evaluation criteria evolve.
- The timeframe of two years from founding may not account for unforeseen accelerations in technology or funding.
- Predictions are influenced by community sentiment and may not reflect actual market dynamics.
- Potential for new entrants to achieve rapid success through unique innovations or strategic partnerships.
- The leaderboard's stability may be affected by external factors such as regulatory changes or shifts in public interest.

### 5) Disconfirming Evidence (Steelman)
- Historical examples of startups that rapidly ascended to prominence in tech sectors, suggesting that new labs could potentially disrupt the AI landscape.
- Ongoing investments and interest in AI from various sectors may lead to unexpected breakthroughs.
- Speculative nature of prediction markets indicates that community sentiment can shift quickly, potentially favoring new entrants.
- The emergence of novel technologies or methodologies could allow new labs to leapfrog established competitors.
- Changes in consumer demand or application areas for AI could create opportunities for new players to gain traction.

# FORECASTS

## R1: Forecaster 1 Reasoning
To forecast the number of new AI labs that will become leading labs within two years of their founding before 2030, we need to consider several factors, including historical trends, current market dynamics, and potential future developments.

### Analysis

1. **Base Rates & Reference Class**:
- Historically, new AI labs have struggled to break into the top 5 within two years of their founding. As of now, no labs founded after April 2024 have achieved this.
- The community median prediction for the number of new "frontier" AI labs by the end of 2025 is around 5.4, indicating some expectation of new entrants but skepticism about their rapid rise.

2. **Status Quo Forces vs Change Drivers**:
- **Status Quo Forces**: Established labs like OpenAI, Google, and Anthropic have significant advantages in resources, talent, and data access, making it difficult for new entrants to compete quickly.
- **Change Drivers**: There is potential for well-funded startups or international labs to disrupt the current landscape, but this is speculative and not yet evidenced by recent trends.

3. **Most Recent Credible Updates**:
- As of August 2025, there have been no new labs breaking into the top 5 since April 2024, reinforcing the challenge for new entrants.

4. **Resolution Criteria Traps & Fine-Print Gotchas**:
- The definition of "leading lab" is based on current ELO ratings, which could change, but this is unlikely to significantly alter the competitive landscape in the short term.

5. **Disconfirming Evidence (Steelman)**:
- While there are historical examples of rapid ascension in tech sectors, the current AI landscape is dominated by a few key players with substantial barriers to entry.

### Bayesian Analysis

- **Base Rate**: Given the historical difficulty for new labs to reach the top 5, the base rate for 0 or 1 new lab achieving this is high.
- **Likelihoods**: The likelihood of new labs disrupting the current top 5 within two years is low given the current market dynamics and historical trends.
- **Posterior**: The posterior probability remains high for the lower end of the spectrum (0 or 1 new lab).

### Ranked List with Probabilities

1. **'0 or 1'**: 60%
- Strong base rate and current evidence support this option.
2. **'2 or 3'**: 25%
- Some potential for disruption exists, but significant barriers remain.
3. **'4 or 5'**: 10%
- Unlikely without major unforeseen breakthroughs or shifts.
4. **'6 or 7'**: 3%
- Highly unlikely given current trends.
5. **'8 or 9'**: 1%
- Very unlikely without drastic changes in the AI landscape.
6. **'10 or more'**: 1%
- Extremely unlikely barring a major paradigm shift.

### Machine-Parseable Section

```
'0 or 1': 60%
'2 or 3': 25%
'4 or 5': 10%
'6 or 7': 3%
'8 or 9': 1%
'10 or more': 1%
```


## R1: Forecaster 2 Reasoning
To forecast the number of new AI labs that will become leading labs within 2 years of their founding before 2030, we need to consider several factors, including historical trends, the current competitive landscape, and potential future developments.

### Analysis

1. **Base Rates & Historical Context**
- Historically, new AI labs have struggled to break into the top 5 within two years of founding. This suggests a low base rate for rapid ascension to the top 5.
- As of August 2025, no new labs founded after April 2024 have reached the top 5, reinforcing the difficulty of this achievement.

2. **Status Quo vs. Change Drivers**
- **Status Quo Forces**: Established labs like OpenAI, Google, and Anthropic have significant advantages in resources, talent, and data, making it challenging for new entrants to compete.
- **Change Drivers**: There is speculation about potential breakthroughs from new entrants and the possibility of well-funded startups disrupting the leaderboard. However, community skepticism remains high regarding their ability to compete within a short timeframe.

3. **Recent Updates and Community Sentiment**
- Community predictions indicate difficulty for new labs to break into the top 5 within two years, with a current resolution status of 0 new labs achieving this feat as of August 2025.
- Speculation continues about potential disruptors, but no concrete evidence suggests imminent breakthroughs.

4. **Resolution Criteria and Potential Traps**
- The definition of "leading lab" is based on Chatbot Arena ELO ratings, which could change, but this is unlikely to drastically alter the competitive landscape in the short term.
- The two-year timeframe is a significant constraint, as it may not allow sufficient time for new labs to establish themselves as leaders.

5. **Disconfirming Evidence**
- While there are historical examples of rapid ascension in tech sectors, the AI landscape is particularly dominated by a few key players, making such disruptions less likely.
- Ongoing investments and interest in AI could lead to unexpected breakthroughs, but these are speculative at this point.

### Bayesian Analysis

Given the base rates and current evidence, the likelihood of new labs breaking into the top 5 within two years remains low. However, considering the calibration note about slight underconfidence in the 60-80% bin, we can make small upward adjustments where appropriate.

- **0 or 1**: This is the most likely scenario given historical trends and current evidence. Established players have a stronghold, and no new labs have broken into the top 5 recently.
- **2 or 3**: Possible but less likely. This would require significant breakthroughs or changes in the competitive landscape.
- **4 or 5**: Unlikely without major disruptions or innovations.
- **6 or 7**, **8 or 9**, **10 or more**: Highly unlikely given the current dominance of established labs and the challenges new entrants face.

### Ranked List with Probabilities

1. **0 or 1**: 60%
2. **2 or 3**: 25%
3. **4 or 5**: 10%
4. **6 or 7**: 3%
5. **8 or 9**: 1%
6. **10 or more**: 1%

### Machine-Parseable Section

```
0 or 1: 60%
2 or 3: 25%
4 or 5: 10%
6 or 7: 3%
8 or 9: 1%
10 or more: 1%
```


## R1: Forecaster 3 Reasoning
To forecast the number of new AI labs that will become leading labs within two years of their founding before 2030, we need to consider several factors. These include the historical difficulty for new labs to break into the top 5, the dominance of established players, and the potential for new entrants to disrupt the status quo.

### Bayesian Analysis

**Base Rates & Reference Class:**
- Historically, new AI labs have struggled to break into the top 5 within two years of founding.
- As of August 2025, no new labs founded after April 2024 have reached the top 5.

**Status Quo Forces vs Change Drivers:**
- Established labs have significant advantages in resources and data.
- There is speculation about potential breakthroughs from new entrants, but skepticism remains about their ability to compete within a short timeframe.

**Most Recent Credible Updates:**
- As of August 2025, the community prediction indicates difficulty for new labs to break into the top 5 within two years.

**Disconfirming Evidence:**
- Historical examples exist of startups rapidly ascending in tech sectors.
- Ongoing investments in AI could lead to unexpected breakthroughs.

### Bayesian Checklist

- **Base Rate Probability (p):** Given the historical difficulty and current status, the base rate for new labs breaking into the top 5 is low.
- **Likelihoods:** Established players maintain dominance, but there is potential for disruption from new entrants.
- **Bayesian Posterior Probability (p):** Adjusting for recent updates and potential for disruption, the probability remains low but not negligible.

### Ranked List with Probabilities

1. **'0 or 1'**: 50% - Given the historical trend and current status, it is most likely that very few, if any, new labs will break into the top 5.
2. **'2 or 3'**: 30% - There is a moderate chance that a couple of new labs could achieve this, especially if there are significant breakthroughs or disruptions.
3. **'4 or 5'**: 10% - Less likely, but possible if multiple new entrants manage to innovate rapidly.
4. **'6 or 7'**: 5% - Unlikely, as it would require a significant shift in the current landscape.
5. **'8 or 9'**: 3% - Very unlikely, given the dominance of established players.
6. **'10 or more'**: 2% - Extremely unlikely, as it would require a complete overhaul of the current AI lab hierarchy.

### Machine-Parseable Output

```
'0 or 1': 50%
'2 or 3': 30%
'4 or 5': 10%
'6 or 7': 5%
'8 or 9': 3%
'10 or more': 2%
```


## R1: Forecaster 4 Reasoning
To forecast the number of new AI labs that will become leading labs within two years of their founding before 2030, we need to consider both the base rates and the forces of change and status quo.

### Base Rates & Reference Class
- Historically, new AI labs have struggled to break into the top 5 within two years of founding.
- As of now, no new labs founded after April 2024 have reached the top 5.
- The community median prediction for new "frontier" AI labs by the end of 2025 is approximately 5.4, but this does not specifically address the top 5 status within two years.

### Status Quo Forces vs Change Drivers
- **Status Quo Forces**: Established labs have significant advantages in resources, data, and market presence.
- **Change Drivers**: There is speculation about breakthroughs from new entrants and potential disruptors, but skepticism remains about their ability to compete quickly.

### Most Recent Credible Updates
- As of August 2025, no new labs have entered the top 5 since April 2024.
- Community predictions indicate difficulty for new labs to break into the top 5 within two years.

### Resolution Criteria Traps & Fine-Print Gotchas
- The definition of "leading lab" is based on Chatbot Arena ELO ratings, which could change.
- The two-year timeframe may not account for rapid technological or funding accelerations.

### Disconfirming Evidence
- Historical examples exist of startups rapidly ascending in tech sectors.
- Ongoing investments and interest in AI could lead to unexpected breakthroughs.

### Bayesian Analysis
Given the historical difficulty for new labs to break into the top 5 quickly, the base rate for such an occurrence is low. However, considering the recent calibration note suggesting a slight upward nudge for forecasts in the 60‚Äì80% bin when base rates and status quo align, we should adjust our probabilities accordingly.

1. **0 or 1**: The most likely scenario given the historical data and current status quo forces. The base rate supports this, and the lack of new entrants into the top 5 since April 2024 reinforces it.
2. **2 or 3**: Possible but less likely, given the skepticism about new labs' ability to compete quickly.
3. **4 or 5**: Unlikely, as it would require multiple new labs to rapidly ascend to the top 5, which has not been observed historically.
4. **6 or 7**: Very unlikely, as it would require a significant shift in the current landscape.
5. **8 or 9**: Extremely unlikely, given the current dynamics and historical data.
6. **10 or more**: Highly improbable, as it would require a complete overhaul of the current competitive landscape.

### Ranked List with Probabilities
1. **0 or 1**: 65%
2. **2 or 3**: 20%
3. **4 or 5**: 10%
4. **6 or 7**: 3%
5. **8 or 9**: 1%
6. **10 or more**: 1%

### Machine-Parseable Section
```
0 or 1: 65%
2 or 3: 20%
4 or 5: 10%
6 or 7: 3%
8 or 9: 1%
10 or more: 1%
```


## R1: Forecaster 5 Reasoning
To forecast the number of new AI labs that will become leading labs within two years of their founding before 2030, we need to consider several factors:

1. **Base Rates & Historical Context**: Historically, it's been challenging for new AI labs to break into the top 5 within two years. As of 2025, no new labs founded post-April 2024 have achieved this. This suggests a low base rate for rapid ascension.

2. **Status Quo vs. Change Drivers**: Established labs have significant advantages, but there is potential for disruption from well-funded startups or international labs. However, community sentiment remains skeptical about new labs' ability to compete quickly.

3. **Recent Updates**: As of August 2025, no new labs have reached the top 5, and community predictions reflect difficulty for new labs to achieve this within the specified timeframe.

4. **Resolution Criteria & Potential Traps**: The definition of "leading lab" is based on Chatbot Arena ELO ratings, which could change. The two-year timeframe may not account for unforeseen accelerations, but current trends suggest stability in the leaderboard.

5. **Disconfirming Evidence**: While there are historical examples of rapid ascension in tech, the AI sector's current dynamics and the dominance of established players make this less likely in the short term.

Given these considerations, we can apply a slight upward nudge to our probabilities in the 60‚Äì80% bin due to recent calibration notes, but the overall expectation remains conservative.

### Bayesian Analysis
- **Base Rate**: Historically low for rapid ascension.
- **Likelihoods**: Established labs have strong advantages, but potential disruptors exist.
- **Posterior**: Adjusted for recent calibration notes.

### Ranked List with Probabilities
1. **'0 or 1'**: 55%
- Base rate and current status quo strongly support this outcome.
2. **'2 or 3'**: 25%
- Some potential for disruption, but significant barriers exist.
3. **'4 or 5'**: 10%
- Unlikely given current dynamics and historical trends.
4. **'6 or 7'**: 5%
- Very unlikely without significant changes in the landscape.
5. **'8 or 9'**: 3%
- Extremely unlikely barring major breakthroughs.
6. **'10 or more'**: 2%
- Highly improbable given the current state of the industry.

### Machine-Parseable Section
- '0 or 1': 55%
- '2 or 3': 25%
- '4 or 5': 10%
- '6 or 7': 5%
- '8 or 9': 3%
- '10 or more': 2%

------------------------------------------------------------

‚ùì Question: How many major US labor strikes with generative AI as one of their main reasons will start in 2029?
üîó URL: https://www.metaculus.com/questions/38880

üìù Full Reasoning:
# SUMMARY
*Question*: How many major US labor strikes with generative AI as one of their main reasons will start in 2029?
*Final Prediction*: Probability distribution:
- 0.00% chance of value below -0.5
- 5.50% chance of value below 0.5
- 17.50% chance of value below 1.5
- 37.50% chance of value below 2.5
- 56.25% chance of value below 3.5
- 68.75% chance of value below 4.5
- 78.75% chance of value below 5.5
- 86.25% chance of value below 6.5
- 91.50% chance of value below 7.5

*Total Cost*: $0.0384
*Time Spent*: 2.15 minutes


## Report 1 Summary
### Forecasts
*Forecaster 1*: Probability distribution:
- 1.00% chance of value below 0.0
- 10.00% chance of value below 1.0
- 25.00% chance of value below 2.0
- 50.00% chance of value below 3.0
- 75.00% chance of value below 5.0
- 90.00% chance of value below 7.0
- 99.00% chance of value below 10.0

*Forecaster 2*: Probability distribution:
- 1.00% chance of value below 0.0
- 10.00% chance of value below 1.0
- 25.00% chance of value below 2.0
- 50.00% chance of value below 3.0
- 75.00% chance of value below 5.0
- 90.00% chance of value below 6.0
- 99.00% chance of value below 8.0

*Forecaster 3*: Probability distribution:
- 1.00% chance of value below 0.0
- 10.00% chance of value below 1.0
- 25.00% chance of value below 2.0
- 50.00% chance of value below 3.0
- 75.00% chance of value below 5.0
- 90.00% chance of value below 7.0
- 99.00% chance of value below 10.0

*Forecaster 4*: Probability distribution:
- 1.00% chance of value below 0.0
- 10.00% chance of value below 1.0
- 25.00% chance of value below 2.0
- 50.00% chance of value below 3.0
- 75.00% chance of value below 5.0
- 90.00% chance of value below 7.0
- 99.00% chance of value below 10.0

*Forecaster 5*: Probability distribution:
- 1.00% chance of value below 0.0
- 10.00% chance of value below 1.0
- 25.00% chance of value below 2.0
- 50.00% chance of value below 3.0
- 75.00% chance of value below 5.0
- 90.00% chance of value below 6.0
- 99.00% chance of value below 8.0



### Research Summary
The research examines the potential for major US labor strikes in 2029 that cite generative AI as a primary reason for the action. It establishes a framework based on historical data and recent trends, noting that major strikes typically involve at least 1,000 workers and last for a minimum of one shift, as defined by the Bureau of Labor Statistics (BLS). The SAG-AFTRA video game strike (2024‚Äì2025) is highlighted as a recent example where generative AI was a central issue, reflecting a growing trend of labor disputes related to technology and automation.

The analysis contrasts status quo forces, such as existing labor agreements that may not address AI concerns and potential employer resistance, with change drivers like increasing union awareness of generative AI's implications on jobs. While recent successful strikes may motivate further actions, the research notes that, as of now, there are no confirmed major labor strikes scheduled for 2029 that explicitly cite generative AI as a primary demand. It also emphasizes the importance of adhering to BLS criteria for qualifying strikes and acknowledges that future developments could alter the landscape of labor disputes related to technology.

Sources used in the research include:
- NPR: [npr.org](https://www.npr.org/2025/06/11/nx-s1-5174160/video-game-strike-sag-aftra-agreement)
- BLS: [bls.gov](https://www.bls.gov/wsp/factsheets/different-ways-to-measure-a-stoppage.htm)


# RESEARCH
## Report 1 Research
### 1) Base Rates & Reference Class
- Major US labor strikes typically involve at least 1,000 workers and last for at least one shift (BLS criteria).
- The SAG-AFTRA video game strike (2024‚Äì2025) serves as a recent reference point for strikes involving generative AI.
- Historical data indicates an increase in labor strikes related to technology and automation, including generative AI.

### 2) Status Quo Forces vs Change Drivers
- **Status Quo Forces:**
- Existing labor agreements may not address generative AI concerns.
- Unions may face resistance from employers regarding new demands related to AI.
- **Change Drivers:**
- Growing awareness and concern among unions about the implications of generative AI on jobs and workplace policies.
- Recent successful strikes (e.g., SAG-AFTRA) may inspire other unions to pursue similar actions.

### 3) Most Recent Credible Updates WITH DATES (YYYY-MM-DD)
- **2025-06-11:** SAG-AFTRA video game strike highlights generative AI as a central issue ([npr.org](https://www.npr.org/2025/06/11/nx-s1-5174160/video-game-strike-sag-aftra-agreement)).
- **2024-10:** Over 100,000 workers involved in major work stoppages, indicating a trend towards technology-related strikes ([bls.gov](https://www.bls.gov/wsp/factsheets/different-ways-to-measure-a-stoppage.htm)).

### 4) Resolution Criteria Traps & Fine-Print Gotchas
- Strikes must be confirmed as having generative AI as a primary demand to count.
- The BLS Detailed Monthly Listing is the definitive source for determining which strikes qualify, and any discrepancies in reporting could affect outcomes.
- Future strikes may emerge that do not meet the current criteria but still involve generative AI concerns.

### 5) Disconfirming Evidence (Steelman)
- As of now, there are **no known major labor strikes scheduled for 2029** that cite generative AI as a primary demand.
- The trend of increasing strikes may not guarantee that generative AI will be a central issue in future negotiations.
- Economic conditions or shifts in union strategies could lead to a decrease in strikes related to technology and automation.

# FORECASTS

## R1: Forecaster 1 Reasoning
### Forecast Percentiles
1st: 0  
10th: 1  
25th: 2  
50th: 3  
75th: 5  
90th: 7  
99th: 10  

### Bayesian Block
<base_rate>  
- Historical base rate of major strikes involving technology and automation is low but increasing.  
- Recent data shows a trend towards more strikes involving generative AI, with at least one major strike (SAG-AFTRA) as a reference.  

<likelihoods>  
- Likelihood of generative AI being a primary demand in future strikes is increasing due to growing awareness and successful past strikes.  
- Economic and technological trends suggest a higher probability of such strikes occurring.  

<family>lognormal</family>  
<params>  
- Mean (log-scale): 1.2  
- Standard deviation (log-scale): 0.5  
</params>  

### Rationale
1. **Base Rates & Reference Class:** The historical data and recent trends suggest an increasing number of strikes related to generative AI. The SAG-AFTRA strike serves as a relevant reference point.

2. **Status Quo Forces vs Change Drivers:** While existing agreements may not fully address AI concerns, the momentum from recent successful strikes and growing awareness among unions are strong change drivers.

3. **Recent Updates:** The ongoing SAG-AFTRA video game strike and the large number of workers involved in recent strikes indicate a trend towards more technology-related labor actions.

4. **Resolution Criteria & Disconfirming Evidence:** Although no strikes are currently scheduled for 2029, the increasing trend and potential for new demands related to AI suggest a non-zero probability of multiple strikes occurring.

5. **Calibration Note:** Given recent calibration indicating slight underconfidence in the 60‚Äì80% bin, a small upward adjustment in the forecast is warranted.


## R1: Forecaster 2 Reasoning
To forecast the number of major US labor strikes with generative AI as a primary reason starting in 2029, we can consider the following:

### Analysis

1. **Base Rates & Reference Class:**
- The recent increase in technology-related strikes, particularly those involving generative AI, provides a relevant reference class. The SAG-AFTRA video game strike and the Writers Guild of America strike are notable examples.
- Historical data shows a trend toward more frequent labor actions related to technological changes.

2. **Status Quo Forces vs Change Drivers:**
- Status quo forces may limit the number of strikes, as existing agreements may not fully address AI concerns, and there may be resistance from employers.
- Change drivers include growing awareness and concern about AI's impact on jobs, as well as recent successful strikes that could inspire similar actions.

3. **Recent Updates:**
- The ongoing SAG-AFTRA video game strike highlights generative AI as a central issue, indicating a trend that may continue into 2029.

4. **Resolution Criteria Traps:**
- Strikes must explicitly cite generative AI as a primary demand to count, which could limit the number of qualifying strikes.

5. **Disconfirming Evidence:**
- No known major strikes are scheduled for 2029 with generative AI as a primary demand, and economic or strategic shifts could reduce the number of such strikes.

### Percentile Forecast

Given these considerations, the forecast percentiles are:

- 1st percentile: 0
- 10th percentile: 1
- 25th percentile: 2
- 50th percentile: 3
- 75th percentile: 5
- 90th percentile: 6
- 99th percentile: 8

### Bayesian Block

- **Base Rate:** Historical data suggests an increasing trend in technology-related strikes, with a recent focus on generative AI.
- **Likelihoods:** 
- Likelihood of strikes involving generative AI is increasing due to heightened awareness and successful precedents.
- Resistance from employers and existing agreements may limit the number of strikes.
- **Parametric Proposal:**
```xml
<family>lognormal</family>
<params>mu=1.0, sigma=0.5</params>
```

This forecast reflects the current trajectory of labor actions related to generative AI, while accounting for potential limiting factors.


## R1: Forecaster 3 Reasoning
### Forecast Percentiles
1st: 0  
10th: 1  
25th: 2  
50th: 3  
75th: 5  
90th: 7  
99th: 10  

### Bayesian Block
<base_rate>  
- Historical data suggests an increase in strikes related to technology and automation, with recent examples involving generative AI.
- The base rate for major strikes involving new technology issues is approximately 1-2 per year, given recent trends.

<likelihoods>  
- Given the increasing trend of AI-related concerns and successful strikes, the likelihood of strikes involving generative AI is rising.
- The likelihood of a strike involving generative AI as a primary demand is higher than average due to recent successful negotiations and increasing awareness.

<family>lognormal</family>  
<params>  
- Mean (Œº): 1.2  
- Standard deviation (œÉ): 0.5  
</params>  

### Rationale
- **Base Rates & Reference Class:** The increasing trend of technology-related strikes, especially involving generative AI, suggests a higher likelihood of such strikes in the future.
- **Status Quo Forces vs Change Drivers:** While existing agreements may not fully address AI concerns, the momentum from recent successful strikes could drive more unions to include AI in their demands.
- **Recent Updates:** The ongoing SAG-AFTRA video game strike and other recent strikes highlight the growing importance of AI in labor negotiations.
- **Disconfirming Evidence:** No known strikes are scheduled for 2029, but the trend suggests potential for new developments.
- **Resolution Criteria Traps & Fine-Print Gotchas:** Ensuring that AI is a primary demand is crucial for a strike to count, but the increasing focus on AI in negotiations suggests this is likely to be met.


## R1: Forecaster 4 Reasoning
### Forecast Percentiles

- **1st percentile:** 0
- **10th percentile:** 1
- **25th percentile:** 2
- **50th percentile:** 3
- **75th percentile:** 5
- **90th percentile:** 7
- **99th percentile:** 10

### Bayesian Block

- **<base_rate>:** 1.5  
(Derived from the recent trend of technology-related strikes and the specific focus on generative AI in recent strikes.)

- **<likelihoods>:**  
- **Status Quo Forces:** Moderate resistance from employers and existing agreements not addressing AI concerns.
- **Change Drivers:** High likelihood due to increasing awareness and recent successful strikes focused on AI issues.

- **<family>lognormal</family>**  
- **<params>mean=1.5, sigma=0.8</params>**

### Rationale

1. **Base Rates & Reference Class:** The recent increase in technology-related strikes, particularly those involving generative AI, suggests a growing trend. The base rate of 1.5 reflects the expectation of at least one major strike per year related to AI.

2. **Status Quo Forces vs Change Drivers:** While existing agreements may not fully address AI concerns, the momentum from recent strikes and growing awareness among unions are strong change drivers. This suggests a higher likelihood of strikes in the coming years.

3. **Recent Updates:** The ongoing SAG-AFTRA video game strike and the involvement of over 100,000 workers in major stoppages in 2024 indicate a significant trend towards addressing AI-related issues.

4. **Resolution Criteria Traps & Fine-Print Gotchas:** The requirement for generative AI to be a primary demand is a critical factor. However, the increasing focus on AI in union negotiations suggests that this criterion will likely be met in future strikes.

5. **Disconfirming Evidence:** While no strikes are currently scheduled for 2029, the trend and momentum suggest that this is likely to change as we approach the year. The economic and strategic factors could influence the number of strikes, but the current trajectory suggests a moderate to high likelihood of multiple strikes.


## R1: Forecaster 5 Reasoning
To forecast the number of major US labor strikes with generative AI as one of their main reasons starting in 2029, we can use the information provided to construct a probabilistic model. Here's how we approach this:

### Base Rates & Reference Class
The base rate for major labor strikes involving generative AI is informed by recent events, such as the SAG-AFTRA strikes. Given the increasing trend in technology-related strikes, we can consider this as a growing area of concern.

### Status Quo Forces vs Change Drivers
- **Status Quo Forces**: Existing labor agreements may not fully address AI concerns, and there may be resistance from employers.
- **Change Drivers**: Successful past strikes and growing awareness may lead to more strikes focused on AI issues.

### Disconfirming Evidence
- No known major strikes scheduled for 2029 that cite generative AI as a primary demand.
- Economic or strategic shifts could reduce the number of strikes.

### Bayesian Analysis
We can use a Bayesian framework to incorporate these elements:

- **Base Rate**: Assume a low initial base rate for strikes involving generative AI, given the novelty of the issue.
- **Likelihoods**: Increase the likelihood of strikes due to recent successful strikes and growing awareness.
- **Parametric Proposal**: Use a lognormal distribution to model the number of strikes, reflecting the skewness and potential for a few high-impact events.

### Percentile Forecast
Based on the above considerations, here are the percentiles:

- **1st percentile**: 0
- **10th percentile**: 1
- **25th percentile**: 2
- **50th percentile**: 3
- **75th percentile**: 5
- **90th percentile**: 6
- **99th percentile**: 8

### Bayesian Block
```xml
<base_rate>0.5</base_rate>
<likelihoods>
<increase_due_to_awareness>1.5</increase_due_to_awareness>
<increase_due_to_successful_strikes>1.3</increase_due_to_successful_strikes>
</likelihoods>
<family>lognormal</family>
<params>mu=1, sigma=0.5</params>
```

This forecast reflects an expectation of a moderate number of strikes, with a skew towards fewer strikes but allowing for the possibility of more due to the dynamic nature of labor relations and technological change.

------------------------------------------------------------

