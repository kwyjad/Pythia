# Pythia
# Copyright (c) 2025 Kevin Wyjad
# Licensed under the Pythia Non-Commercial Public License v1.0.
# See the LICENSE file in the project root for details.

---
# This workflow runs the Pythia Horizon Scanner triage stage.

name: Horizon Scanner Triage

concurrency:
  group: pythia-resolver-db
  cancel-in-progress: false

# --- Triggers ---
on:
  # Manual run from the Actions tab
  workflow_dispatch:
    inputs:
      run_spd_eval:
        description: "Run SPD aggregation evaluation (non-core)"
        required: false
        default: "false"
        type: choice
        options: ["false", "true"]
      db_run_id:
        description: "Optional: force canonical DB from Actions run ID (/actions/runs/<id>) containing artifact 'pythia-resolver-db'"
        required: false
        default: ""
        type: string
      db_artifact_name:
        description: "Artifact name to download from db_run_id (default: pythia-resolver-db). Use pythia-resolver-db-reset for bootstrap runs."
        required: false
        default: "pythia-resolver-db"
        type: string

# --- Job Definition ---
jobs:
  build-report:
    runs-on: ubuntu-latest
    env:
      RESOLVER_DB_URL: duckdb:///${{ github.workspace }}/data/resolver.duckdb
      PYTHIA_DB_URL: duckdb:///${{ github.workspace }}/data/resolver.duckdb
      SIGNATURE_REQUIRED_TABLES: questions,hs_triage,question_research,forecasts_ensemble,llm_calls,facts_resolved,facts_deltas,acled_monthly_fatalities
      SIGNATURE_OPTIONAL_TABLES: scenarios
      CANONICAL_DB_READY: "false"
      CANONICAL_DB_RUN_ID: ""
      CANONICAL_DB_SOURCE: ""
      CANONICAL_CREATED_AT: ""
      SIGNATURE_OK: "false"
      DB_SOURCE: ""

    steps:
      # Step 1: Check out the repository's code
      - name: Check out code
        uses: actions/checkout@v4

      - name: Install gh CLI
        run: |
          sudo apt-get update
          sudo apt-get install -y gh

      - name: Authenticate gh
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: gh auth status

      # Step 2: Set up Python
      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      # Step 3: Diagnostics – workspace layout and key files
      - name: Diagnostics — workspace layout and key files
        run: |
          echo "=== Diagnostics: workspace layout ==="
          echo "PWD: $(pwd)"
          echo ""
          echo "Top-level listing:"
          ls -la
          echo ""
          echo "horizon_scanner directory listing:"
          if [ -d horizon_scanner ]; then
            ls -la horizon_scanner
          else
            echo "✘ MISSING: horizon_scanner directory"
          fi
          echo ""
          echo "Checking for Horizon Scanner files:"
          for f in \
            "horizon_scanner/horizon_scanner.py" \
            "horizon_scanner/db_writer.py" \
            "horizon_scanner/hs_country_list.txt" \
            "horizon_scanner/hs_prompt.py" \
            "python_library_requirements.txt"
          do
            if [ -f "$f" ]; then
              echo "✔ Found $f"
            else
              echo "✘ MISSING: $f"
            fi
          done
          echo ""
          if [ -f python_library_requirements.txt ]; then
            echo "=== python_library_requirements.txt (root) ==="
            cat python_library_requirements.txt
          else
            echo "WARNING: python_library_requirements.txt is missing in $(pwd); dependency install will fail."
          fi

      # Step 4: Install the necessary Python libraries
      - name: Install dependencies
        run: |
          set -e
          echo "Upgrading pip..."
          python -m pip install --upgrade pip
          echo ""
          echo "Installing dependencies from python_library_requirements.txt..."
          if [ ! -f python_library_requirements.txt ]; then
            echo "ERROR: python_library_requirements.txt not found in $(pwd)."
            exit 1
          fi
          pip install -r python_library_requirements.txt

      - name: Download canonical resolver DB with signature guardrail
        id: canonical_download
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          mkdir -p data diagnostics
          rm -f diagnostics/db_signature_before.json
          rm -rf data/pythia-resolver-db

          OVERRIDE_RUN_ID="${{ github.event.inputs.db_run_id }}"
          DB_ARTIFACT_NAME_INPUT="${{ github.event.inputs.db_artifact_name }}"
          DB_ARTIFACT_NAME="${DB_ARTIFACT_NAME_INPUT:-pythia-resolver-db}"

          if [ -n "$OVERRIDE_RUN_ID" ]; then
            if ! echo "$OVERRIDE_RUN_ID" | grep -Eq '^[0-9]+$'; then
              echo "ERROR: db_run_id must be a numeric Actions run id from /actions/runs/<id>. Got: '$OVERRIDE_RUN_ID'"
              exit 1
            fi

            DB_RUN_ID="$OVERRIDE_RUN_ID"
            DB_SOURCE="override"
            {
              echo "DB_RUN_ID=$OVERRIDE_RUN_ID"
              echo "DB_SOURCE=override"
              echo "DB_CREATED_AT=manual-override"
              echo "DB_ARTIFACT_NAME=${DB_ARTIFACT_NAME}"
            } >> "$GITHUB_ENV"
            echo "DB selection: source=override run_id=$OVERRIDE_RUN_ID artifact=${DB_ARTIFACT_NAME}"
          fi

          if [ -z "${DB_ARTIFACT_NAME:-}" ]; then
            DB_ARTIFACT_NAME="pythia-resolver-db"
            echo "DB_ARTIFACT_NAME=pythia-resolver-db" >> "$GITHUB_ENV"
          fi

          if [ -z "${DB_RUN_ID:-}" ]; then
            CANDIDATES_FILE=$(mktemp)
            gh run list \
              --workflow "Horizon Scanner Triage" \
              --branch main \
              --status success \
              --json databaseId,createdAt \
              --limit 1 | jq -r '.[] | "\(.createdAt),\(.databaseId),Horizon Scanner Triage"' >>"${CANDIDATES_FILE}" || true
            gh run list \
              --workflow "Resolver — Initial Backfill" \
              --branch main \
              --status success \
              --json databaseId,createdAt \
              --limit 1 | jq -r '.[] | "\(.createdAt),\(.databaseId),Resolver — Initial Backfill"' >>"${CANDIDATES_FILE}" || true

            PIPELINE_LINE=$(grep "Horizon Scanner Triage" "${CANDIDATES_FILE}" | head -n 1 || true)
            BACKFILL_LINE=$(grep "Resolver — Initial Backfill" "${CANDIDATES_FILE}" | head -n 1 || true)
            PIPELINE_RUN_ID=$(echo "$PIPELINE_LINE" | cut -d',' -f2 || true)
            BACKFILL_RUN_ID=$(echo "$BACKFILL_LINE" | cut -d',' -f2 || true)
            PIPELINE_CREATED=$(echo "$PIPELINE_LINE" | cut -d',' -f1 || true)
            BACKFILL_CREATED=$(echo "$BACKFILL_LINE" | cut -d',' -f1 || true)

            if [ -n "$PIPELINE_RUN_ID" ]; then
              DB_ARTIFACT_NAME="pythia-resolver-db"
              DB_RUN_ID="$PIPELINE_RUN_ID"
              DB_SOURCE="pipeline"
              {
                echo "DB_RUN_ID=$PIPELINE_RUN_ID"
                echo "DB_SOURCE=pipeline"
                echo "DB_CREATED_AT=$PIPELINE_CREATED"
                echo "DB_ARTIFACT_NAME=pythia-resolver-db"
              } >> "$GITHUB_ENV"
              echo "DB selection: source=pipeline run_id=$PIPELINE_RUN_ID"
            elif [ -n "$BACKFILL_RUN_ID" ]; then
              DB_ARTIFACT_NAME="pythia-resolver-db"
              DB_RUN_ID="$BACKFILL_RUN_ID"
              DB_SOURCE="backfill"
              {
                echo "DB_RUN_ID=$BACKFILL_RUN_ID"
                echo "DB_SOURCE=backfill"
                echo "DB_CREATED_AT=$BACKFILL_CREATED"
                echo "DB_ARTIFACT_NAME=pythia-resolver-db"
              } >> "$GITHUB_ENV"
              echo "DB selection: source=backfill run_id=$BACKFILL_RUN_ID"
            else
              DB_ARTIFACT_NAME="pythia-resolver-db"
              DB_SOURCE="fresh"
              echo "DB_SOURCE=fresh" >> "$GITHUB_ENV"
              echo "DB_ARTIFACT_NAME=pythia-resolver-db" >> "$GITHUB_ENV"
              echo "DB selection: source=fresh run_id=<none>"
            fi
          fi

          if [ -z "${DB_RUN_ID:-}" ]; then
            echo "ERROR: No successful Horizon Scanner or Resolver — Initial Backfill runs found; refusing to start without canonical DB."
            exit 1
          fi

          echo "DB download: source=${DB_SOURCE:-unknown} run_id=${DB_RUN_ID} artifact=${DB_ARTIFACT_NAME:-pythia-resolver-db}"

          rm -rf data/pythia-resolver-db
          rm -f data/resolver.duckdb

          if ! gh run download "$DB_RUN_ID" -n "${DB_ARTIFACT_NAME:-pythia-resolver-db}" --dir data; then
            echo "ERROR: Download failed for run ${DB_RUN_ID}."
            exit 1
          fi

          if [ -f data/pythia-resolver-db/resolver.duckdb ]; then
            SRC="data/pythia-resolver-db/resolver.duckdb"
          else
            SRC=$(find data -maxdepth 4 -type f -name "resolver.duckdb" | head -n 1 || true)
          fi

          if [ -z "${SRC}" ]; then
            echo "ERROR: resolver.duckdb not found in downloaded artifact from ${DB_RUN_ID}."
            exit 1
          fi

          if [ "$SRC" != "data/resolver.duckdb" ]; then
            cp "$SRC" data/resolver.duckdb
          fi

          # Bootstrap-only: if we're starting from a fresh reset DB, ensure Pythia schema tables exist before signature check.
          if [ "${DB_ARTIFACT_NAME:-pythia-resolver-db}" = "pythia-resolver-db-reset" ]; then
            echo "Bootstrap DB detected (${DB_ARTIFACT_NAME}); ensuring Pythia schema tables exist before signature check."
            PYTHIA_DB_URL="${RESOLVER_DB_URL}" python -c "from pythia.db.schema import ensure_schema; ensure_schema(); print('ensure_schema(): OK')"
          fi

          python -m scripts.ci.db_signature write \
            --db data/resolver.duckdb \
            --required "${SIGNATURE_REQUIRED_TABLES}" \
            --optional "${SIGNATURE_OPTIONAL_TABLES}" \
            --out diagnostics/db_signature_before.json

          if [ -f diagnostics/db_signature_before.json ]; then
            {
              echo "CANONICAL_DB_READY=true"
              echo "CANONICAL_DB_SOURCE=${DB_SOURCE:-unknown}"
              echo "CANONICAL_DB_RUN_ID=${DB_RUN_ID}"
              echo "CANONICAL_CREATED_AT=${DB_CREATED_AT:-manual}"
            } >> "$GITHUB_ENV"
            echo "Baseline signature written to diagnostics/db_signature_before.json"
          else
            echo "ERROR: Signature missing after validating run ${DB_RUN_ID}."
            exit 1
          fi

          if [ -n "${GITHUB_STEP_SUMMARY:-}" ] && [ -f diagnostics/db_signature_before.json ]; then
            {
              echo "### Canonical DB signature (before HS run)"
              echo "- Source workflow: ${CANONICAL_DB_SOURCE}"
              echo "- Run ID: ${CANONICAL_DB_RUN_ID}"
              echo "- Created: ${CANONICAL_CREATED_AT}"
              echo "- Signature file: diagnostics/db_signature_before.json"
            } >> "$GITHUB_STEP_SUMMARY"
          fi

      # Step 5: Diagnostics – confirm GEMINI_API_KEY is present
      - name: Diagnostics — GEMINI_API_KEY presence
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          if [ -z "${GEMINI_API_KEY:-}" ]; then
            echo "ERROR: GEMINI_API_KEY is NOT set."
            echo "Set it under: Settings > Secrets and variables > Actions."
            exit 1
          else
            echo "GEMINI_API_KEY is set (value hidden)."
          fi

      # Step 6: Run the main Python script (as a module)
      - name: Run Horizon Scanner
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          set -e
          echo "=== Running horizon_scanner.horizon_scanner as a module ==="
          python -m horizon_scanner.horizon_scanner
          echo "=== horizon_scanner.horizon_scanner completed ==="

      - name: Create questions from latest HS triage run
        env:
          PYTHIA_DB_URL: ${{ env.RESOLVER_DB_URL }}
        run: |
          set -e
          echo "Creating questions from hs_triage into resolver.duckdb..."
          python -m scripts.create_questions_from_triage --db "${PYTHIA_DB_URL}"

      # Step 7: Run Forecaster on newly written HS questions (Pythia mode)
      - name: Run Forecaster (Pythia mode on HS questions)
        env:
          PYTHIA_DB_URL: ${{ env.RESOLVER_DB_URL }}
          PYTHIA_LLM_PROFILE: prod
          PYTHIA_SPD_V2_WRITE_BOTH: "1"

          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          XAI_API_KEY: ${{ secrets.XAI_API_KEY }}
          MODEL_COSTS_JSON: ${{ secrets.MODEL_COSTS_JSON }}
        run: |
          set -e
          echo "=== Running Forecaster in Pythia mode on active HS questions ==="
          # No limit: forecast all questions from the current HS epoch.
          # Use a batch size to keep per-batch concurrency manageable for large epochs.
          python -m forecaster.cli \
            --mode pythia \
            --limit 0 \
            --batch-size 100 \
            --purpose hs_pipeline
          echo "=== Forecaster (Pythia mode) completed ==="

      - name: Verify Forecaster wrote both aggregation methods
        env:
          PYTHIA_DB_URL: ${{ env.RESOLVER_DB_URL }}
        run: |
          set -e
          python -m scripts.ci.verify_forecaster_aggregations --db "${PYTHIA_DB_URL}"

      - name: Evaluate SPD aggregations (Brier + log score)
        if: github.event_name == 'workflow_dispatch' && github.event.inputs.run_spd_eval == 'true'
        continue-on-error: true
        env:
          PYTHIA_DB_URL: ${{ env.RESOLVER_DB_URL }}
          PYTHONPATH: ${{ github.workspace }}
        run: |
          set -e
          mkdir -p debug/eval
          python scripts/evaluate_spd_aggregations.py \
            --db "${PYTHIA_DB_URL}" \
            --model-names ensemble_mean_v2,ensemble_bayesmc_v2 \
            --out-dir debug/eval
          ls -la debug/eval

      # Step 8: Diagnostics – DuckDB validation
      - name: Diagnostics — DuckDB
        env:
          PYTHIA_DB_URL: ${{ env.RESOLVER_DB_URL }}
        run: |
          set -e
          echo "=== Post-run diagnostics ==="
          echo "Top-level listing after run:"
          ls -la
          echo ""

          DB_PATH="data/resolver.duckdb"
          if [ -f "$DB_PATH" ]; then
            echo "DuckDB database found at $DB_PATH"
          else
            echo "WARNING: DuckDB database $DB_PATH not found."
          fi

          python scripts/post_run_diagnostics.py --db "${PYTHIA_DB_URL}"

      - name: Pythia v2 run summary
        run: |
          set -e
          python -m scripts.dump_pythia_v2_run_summary
        env:
          PYTHIA_DB_URL: ${{ env.RESOLVER_DB_URL }}

      - name: Dump unified Pythia v2 debug bundle
        run: python -m scripts.dump_pythia_debug_bundle --db "${{ env.RESOLVER_DB_URL }}"

      - name: Upload unified debug bundle artifact
        uses: actions/upload-artifact@v4
        with:
          name: pythia-debug-bundle
          path: debug/pytia_debug_bundle__*.md

      - name: Upload evaluation artifacts
        if: always() && github.event_name == 'workflow_dispatch' && github.event.inputs.run_spd_eval == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: pythia-eval
          path: debug/eval/*
          if-no-files-found: warn

      - name: Compare DB signature after HS run
        id: signature_after
        if: env.CANONICAL_DB_READY == 'true'
        env:
          REQUIRED_TABLES: ${{ env.SIGNATURE_REQUIRED_TABLES }}
          OPTIONAL_TABLES: ${{ env.SIGNATURE_OPTIONAL_TABLES }}
        run: |
          set -euo pipefail
          python -m scripts.ci.db_signature compare \
            --before diagnostics/db_signature_before.json \
            --after-db data/resolver.duckdb \
            --required "${REQUIRED_TABLES}" \
            --optional "${OPTIONAL_TABLES}" \
            --out diagnostics/db_signature_after.json

          echo "SIGNATURE_OK=true" >> "$GITHUB_ENV"
          echo "signature_ok=true" >> "$GITHUB_OUTPUT"

          if [ -n "${GITHUB_STEP_SUMMARY:-}" ]; then
            {
              echo "### Canonical DB signature (after HS run)"
              echo "- Source workflow: ${CANONICAL_DB_SOURCE}"
              echo "- Run ID: ${CANONICAL_DB_RUN_ID}"
              echo "- Signature file: diagnostics/db_signature_after.json"
            } >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Upload canonical resolver DB
        if: success() && env.CANONICAL_DB_READY == 'true' && steps.signature_after.outputs.signature_ok == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: pythia-resolver-db
          path: data/resolver.duckdb
