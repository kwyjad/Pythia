name: Inspect Resolver DuckDB

on:
  workflow_dispatch:
    inputs:
      backfill_run_id:
        description: "Run ID of the Resolver backfill workflow (the run that produced pythia-resolver-db/resolver.duckdb)"
        required: true
        type: string

  workflow_run:
    workflows: ["Resolver â€” Initial Backfill"]
    types: [completed]

jobs:
  inspect-resolver-db:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install duckdb and gh
        run: |
          python -m pip install --upgrade pip
          python -m pip install duckdb
          sudo apt-get update
          sudo apt-get install -y gh

      - name: Authenticate gh
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: gh auth status

      - name: Determine backfill run ID
        env:
          EVENT_NAME: ${{ github.event_name }}
          DISPATCH_RUN_ID: ${{ inputs.backfill_run_id }}
          WORKFLOW_RUN_ID: ${{ github.event.workflow_run.id }}
        run: |
          if [ "$EVENT_NAME" = "workflow_run" ]; then
            echo "BACKFILL_RUN_ID=${WORKFLOW_RUN_ID}" >> "$GITHUB_ENV"
            echo "Using workflow_run.id=${WORKFLOW_RUN_ID}"
          else
            echo "BACKFILL_RUN_ID=${DISPATCH_RUN_ID}" >> "$GITHUB_ENV"
            echo "Using dispatch input backfill_run_id=${DISPATCH_RUN_ID}"
          fi

      - name: Download canonical resolver DB from backfill run
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          mkdir -p data
          
          echo "Downloading pythia-resolver-db for run $BACKFILL_RUN_ID ..."
          gh run download "$BACKFILL_RUN_ID" -n pythia-resolver-db --dir data

          echo "Artifacts downloaded under data/:"
          ls -R data

          # Canonical layout: data/pythia-resolver-db/resolver.duckdb
          if [ -f data/pythia-resolver-db/resolver.duckdb ]; then
            cp data/pythia-resolver-db/resolver.duckdb data/resolver.duckdb
          else
            # Fallback: search any resolver.duckdb
            FILE_PATH=$(find data -maxdepth 4 -type f -name "resolver.duckdb" | head -n 1 || true)
            if [ -n "$FILE_PATH" ]; then
              cp "$FILE_PATH" data/resolver.duckdb
            fi
          fi

          if [ ! -f data/resolver.duckdb ]; then
            echo "ERROR: resolver.duckdb not found in pythia-resolver-db for run $BACKFILL_RUN_ID"
            ls -R data
            exit 1
          fi

      - name: Inspect data/resolver.duckdb
        run: |
          python - << 'EOF'
          import duckdb, os
          from pathlib import Path

          db_path = 'data/resolver.duckdb'
          out_path = Path('resolver_inspect.md')

          lines = []
          lines.append("# Resolver DuckDB Inspection")
          lines.append("")

          if not os.path.exists(db_path):
              lines.append(f"_Database not found at `{db_path}`_")
          else:
              con = duckdb.connect(db_path, read_only=True)

              lines.append("## Tables")
              tables = con.execute("""
                  SELECT table_name
                  FROM information_schema.tables
                  WHERE table_schema = 'main'
                  ORDER BY table_name
              """).fetchall()
              lines.append("```")
              for (tbl,) in tables:
                  lines.append(tbl)
              lines.append("```")
              lines.append("")

              def dump_table_schema_and_sample(table_name: str, limit: int = 10):
                  lines.append(f"## {table_name} schema & sample")
                  lines.append("")
                  try:
                      schema = con.execute(f"PRAGMA table_info('{table_name}')").fetchall()
                      lines.append("Schema (PRAGMA table_info):")
                      lines.append("```")
                      for row in schema:
                          lines.append(str(row))
                      lines.append("```")
                      lines.append("")
                      sample = con.execute(f"SELECT * FROM {table_name} LIMIT {limit}").fetchall()
                      lines.append(f"Sample rows (up to {limit}):")
                      lines.append("```")
                      for row in sample:
                          lines.append(str(row))
                      lines.append("```")
                  except Exception as e:
                      lines.append(f"_Error reading {table_name}: {type(e).__name__}: {e}_")
                  lines.append("")

              # Key Resolver / Pythia tables of interest
              for tbl in [
                  "bucket_centroids",
                  "facts_resolved",
                  "emdat_pa",
                  "acled_monthly_fatalities",
                  "calibration_weights",
                  "calibration_advice",
                  "resolutions",
                  "scores",
                  "hs_runs",
                  "hs_scenarios",
                  "questions",
                  "forecasts_ensemble",
                  "forecasts_raw",
                  "llm_calls",
                  "question_context",
              ]:
                  dump_table_schema_and_sample(tbl, limit=10)

              con.close()

          out_path.write_text("\n".join(lines), encoding='utf-8')
          print(f"Wrote {out_path}")
          EOF

      - name: Upload resolver inspection artifact
        uses: actions/upload-artifact@v4
        with:
          name: resolver-inspect
          path: resolver_inspect.md
