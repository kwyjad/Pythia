---
name: Resolver CI â€” Fast

on:
  push:
  pull_request:
  workflow_dispatch:

concurrency:
  group: resolver-fast-${{ github.ref }}
  cancel-in-progress: true

jobs:
  fast-tests:
    name: Fast tests
    runs-on: ubuntu-latest

    # Keep a label available for artifact naming even without a matrix
    env:
      duckdb_label: default

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Diagnostics collector sanity check
        shell: bash
        run: |
          set -euo pipefail
          bash -n .github/actions/collect-diagnostics/collect.sh
          tmp_env="$(mktemp)"
          GITHUB_ENV="${tmp_env}" .github/actions/collect-diagnostics/collect.sh test-sanity
          test -f dist/diag-test-sanity/SUMMARY.md
          rm -rf dist/diag-test-sanity dist/diagnostics-test-sanity-*
          rm -f "${tmp_env}"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies (fast)
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install -e .
          if [ -f resolver/requirements.txt ]; then pip install -r resolver/requirements.txt; fi
          pip install 'duckdb>=1.0,<2.0' pytest

      - name: Snapshot environment (pip freeze)
        run: |
          scripts/ci/run_and_capture.sh pip-freeze "pip freeze | tee .ci/diagnostics/pip-freeze.txt"

      - name: Pytest (with JUnit)
        id: tests
        continue-on-error: true
        run: |
          scripts/ci/run_and_capture.sh pytest-${{ runner.os }} "pytest -q resolver/tests -k 'not slow and not nightly' --junitxml .ci/diagnostics/pytest-junit.xml"

      - name: Post-test housekeeping
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          if [[ -d "data/snapshots" ]]; then
            echo "Snapshots exist; listing:"
            ls -R data/snapshots || true
          else
            echo "No snapshots directory (ok for fast tests)."
          fi

      - name: Write AI SUMMARY.md (always)
        if: always()
        run: |
          python scripts/ci/make_ai_summary.py || true

      - name: Collect diagnostics (fast)
        if: always()
        uses: ./.github/actions/collect-diagnostics
        with:
          job_name: fast-tests

      - name: Upload diagnostics artifact (fast)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: diagnostics-fast-tests-${{ github.run_id }}-${{ github.run_attempt }}
          path: ${{ env.ARTIFACT_PATH }}/**
          if-no-files-found: warn
          retention-days: 7

      - name: Respect test outcome
        if: ${{ always() && steps.tests.outcome == 'failure' }}
        run: exit 1

  aggregate:
    name: "Aggregate AI SUMMARY"
    runs-on: ubuntu-latest
    needs: [fast-tests]
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./downloads

      - name: Prepare diagnostics summaries
        run: |
          set -euo pipefail
          for artifact_dir in ./downloads/*; do
            [ -d "$artifact_dir" ] || continue

            # Support legacy nested ZIPs if they exist
            find "$artifact_dir" -maxdepth 1 -type f -name 'diagnostics-*.zip' -print0 |
              while IFS= read -r -d '' archive; do
                expand_dir="$artifact_dir/expanded"
                mkdir -p "$expand_dir"
                unzip -o "$archive" -d "$expand_dir" >/dev/null || true
              done

            summary_path=""
            if [ -f "$artifact_dir/SUMMARY.md" ]; then
              summary_path="$artifact_dir/SUMMARY.md"
            else
              summary_path=$(find "$artifact_dir" -maxdepth 5 -type f -name 'SUMMARY.md' -print -quit || true)
            fi

            if [ -n "$summary_path" ]; then
              mkdir -p "$artifact_dir/.ci/diagnostics"
              cp "$summary_path" "$artifact_dir/.ci/diagnostics/SUMMARY.md"
            fi
          done

      - name: Merge per-job AI summaries into one file
        run: |
          python scripts/ci/consolidate_summaries.py ./downloads ./consolidated || true

      - name: Publish consolidated summary to job log
        if: ${{ always() && hashFiles('consolidated/SUMMARY.md') != '' }}
        shell: bash
        run: |
          {
            echo "# Aggregated Resolver Summary"
            echo
            cat consolidated/SUMMARY.md
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Note missing consolidated summary
        if: ${{ always() && hashFiles('consolidated/SUMMARY.md') == '' }}
        shell: bash
        run: |
          echo "No consolidated summary produced" >> "$GITHUB_STEP_SUMMARY"
