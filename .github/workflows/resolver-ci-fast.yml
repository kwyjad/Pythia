---
name: Resolver CI â€” Fast

on:
  push:
  pull_request:
  workflow_dispatch:

concurrency:
  group: resolver-fast-${{ github.ref }}
  cancel-in-progress: true

jobs:
  fast-tests:
    name: Fast tests
    runs-on: ubuntu-latest

    # Keep a label available for artifact naming even without a matrix
    env:
      duckdb_label: default

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies (fast)
        run: |
          set -o pipefail
          python -m pip install --upgrade pip
          # Try project extras if defined; fall back to essentials
          python -m pip install -e ".[test]" || true
          python -m pip install duckdb pytest || true
          python -c "import sys,duckdb,pytest; print('DuckDB:', duckdb.__version__,'Pytest OK on', sys.version)"

      - name: Run fast tests
        id: tests
        continue-on-error: true
        run: |
          set -o pipefail
          mkdir -p .ci/diagnostics
          python -m pytest -q resolver/tests -k "not slow and not nightly" --junitxml=pytest-junit.xml

      - name: Post-test housekeeping
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          if [[ -d "data/snapshots" ]]; then
            echo "Snapshots exist; listing:"
            ls -R data/snapshots || true
          else
            echo "No snapshots directory (ok for fast tests)."
          fi

      - name: Write AI SUMMARY.md (always)
        if: always()
        run: |
          python scripts/ci/make_ai_summary.py || true

      - name: Collect diagnostics (fast)
        if: always()
        uses: ./.github/actions/collect-diagnostics
        with:
          job_name: fast-tests

      - name: Upload diagnostics artifact (fast)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: diagnostics-fast-tests-${{ github.run_id }}-${{ github.run_attempt }}
          path: ${{ env.ARTIFACT_PATH }}
          if-no-files-found: error
          retention-days: 7
          overwrite: true

      - name: Respect test outcome
        if: ${{ always() && steps.tests.outcome == 'failure' }}
        run: exit 1

  aggregate:
    name: "Aggregate AI SUMMARY"
    runs-on: ubuntu-latest
    needs: [fast-tests]
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./downloads

      - name: Expand diagnostics archives
        run: |
          set -euo pipefail
          find ./downloads -name 'diagnostics-*.zip' -print0 | while IFS= read -r -d '' archive; do
            artifact_dir="$(dirname "$archive")"
            if [ "$(basename "$artifact_dir")" = "dist" ]; then
              artifact_dir="$(dirname "$artifact_dir")"
            fi
            expand_dir="$artifact_dir/expanded"
            mkdir -p "$expand_dir"
            unzip -o "$archive" -d "$expand_dir" >/dev/null || true
            summary_path=$(find "$expand_dir" -maxdepth 4 -name 'SUMMARY.md' -print -quit)
            if [ -n "$summary_path" ]; then
              mkdir -p "$artifact_dir/.ci/diagnostics"
              cp "$summary_path" "$artifact_dir/.ci/diagnostics/SUMMARY.md"
            fi
          done

      - name: Merge per-job AI summaries into one file
        run: |
          python scripts/ci/consolidate_summaries.py ./downloads ./consolidated || true

      - name: Publish consolidated summary to job log
        if: always()
        run: |
          if [ -f consolidated/SUMMARY.md ]; then
            echo "# Aggregated Resolver Summary" >> "$GITHUB_STEP_SUMMARY"
            cat consolidated/SUMMARY.md >> "$GITHUB_STEP_SUMMARY"
          else
            echo "No consolidated summary produced" >> "$GITHUB_STEP_SUMMARY"
