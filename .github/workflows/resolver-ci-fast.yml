---
name: Resolver CI â€” Fast

on:
  push:
  pull_request:
  workflow_dispatch:

concurrency:
  group: resolver-fast-${{ github.ref }}
  cancel-in-progress: true

jobs:
  fast-tests:
    name: Fast tests
    runs-on: ubuntu-latest
    env:
      duckdb_label: default
      RESOLVER_EXPORT_ENABLE_FLOW: "0"
      RESOLVER_SKIP_DTM: "0"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Prepare diagnostics directory
        run: |
          set -euo pipefail
          RUN_TS="$(date -u +%Y%m%dT%H%M%SZ)"
          echo "RUN_TS=$RUN_TS" >> "$GITHUB_ENV"
          ART_DIR="$GITHUB_WORKSPACE/.ci/diagnostics"
          echo "ART_DIR=$ART_DIR" >> "$GITHUB_ENV"
          mkdir -p "$ART_DIR"

      - name: Diagnostics collector syntax check
        shell: bash
        run: |
          set -euo pipefail
          bash -n .github/actions/collect-diagnostics/collect.sh

      - name: Install dependencies (fast)
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip wheel setuptools
          pip install -c constraints-ci.txt -e '.[db,test]'
          if [ -f resolver/requirements.txt ]; then pip install -c constraints-ci.txt -r resolver/requirements.txt; fi

      - name: Ensure CI helpers are executable
        run: |
          set -euo pipefail
          chmod +x scripts/ci/run_and_capture.sh || true

      - name: Capture baseline diagnostics files
        run: |
          set -euo pipefail
          env | sort > "$ART_DIR/env.txt" || true
          python -m pip freeze > "$ART_DIR/pip-freeze.txt" || true

      - name: Import probes (python, pytest, duckdb)
        run: |
          bash scripts/ci/run_and_capture.sh import-probes "python - <<'PY'
          import sys, os
          print('Python:', sys.version)
          try:
              import pytest
              print('Pytest:', getattr(pytest, '__version__', 'unknown'))
          except Exception as exc:
              print('Pytest import failed:', exc)
          try:
              import duckdb
              print('DuckDB:', duckdb.__version__)
          except Exception as exc:
              print('DuckDB import failed:', exc)
          print('sys.executable:', sys.executable)
          print('PATH:', os.environ.get('PATH', ''))
          PY"

      - name: Show test tree
        run: |
          set -euo pipefail
          echo "== resolver/tests tree =="
          if [ -d resolver/tests ]; then
            find resolver/tests -maxdepth 2 -type f -name 'test_*.py' | sort | sed 's/^/ - /'
          else
            echo "resolver/tests missing"
          fi

      - name: Python syntax check (critical CI modules)
        run: |
          python scripts/ci/validate_python_syntax.py

      - name: Pytest (with JUnit)
        id: tests
        continue-on-error: true
        run: |
          set -euo pipefail

          # Collect-only (always allowed to fail non-fatally but we still want logs)
          if ! bash scripts/ci/run_and_capture.sh pytest-collect "pytest -q resolver/tests -k 'not slow and not nightly' --collect-only"; then
            echo "pytest --collect-only failed (non-fatal for diagnostics)" >&2
          fi

          # Durations (non-fatal)
          if ! bash scripts/ci/run_and_capture.sh pytest-durations "pytest -q resolver/tests -k 'not slow and not nightly' --maxfail=1 --durations=25 -x"; then
            echo "pytest --durations failed (non-fatal)" >&2
          fi

          # Real run with JUnit (this one we care about)
          bash scripts/ci/run_and_capture.sh pytest-${{ runner.os }} "pytest -q resolver/tests -k 'not slow and not nightly' --junitxml $ART_DIR/pytest-junit.xml"

          # Mirror to legacy root filename for collectors that still look there
          if [ -f "$ART_DIR/pytest-junit.xml" ]; then
            cp "$ART_DIR/pytest-junit.xml" pytest-junit.xml
          fi

      - name: Verify imports (python, pytest, duckdb)
        run: |
          python - <<'PY'
          import sys
          print('Python:', sys.version)
          try:
              import pytest
              print('Pytest:', getattr(pytest, '__version__', 'unknown'))
          except Exception as exc:
              print('Pytest import failed:', exc)
          try:
              import duckdb
              print('DuckDB:', duckdb.__version__)
          except Exception as exc:
              print('DuckDB import failed:', exc)
          PY

      - name: Post-test housekeeping
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          if [[ -d "data/snapshots" ]]; then
            echo "Snapshots exist; listing:"
            ls -R data/snapshots || true
          else
            echo "No snapshots directory (ok for fast tests)."
          fi

      - name: Write AI SUMMARY.md (always)
        if: always()
        run: |
          python scripts/ci/make_ai_summary.py || true

      - name: Collect diagnostics summary (fast)
        if: always()
        env:
          ART_DIR: ${{ env.ART_DIR }}
          SAFE_SUFFIX: fast-tests
        run: |
          python scripts/ci/collect_diagnostics.py "$ART_DIR"
          bash .github/actions/collect-diagnostics/collect.sh

      - name: Upload diagnostics artifact (fast)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: diagnostics-fast-tests-${{ github.run_id }}-${{ github.run_attempt }}
          path: ${{ env.ART_DIR }}
          if-no-files-found: warn
          retention-days: 7

      - name: Respect test outcome
        if: ${{ always() && steps.tests.outcome == 'failure' }}
        run: exit 1

  aggregate:
    name: "Aggregate AI SUMMARY"
    runs-on: ubuntu-latest
    needs: [fast-tests]
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./downloads

      - name: Prepare diagnostics summaries
        run: |
          set -euo pipefail
          for artifact_dir in ./downloads/*; do
            [ -d "$artifact_dir" ] || continue

            # Expand legacy nested zips if any
            find "$artifact_dir" -maxdepth 1 -type f -name 'diagnostics-*.zip' -print0 |
              while IFS= read -r -d '' archive; do
                expand_dir="$artifact_dir/expanded"
                mkdir -p "$expand_dir"
                unzip -o "$archive" -d "$expand_dir" >/dev/null || true
              done

            summary_path=""
            if [ -f "$artifact_dir/SUMMARY.md" ]; then
              summary_path="$artifact_dir/SUMMARY.md"
            elif [ -f "$artifact_dir/summary.md" ]; then
              summary_path="$artifact_dir/summary.md"
            else
              summary_path=$(find "$artifact_dir" -maxdepth 5 -type f \( -name 'SUMMARY.md' -o -name 'summary.md' \) -print -quit || true)
            fi

            if [ -n "$summary_path" ]; then
              mkdir -p "$artifact_dir/.ci/diagnostics"
              cp "$summary_path" "$artifact_dir/.ci/diagnostics/SUMMARY.md"
            fi
          done

      - name: Merge per-job AI summaries into one file
        run: |
          python scripts/ci/consolidate_summaries.py ./downloads ./consolidated || true

      - name: Publish consolidated summary to job log
        if: ${{ always() && hashFiles('consolidated/SUMMARY.md') != '' }}
        shell: bash
        run: |
          {
            echo "# Aggregated Resolver Summary"
            echo
            cat consolidated/SUMMARY.md
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Note missing consolidated summary
        if: ${{ always() && hashFiles('consolidated/SUMMARY.md') == '' }}
        shell: bash
        run: |
          echo "No consolidated summary produced" >> "$GITHUB_STEP_SUMMARY"
