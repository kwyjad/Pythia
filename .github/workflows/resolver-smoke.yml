---
name: "Resolver pipeline â€” smoke"

on:
  push:
  pull_request:
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: resolver-pipeline-smoke-${{ github.ref }}
  cancel-in-progress: true

jobs:
  smoke:
    name: "Smoke pipeline (stubs)"
    runs-on: ubuntu-latest
    timeout-minutes: 15
    env:
      PYTHONUNBUFFERED: "1"
      PERIOD_LABEL: ci-smoke
      RESOLVER_PERIOD: ci-smoke
      RESOLVER_STAGING_DIR: data/staging
      RESOLVER_INGESTION_MODE: stubs
      RESOLVER_FAIL_ON_STUB_ERROR: "0"
      RESOLVER_DEBUG: "0"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install resolver dependencies
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install -e .
          pip install -r resolver/requirements.txt
          pip install 'duckdb>=1.0,<2.0'

      - name: Reset staging directories
        run: |
          set -euo pipefail
          rm -rf "data/staging/${PERIOD_LABEL}"
          rm -rf "data/snapshots/${PERIOD_LABEL}"

      - name: Prepare raw staging (stubs)
        env:
          PERIOD_LABEL: ci-smoke
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p .ci/exitcodes
          RAW_DIR="data/staging/${PERIOD_LABEL}/raw"
          mkdir -p "${RAW_DIR}"

          set +e
          python -m resolver.ingestion.ifrc_go_stub --out "${RAW_DIR}"
          status=$?
          set -euo pipefail

          if [ "${status}" -eq 0 ]; then
            echo "exit=0" > .ci/exitcodes/run_stubs
          else
            echo "exit=${status}" > .ci/exitcodes/run_stubs
            echo "IFRC stub failed with exit code ${status}" >&2
            exit ${status}
          fi

          echo "Raw contents:"
          ls -lh "${RAW_DIR}" || true

      - name: Discover normalizable sources
        env:
          PERIOD_LABEL: ci-smoke
        shell: bash
        run: |
          set -euo pipefail
          python scripts/ci/discover_normalizable_sources.py "${PERIOD_LABEL}" | tee _sources.env
          grep "^SOURCES=" _sources.env >> "$GITHUB_ENV"

      - name: Normalize
        env:
          PERIOD_LABEL: ci-smoke
          SOURCES: ${{ env.SOURCES }}
        run: |
          set -euo pipefail
          python -m resolver.transform.normalize \
            --in "data/staging/${PERIOD_LABEL}/raw" \
            --out "data/staging/${PERIOD_LABEL}/canonical" \
            --period "${PERIOD_LABEL}" \
            --sources "${SOURCES}"

      - name: Gate canonical row count
        env:
          PERIOD_LABEL: ci-smoke
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p .ci/exitcodes
          CANONICAL_DIR="data/staging/${PERIOD_LABEL}/canonical"

          if [ ! -d "${CANONICAL_DIR}" ]; then
            echo "exit=2 reason=missing_canonical_dir" > .ci/exitcodes/gate_rows
            echo "Canonical directory missing: ${CANONICAL_DIR}" >&2
            exit 2
          fi

          total_rows=$(python - <<'PY'
            import os
            from pathlib import Path

            period = os.environ.get("PERIOD_LABEL", "")
            canonical = Path("data/staging") / period / "canonical"
            total = 0
            for csv_path in sorted(canonical.glob("*.csv")):
                try:
                    with csv_path.open("r", encoding="utf-8") as handle:
                        row_count = sum(1 for _ in handle) - 1
                except Exception:
                    row_count = 0
                if row_count < 0:
                    row_count = 0
                total += row_count
            print(total)
PY
          )

          echo "Canonical rows discovered: ${total_rows}"

          if [ "${total_rows}" -ge 1 ]; then
            echo "exit=0 rows=${total_rows}" > .ci/exitcodes/gate_rows
          else
            echo "exit=2 rows=${total_rows}" > .ci/exitcodes/gate_rows
            echo "No canonical rows produced (expected >= 1 for smoke)." >&2
            exit 2
          fi

      - name: Load / derive / export
        env:
          PERIOD_LABEL: ci-smoke
        run: |
          set -euo pipefail
          python -m resolver.tools.load_and_derive load-canonical \
            --in "data/staging/${PERIOD_LABEL}/canonical"
          python -m resolver.tools.load_and_derive derive-deltas \
            --period "${PERIOD_LABEL}" --allow-negatives 1
          python -m resolver.tools.load_and_derive export \
            --period "${PERIOD_LABEL}" --format parquet \
            --out "data/snapshots/${PERIOD_LABEL}"

      - name: Optional smoke checks
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p .ci/exitcodes

          if [ -f data/resolver.duckdb ]; then
            echo "DuckDB present"
            echo "exit=0" > .ci/exitcodes/check_duckdb
          else
            echo "DuckDB missing (expected in smoke)"
            echo "exit=0" > .ci/exitcodes/check_duckdb
          fi

          if ls -lh data/snapshots 1>/dev/null 2>&1; then
            ls -lh data/snapshots || true
          else
            echo "data/snapshots missing (allowed in smoke)"
          fi
          echo "exit=0" > .ci/exitcodes/ls_snapshots

          logs_present="false"
          if ls -lh resolver/logs 1>/dev/null 2>&1; then
            ls -lh resolver/logs || true
            logs_present="true"
          fi
          if ls -lh data/logs 1>/dev/null 2>&1; then
            ls -lh data/logs || true
            logs_present="true"
          fi
          if [ "${logs_present}" = "false" ]; then
            echo "resolver/data logs missing (allowed in smoke)"
          fi
          echo "exit=0" > .ci/exitcodes/ls_logs

      - name: Collect diagnostics (smoke)
        if: always()
        uses: ./.github/actions/collect-diagnostics
        with:
          job_name: pipeline-smoke

      - name: Upload diagnostics (smoke)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: diagnostics-pipeline-smoke-${{ github.run_id }}-${{ github.run_attempt }}
          path: ${{ env.ARTIFACT_PATH }}
          if-no-files-found: ignore
          retention-days: 7
          overwrite: true

      - name: Upload snapshot artifacts
        uses: actions/upload-artifact@v4
        with:
          name: resolver-smoke-snapshots
          path: data/snapshots/${PERIOD_LABEL}/*.parquet
          if-no-files-found: ignore
          retention-days: 7
          overwrite: true
