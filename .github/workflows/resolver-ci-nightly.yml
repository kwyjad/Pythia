---
name: resolver-ci-nightly

on:
  schedule:
    - cron: "0 23 * * *"
  workflow_dispatch: {}

permissions:
  contents: read

concurrency:
  group: resolver-nightly
  cancel-in-progress: false

jobs:
  full_connectors:
    if: ${{ github.repository == 'oughtinc/Pythia' && (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch') }}
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        connector:
          [reliefweb, ifrc_go, unhcr, unhcr_odp, dtm, who_phe, hdx, acled, emdat, gdacs, ipc, wfp_mvam, worldpop]
    env:
      ACLED_REFRESH_TOKEN: ${{ secrets.ACLED_REFRESH_TOKEN }}
      ACLED_USERNAME: ${{ secrets.ACLED_USERNAME }}
      ACLED_PASSWORD: ${{ secrets.ACLED_PASSWORD }}
      DTM_API_PRIMARY_KEY: ${{ secrets.DTM_API_PRIMARY_KEY }}
      DTM_API_SECONDARY_KEY: ${{ secrets.DTM_API_SECONDARY_KEY }}
      DTM_API_HEADER_NAME: ${{ vars.DTM_API_HEADER_NAME }}
      PYTHONPATH: ${{ github.workspace }}
      RESOLVER_DEBUG: "0"
      RESOLVER_INCLUDE_STUBS: "0"
      RESOLVER_WINDOW_DAYS: ""
      RESOLVER_MAX_PAGES: ""
      RESOLVER_MAX_RESULTS: ""
      RESOLVER_DUCKDB_DISABLE_MERGE: "1"
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Debug repo context
        run: |
          echo "GITHUB_REPOSITORY=$GITHUB_REPOSITORY"
          echo "GITHUB_REF=$GITHUB_REF"
          echo "GITHUB_SHA=$GITHUB_SHA"
          python -c "import pathlib; p = pathlib.Path().resolve(); print('CWD:', p); print('Tree:', len(list(p.glob('**/*'))))"

      - name: Check DB tests present
        id: dbfiles
        shell: bash
        run: |
          set -euo pipefail
          if [ -f "resolver/tests/test_db_parity.py" ] || [ -f "resolver/tests/test_duckdb_idempotency.py" ]; then
            echo "present=true" >> "$GITHUB_OUTPUT"
            echo "Found DB tests."
          else
            echo "present=false" >> "$GITHUB_OUTPUT"
            echo "No DB tests found; will skip DB test steps."
          fi

      - name: "Anti-drift: assert no legacy repo references"
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          part_a="spa"
          part_b="gbot"
          script_path="scripts/ci/assert_no_${part_a}${part_b}_refs.sh"
          chmod +x "$script_path"
          "$script_path"
      - name: Set up Python
        if: steps.dbfiles.outputs.present == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: |
            resolver/requirements.txt
            resolver/requirements-dev.txt
      - name: Confirm Pythia root
        if: steps.dbfiles.outputs.present == 'true'
        run: ls -la && test -f pyproject.toml
      - name: Install dependencies (project + db + tests)
        if: steps.dbfiles.outputs.present == 'true'
        env:
          PIP_NO_CACHE_DIR: "1"
          PIP_DEFAULT_TIMEOUT: "60"
          PIP_INDEX_URL: ${{ secrets.PIP_INDEX_URL }}
          PIP_EXTRA_INDEX_URL: ${{ secrets.PIP_EXTRA_INDEX_URL }}
          HTTP_PROXY: ${{ secrets.HTTP_PROXY }}
          HTTPS_PROXY: ${{ secrets.HTTPS_PROXY }}
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip wheel setuptools
          pip install -e .[db, test]

      - name: Capture baseline diagnostics files
        if: always()
        run: |
          set -euo pipefail
          env | sort > "${ART_DIR}/env.txt" || true
          if command -v python >/dev/null 2>&1; then
            python -m pip freeze > "${ART_DIR}/pip-freeze.txt" || true
          fi

      - name: Verify DuckDB presence
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          python - <<'PY'
          import importlib.util, sys
          spec = importlib.util.find_spec("duckdb")
          if spec is None:
              print("❌ DuckDB not installed — cannot run DB parity tests.")
              sys.exit(1)
          import duckdb
          print("✅ DuckDB installed:", duckdb.__version__)
          PY
      - name: Show resolver import location & DuckDB version
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          python - <<'PY'
          import sys, pathlib, resolver, duckdb
          print("Python executable:", sys.executable)
          print("resolver module path:", pathlib.Path(resolver.__file__).resolve())
          print("duckdb version:", getattr(duckdb, "__version__", "n/a"))
          PY
      - name: Run ${{ matrix.connector }} (full)
        if: steps.dbfiles.outputs.present == 'true'
        env:
          RESOLVER_FAIL_ON_STUB_ERROR: "0"
        run: |
          scripts/ci/run_and_capture.sh connector-${{ matrix.connector }} "python -m resolver.ingestion.run_all_stubs --mode real --only ${{ matrix.connector }} --log-level INFO --log-format json"
      - name: Run staging schema tests
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          scripts/ci/run_and_capture.sh staging-schema "pytest -q resolver/tests/test_staging_schema_all.py"
      - name: Record job status
        if: always()
        env:
          CONNECTOR: ${{ matrix.connector }}
          JOB_STATUS: ${{ job.status }}
        run: |
          python - <<'PY'
          import json
          import os
          from pathlib import Path

          connector = os.environ["CONNECTOR"]
          status = os.environ.get("JOB_STATUS", "unknown")
          log_dir = Path("resolver/logs/ingestion")
          log_dir.mkdir(parents=True, exist_ok=True)
          summary_path = log_dir / f"{connector}-job-status.json"
          summary_path.write_text(json.dumps({"connector": connector, "job_status": status}))
          PY
      - name: Upload nightly artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: nightly-${{ matrix.connector }}
          path: |
            resolver/logs/ingestion/**
            resolver/exports/**
            resolver/staging/**
          retention-days: 7

      - name: Skip DB tests (not present)
        if: steps.dbfiles.outputs.present != 'true'
        run: echo "::notice ::Skipping nightly connectors (DB tests not present in this repo/branch)."

  aggregate:
    if: ${{ github.repository == 'oughtinc/Pythia' && always() && (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch') }}
    needs: full_connectors
    runs-on: ubuntu-latest
    steps:
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: nightly-artifacts
          merge-multiple: true
      - name: Build summary
        run: |
          python - <<'PY'
          import csv
          import json
          from pathlib import Path

          root = Path("nightly-artifacts")
          records = []
          for status_file in root.rglob("*-job-status.json"):
              try:
                  data = json.loads(status_file.read_text())
              except json.JSONDecodeError:
                  continue
              connector = data.get("connector") or status_file.stem.replace("-job-status", "")
              job_status = data.get("job_status", "unknown")
              record = {
                  "connector": connector,
                  "job_status": job_status,
                  "status": "unknown",
                  "attempts": None,
                  "duration_ms": None,
                  "notes": None,
              }
              log_dir = status_file.parent
              for log_file in sorted(log_dir.glob("*")):
                  if not log_file.is_file():
                      continue
                  try:
                      lines = log_file.read_text().splitlines()
                  except Exception:
                      continue
                  for line in lines:
                      line = line.strip()
                      if not line:
                          continue
                      try:
                          payload = json.loads(line)
                      except json.JSONDecodeError:
                          continue
                      if payload.get("event") == "connector_summary":
                          record.update(
                              {
                                  "status": payload.get("status", record["status"]),
                                  "attempts": payload.get("attempts", record["attempts"]),
                                  "duration_ms": payload.get("duration_ms", record["duration_ms"]),
                                  "notes": payload.get("notes", record["notes"]),
                              }
                          )
              records.append(record)
          records.sort(key=lambda item: item["connector"] or "")
          summary_dir = Path("nightly-summary")
          summary_dir.mkdir(exist_ok=True)
          json_path = summary_dir / "summary.json"
          csv_path = summary_dir / "summary.csv"
          json_path.write_text(json.dumps(records, indent=2, sort_keys=True))
          with csv_path.open("w", newline="", encoding="utf-8") as handle:
              writer = csv.DictWriter(handle, fieldnames=["connector", "job_status", "status", "attempts", "duration_ms", "notes"])
              writer.writeheader()
              for row in records:
                  writer.writerow(row)
          PY
      - name: Upload nightly summary
        uses: actions/upload-artifact@v4
        with:
          name: nightly-summary
          path: nightly-summary
          retention-days: 7

  tests-db:
    name: tests (db backend)
    if: ${{ github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' }}
    runs-on: ubuntu-latest
    env:
      ART_ROOT: ${{ github.workspace }}/ci_artifacts
      RESOLVER_API_BACKEND: db
      RESOLVER_DB_URL: duckdb:///${{ github.workspace }}/.ci-resolver.duckdb
      RESOLVER_LOG_LEVEL: DEBUG
      PYTEST_ADDOPTS: "-vv -ra --maxfail=1 --durations=25 --durations-min=1.0"
      PYTHONDONTWRITEBYTECODE: "1"
      PIP_DISABLE_PIP_VERSION_CHECK: "1"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Derive sanitized artifact suffix
        if: always()
        run: |
          raw="nightly"
          SAFE_SUFFIX="${raw}"
          SAFE_SUFFIX="${SAFE_SUFFIX//\*/_}"
          SAFE_SUFFIX="${SAFE_SUFFIX// /_}"
          SAFE_SUFFIX="$(printf '%s' "${SAFE_SUFFIX}" | tr -c 'A-Za-z0-9_.-' '_')"
          echo "SAFE_SUFFIX=${SAFE_SUFFIX}" >> "$GITHUB_ENV"

      - name: Initialize run folders (fresh)
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "${ART_ROOT}"
          RUN_TS="$(date -u +'%Y%m%dT%H%M%SZ')"
          ART_DIR="${ART_ROOT}/${RUN_TS}-${GITHUB_SHA::7}"
          echo "RUN_TS=${RUN_TS}" >> "$GITHUB_ENV"
          echo "ART_DIR=${ART_DIR}" >> "$GITHUB_ENV"
          echo "Initialized artifact directory: ${ART_DIR}"
          rm -rf logs .ci/diagnostics .ci/exitcodes || true
          mkdir -p logs "${ART_DIR}"
          if [[ "${RESOLVER_DB_URL:-}" == duckdb:///* ]]; then
            db_path="${RESOLVER_DB_URL#duckdb:///}"
            if [ -n "${db_path}" ]; then
              rm -f "${db_path}" || true
            fi
          fi

      - name: Debug repo context
        run: |
          echo "GITHUB_REPOSITORY=$GITHUB_REPOSITORY"
          echo "GITHUB_REF=$GITHUB_REF"
          echo "GITHUB_SHA=$GITHUB_SHA"
          python -c "import pathlib; p = pathlib.Path().resolve(); print('CWD:', p); print('Tree:', len(list(p.glob('**/*'))))"

      - name: Check DB tests present
        id: dbfiles
        shell: bash
        run: |
          set -euo pipefail
          if [ -f "resolver/tests/test_db_parity.py" ] || [ -f "resolver/tests/test_duckdb_idempotency.py" ]; then
            echo "present=true" >> "$GITHUB_OUTPUT"
            echo "Found DB tests."
          else
            echo "present=false" >> "$GITHUB_OUTPUT"
            echo "No DB tests found; will skip DB test steps."
          fi

      - name: "Anti-drift: assert no legacy repo references"
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          part_a="spa"
          part_b="gbot"
          script_path="scripts/ci/assert_no_${part_a}${part_b}_refs.sh"
          chmod +x "$script_path"
          "$script_path"

      - name: Set up Python
        if: steps.dbfiles.outputs.present == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Confirm Pythia root
        if: steps.dbfiles.outputs.present == 'true'
        run: ls -la && test -f pyproject.toml

      - name: Install (robust, proxy-safe) with fallback
        id: robust_install
        if: steps.dbfiles.outputs.present == 'true'
        env:
          PIP_NO_CACHE_DIR: "1"
          PIP_DEFAULT_TIMEOUT: "60"
          PIP_INDEX_URL: ${{ secrets.PIP_INDEX_URL }}
          PIP_EXTRA_INDEX_URL: ${{ secrets.PIP_EXTRA_INDEX_URL }}
          HTTP_PROXY: ${{ secrets.HTTP_PROXY }}
          HTTPS_PROXY: ${{ secrets.HTTPS_PROXY }}
        run: |
          set -euo pipefail
          echo "Attempt A: editable install with preloaded build tooling and DuckDB wheel"
          python -m pip install -U pip wheel setuptools "poetry-core>=1.9"
          python -m pip install --only-binary=:all: "duckdb==1.1.3" || true
          if python -m pip install -e ".[db]" --no-build-isolation; then
            echo "mode=editable" >>"$GITHUB_OUTPUT"
            exit 0
          fi
          echo "Attempt B: retry editable install after short backoff"
          sleep 5
          if python -m pip install -e ".[db]" --no-build-isolation; then
            echo "mode=editable" >>"$GITHUB_OUTPUT"
            exit 0
          fi
          echo "Editable install failed; falling back to requirements with PYTHONPATH"
          python -m pip install --only-binary=:all: "duckdb==1.1.3" || true
          if [ -f resolver/requirements.txt ]; then python -m pip install -r resolver/requirements.txt || true; fi
          if [ -f resolver/requirements-dev.txt ]; then python -m pip install -r resolver/requirements-dev.txt || true; fi
          if [ -f resolver/requirements-ci.txt ]; then python -m pip install -r resolver/requirements-ci.txt || true; fi
          python -m pip install httpx pytest || true
          echo "mode=fallback" >>"$GITHUB_OUTPUT"
          exit 0

      - name: Ensure test utilities for diagnostics
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          python -m pip install -U pytest pytest-timeout pytest-xdist

      - name: Verify DuckDB presence
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          python - <<'PY'
          import importlib.util, sys
          spec = importlib.util.find_spec("duckdb")
          if spec is None:
              print("❌ DuckDB not installed — cannot run DB parity tests.")
              sys.exit(1)
          import duckdb
          print("✅ DuckDB installed:", duckdb.__version__)
          PY

      - name: Run full test suite (nightly)
        id: run_db_tests
        if: steps.dbfiles.outputs.present == 'true'
        continue-on-error: true
        timeout-minutes: 45
        env:
          INSTALL_MODE: ${{ steps.robust_install.outputs.mode }}
        shell: bash
        run: |
          set -euo pipefail
          echo "Resolved install mode: ${INSTALL_MODE:-unset}"
          if [ "${INSTALL_MODE}" = "fallback" ]; then
            export PYTHONPATH="${PYTHONPATH:-$GITHUB_WORKSPACE}"
            echo "Using fallback install mode; PYTHONPATH=$PYTHONPATH"
          fi

          if [ ! -d resolver/tests ]; then
            echo "resolver/tests directory missing; skipping pytest run."
            printf '%s\n' "0" | tee "${ART_DIR}/pytest.exit"
            printf '%s\n' "_resolver/tests not found; pytest run skipped._" | tee "${ART_DIR}/pytest.out"
            echo "exit_code=0" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          echo "Collecting resolver test inventory"
          python - <<'PY' | tee "${ART_DIR}/test-inventory.txt"
            import pathlib

            root = pathlib.Path("resolver/tests")
            tests = sorted(str(path) for path in root.rglob("test_*.py"))
            print(f"Discovered {len(tests)} test file(s)")
            for path in tests:
                print(f" - {path}")
          PY

          PYTEST_JUNIT="${ART_DIR}/junit.xml"
          PYTEST_OUT="${ART_DIR}/pytest.out"

          TEST_RC=0
          set +e
          pytest resolver/tests -n auto --timeout=180 --timeout-method=thread --junitxml="${PYTEST_JUNIT}" 2>&1 | tee "${PYTEST_OUT}"
          TEST_RC=${PIPESTATUS[0]}
          set -e

          printf '%s\n' "${TEST_RC}" > "${ART_DIR}/pytest.exit"
          echo "exit_code=${TEST_RC}" >> "$GITHUB_OUTPUT"

          exit "${TEST_RC}"

      - name: DB parity/idempotency tests (if present)
        id: run_db_parity
        if: steps.dbfiles.outputs.present == 'true' && hashFiles('resolver/tests/test_db_parity.py','resolver/tests/test_duckdb_idempotency.py') != ''
        continue-on-error: true
        timeout-minutes: 20
        env:
          INSTALL_MODE: ${{ steps.robust_install.outputs.mode }}
        run: |
          set -euo pipefail
          if [ "${INSTALL_MODE}" = "fallback" ]; then
            export PYTHONPATH="${PYTHONPATH:-$GITHUB_WORKSPACE}"
            echo "Using fallback install mode for DB parity run; PYTHONPATH=$PYTHONPATH"
          fi

          PYTEST_JUNIT="${ART_DIR}/db.junit.xml"
          PYTEST_OUT="${ART_DIR}/pytest-db.out"

          DB_RC=0
          set +e
          pytest resolver/tests/test_db_parity.py resolver/tests/test_duckdb_idempotency.py -n auto --timeout=120 --timeout-method=thread --junitxml="${PYTEST_JUNIT}" 2>&1 | tee "${PYTEST_OUT}"
          DB_RC=${PIPESTATUS[0]}
          set -e

          printf '%s\n' "${DB_RC}" > "${ART_DIR}/pytest-db.exit"
          echo "exit_code=${DB_RC}" >> "$GITHUB_OUTPUT"

          exit "${DB_RC}"

      - name: Canonical listing snapshot
        if: always()
        run: |
          scripts/ci/run_and_capture.sh canonical-listing "python scripts/ci/list_canonical.py --dir data/staging --out .ci/diagnostics/canonical-listing.txt || true"

      - name: DuckDB table counts (optional)
        if: always()
        run: |
          scripts/ci/run_and_capture.sh duckdb-counts "python scripts/ci/db_counts.py --db .ci-resolver.duckdb --out .ci/diagnostics/duckdb-counts.txt || true"

      - name: Stage diagnostics bundle
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "${ART_DIR}"
          if [ -d logs ]; then
            mkdir -p "${ART_DIR}/logs"
            cp -R logs/. "${ART_DIR}/logs/" || true
          fi
          if [ -d .ci/diagnostics ]; then
            mkdir -p "${ART_DIR}/ci-diagnostics"
            cp -R .ci/diagnostics/. "${ART_DIR}/ci-diagnostics/" || true
          fi
          if [ -d .ci/exitcodes ]; then
            mkdir -p "${ART_DIR}/ci-exitcodes"
            cp -R .ci/exitcodes/. "${ART_DIR}/ci-exitcodes/" || true
          fi
          for target in resolver/logs/ingestion resolver/exports resolver/staging; do
            if [ -d "$target" ]; then
              mkdir -p "${ART_DIR}/${target}"
              cp -R "$target"/. "${ART_DIR}/${target}/" || true
            fi
          done

      - name: Collect diagnostics (always)
        if: always()
        env:
          ART_DIR: ${{ env.ART_DIR }}
          GITHUB_STEP_SUMMARY: ${{ github.step_summary }}
        run: |
          python scripts/ci/collect_diagnostics.py "${ART_DIR}"
          bash .github/actions/collect-diagnostics/collect.sh

      - name: Upload CI artifacts (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: nightly-tests-db-${{ env.RUN_TS }}
          path: ${{ env.ART_DIR }}
          if-no-files-found: warn
          retention-days: 14

      - name: Evaluate pytest outcomes
        if: ${{ steps.dbfiles.outputs.present == 'true' }}
        env:
          MAIN_EXIT: ${{ steps.run_db_tests.outputs.exit_code }}
          DB_EXIT: ${{ steps.run_db_parity.outputs.exit_code }}
        run: |
          python - <<'PY'
            import os
            import pathlib
            import sys
            import xml.etree.ElementTree as ET

            issues = []

            def has_failures(path: pathlib.Path, label: str) -> bool:
                if not path.exists():
                    return False
                try:
                    tree = ET.parse(path)
                except ET.ParseError as exc:  # pragma: no cover - diagnostics only
                    issues.append(f"{label}: unable to parse {path} ({exc})")
                    return True
                total = 0
                for suite in tree.iter("testsuite"):
                    total += int(suite.attrib.get("failures", "0")) + int(suite.attrib.get("errors", "0"))
                if total:
                    issues.append(f"{label}: {total} recorded failure/error cases in {path}")
                    return True
                return False

            main_exit = (os.environ.get("MAIN_EXIT") or "").strip()
            db_exit = (os.environ.get("DB_EXIT") or "").strip()

            art_dir = pathlib.Path(os.environ.get("ART_DIR", ".")).resolve()
            has_failures(art_dir / "junit.xml", "nightly suite")
            has_failures(art_dir / "db.junit.xml", "db parity suite")

            if main_exit and main_exit != "0":
                issues.append(f"nightly pytest exited with {main_exit}")
            if db_exit and db_exit != "0":
                issues.append(f"db parity pytest exited with {db_exit}")

            if issues:
                print("\n".join(issues))
                sys.exit(1)

            print("All pytest runs reported success.")
          PY

      - name: Skip DB tests (not present)
        if: steps.dbfiles.outputs.present != 'true'
        run: echo "::notice ::Skipping DB tests (files not present in this repo/branch)."
