---
name: resolver-ci-nightly

on:
  schedule:
    - cron: "0 23 * * *"
  workflow_dispatch: {}

permissions:
  contents: read

concurrency:
  group: resolver-nightly
  cancel-in-progress: false

jobs:
  full_connectors:
    if: ${{ github.repository == 'oughtinc/Pythia' && (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch') }}
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        connector:
          [reliefweb, ifrc_go, unhcr, unhcr_odp, dtm, who_phe, hdx, acled, emdat, gdacs, ipc, wfp_mvam, worldpop]
    env:
      ACLED_REFRESH_TOKEN: ${{ secrets.ACLED_REFRESH_TOKEN }}
      ACLED_USERNAME: ${{ secrets.ACLED_USERNAME }}
      ACLED_PASSWORD: ${{ secrets.ACLED_PASSWORD }}
      DTM_API_PRIMARY_KEY: ${{ secrets.DTM_API_PRIMARY_KEY }}
      DTM_API_SECONDARY_KEY: ${{ secrets.DTM_API_SECONDARY_KEY }}
      DTM_API_HEADER_NAME: ${{ vars.DTM_API_HEADER_NAME }}
      PYTHONPATH: ${{ github.workspace }}
      RESOLVER_DEBUG: "0"
      RESOLVER_INCLUDE_STUBS: "0"
      RESOLVER_WINDOW_DAYS: ""
      RESOLVER_MAX_PAGES: ""
      RESOLVER_MAX_RESULTS: ""
      RESOLVER_DUCKDB_DISABLE_MERGE: "1"
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Debug repo context
        run: |
          echo "GITHUB_REPOSITORY=$GITHUB_REPOSITORY"
          echo "GITHUB_REF=$GITHUB_REF"
          echo "GITHUB_SHA=$GITHUB_SHA"
          python -c "import pathlib; p = pathlib.Path().resolve(); print('CWD:', p); print('Tree:', len(list(p.glob('**/*'))))"

      - name: Check DB tests present
        id: dbfiles
        shell: bash
        run: |
          set -euo pipefail
          if [ -f "resolver/tests/test_db_parity.py" ] || [ -f "resolver/tests/test_duckdb_idempotency.py" ]; then
            echo "present=true" >> "$GITHUB_OUTPUT"
            echo "Found DB tests."
          else
            echo "present=false" >> "$GITHUB_OUTPUT"
            echo "No DB tests found; will skip DB test steps."
          fi

      - name: "Anti-drift: assert no legacy repo references"
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          part_a="spa"
          part_b="gbot"
          script_path="scripts/ci/assert_no_${part_a}${part_b}_refs.sh"
          chmod +x "$script_path"
          "$script_path"
      - name: Set up Python
        if: steps.dbfiles.outputs.present == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: |
            resolver/requirements.txt
            resolver/requirements-dev.txt
      - name: Confirm Pythia root
        if: steps.dbfiles.outputs.present == 'true'
        run: ls -la && test -f pyproject.toml
      - name: Install dependencies (project + db + tests)
        if: steps.dbfiles.outputs.present == 'true'
        env:
          PIP_NO_CACHE_DIR: "1"
          PIP_DEFAULT_TIMEOUT: "60"
          PIP_INDEX_URL: ${{ secrets.PIP_INDEX_URL }}
          PIP_EXTRA_INDEX_URL: ${{ secrets.PIP_EXTRA_INDEX_URL }}
          HTTP_PROXY: ${{ secrets.HTTP_PROXY }}
          HTTPS_PROXY: ${{ secrets.HTTPS_PROXY }}
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip wheel setuptools
          pip install -e .[db, test]

      - name: Verify DuckDB presence
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          python - <<'PY'
          import importlib.util, sys
          spec = importlib.util.find_spec("duckdb")
          if spec is None:
              print("❌ DuckDB not installed — cannot run DB parity tests.")
              sys.exit(1)
          import duckdb
          print("✅ DuckDB installed:", duckdb.__version__)
          PY
      - name: Show resolver import location & DuckDB version
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          python - <<'PY'
          import sys, pathlib, resolver, duckdb
          print("Python executable:", sys.executable)
          print("resolver module path:", pathlib.Path(resolver.__file__).resolve())
          print("duckdb version:", getattr(duckdb, "__version__", "n/a"))
          PY
      - name: Run ${{ matrix.connector }} (full)
        if: steps.dbfiles.outputs.present == 'true'
        env:
          RESOLVER_FAIL_ON_STUB_ERROR: "0"
        run: |
          python -m resolver.ingestion.run_all_stubs --mode real --only ${{ matrix.connector }} --log-level INFO --log-format json
      - name: Run staging schema tests
        if: steps.dbfiles.outputs.present == 'true'
        run: pytest -q resolver/tests/test_staging_schema_all.py
      - name: Record job status
        if: always()
        env:
          CONNECTOR: ${{ matrix.connector }}
          JOB_STATUS: ${{ job.status }}
        run: |
          python - <<'PY'
          import json
          import os
          from pathlib import Path

          connector = os.environ["CONNECTOR"]
          status = os.environ.get("JOB_STATUS", "unknown")
          log_dir = Path("resolver/logs/ingestion")
          log_dir.mkdir(parents=True, exist_ok=True)
          summary_path = log_dir / f"{connector}-job-status.json"
          summary_path.write_text(json.dumps({"connector": connector, "job_status": status}))
          PY
      - name: Upload nightly artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: nightly-${{ matrix.connector }}
          path: |
            resolver/logs/ingestion/**
            resolver/exports/**
            resolver/staging/**
          retention-days: 7

      - name: Skip DB tests (not present)
        if: steps.dbfiles.outputs.present != 'true'
        run: echo "::notice ::Skipping nightly connectors (DB tests not present in this repo/branch)."

  aggregate:
    if: ${{ github.repository == 'oughtinc/Pythia' && always() && (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch') }}
    needs: full_connectors
    runs-on: ubuntu-latest
    steps:
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: nightly-artifacts
          merge-multiple: true
      - name: Build summary
        run: |
          python - <<'PY'
          import csv
          import json
          from pathlib import Path

          root = Path("nightly-artifacts")
          records = []
          for status_file in root.rglob("*-job-status.json"):
              try:
                  data = json.loads(status_file.read_text())
              except json.JSONDecodeError:
                  continue
              connector = data.get("connector") or status_file.stem.replace("-job-status", "")
              job_status = data.get("job_status", "unknown")
              record = {
                  "connector": connector,
                  "job_status": job_status,
                  "status": "unknown",
                  "attempts": None,
                  "duration_ms": None,
                  "notes": None,
              }
              log_dir = status_file.parent
              for log_file in sorted(log_dir.glob("*")):
                  if not log_file.is_file():
                      continue
                  try:
                      lines = log_file.read_text().splitlines()
                  except Exception:
                      continue
                  for line in lines:
                      line = line.strip()
                      if not line:
                          continue
                      try:
                          payload = json.loads(line)
                      except json.JSONDecodeError:
                          continue
                      if payload.get("event") == "connector_summary":
                          record.update(
                              {
                                  "status": payload.get("status", record["status"]),
                                  "attempts": payload.get("attempts", record["attempts"]),
                                  "duration_ms": payload.get("duration_ms", record["duration_ms"]),
                                  "notes": payload.get("notes", record["notes"]),
                              }
                          )
              records.append(record)
          records.sort(key=lambda item: item["connector"] or "")
          summary_dir = Path("nightly-summary")
          summary_dir.mkdir(exist_ok=True)
          json_path = summary_dir / "summary.json"
          csv_path = summary_dir / "summary.csv"
          json_path.write_text(json.dumps(records, indent=2, sort_keys=True))
          with csv_path.open("w", newline="", encoding="utf-8") as handle:
              writer = csv.DictWriter(handle, fieldnames=["connector", "job_status", "status", "attempts", "duration_ms", "notes"])
              writer.writeheader()
              for row in records:
                  writer.writerow(row)
          PY
      - name: Upload nightly summary
        uses: actions/upload-artifact@v4
        with:
          name: nightly-summary
          path: nightly-summary
          retention-days: 7

  tests-db:
    name: tests (db backend)
    if: ${{ github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' }}
    runs-on: ubuntu-latest
    env:
      RESOLVER_API_BACKEND: db
      RESOLVER_DB_URL: duckdb:///${{ github.workspace }}/.ci-resolver.duckdb
      RESOLVER_LOG_LEVEL: DEBUG
      PYTEST_ADDOPTS: "-vv -ra --maxfail=1 --durations=25 --durations-min=1.0"
      PYTHONDONTWRITEBYTECODE: "1"
      PIP_DISABLE_PIP_VERSION_CHECK: "1"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Derive sanitized artifact suffix
        if: always()
        run: |
          raw="nightly"
          SAFE_SUFFIX="${raw}"
          SAFE_SUFFIX="${SAFE_SUFFIX//\*/_}"
          SAFE_SUFFIX="${SAFE_SUFFIX// /_}"
          SAFE_SUFFIX="$(printf '%s' "${SAFE_SUFFIX}" | tr -c 'A-Za-z0-9_.-' '_')"
          echo "SAFE_SUFFIX=${SAFE_SUFFIX}" >> "$GITHUB_ENV"

      - name: Debug repo context
        run: |
          echo "GITHUB_REPOSITORY=$GITHUB_REPOSITORY"
          echo "GITHUB_REF=$GITHUB_REF"
          echo "GITHUB_SHA=$GITHUB_SHA"
          python -c "import pathlib; p = pathlib.Path().resolve(); print('CWD:', p); print('Tree:', len(list(p.glob('**/*'))))"

      - name: Check DB tests present
        id: dbfiles
        shell: bash
        run: |
          set -euo pipefail
          if [ -f "resolver/tests/test_db_parity.py" ] || [ -f "resolver/tests/test_duckdb_idempotency.py" ]; then
            echo "present=true" >> "$GITHUB_OUTPUT"
            echo "Found DB tests."
          else
            echo "present=false" >> "$GITHUB_OUTPUT"
            echo "No DB tests found; will skip DB test steps."
          fi

      - name: "Anti-drift: assert no legacy repo references"
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          part_a="spa"
          part_b="gbot"
          script_path="scripts/ci/assert_no_${part_a}${part_b}_refs.sh"
          chmod +x "$script_path"
          "$script_path"

      - name: Set up Python
        if: steps.dbfiles.outputs.present == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Confirm Pythia root
        if: steps.dbfiles.outputs.present == 'true'
        run: ls -la && test -f pyproject.toml

      - name: Install (robust, proxy-safe) with fallback
        id: robust_install
        if: steps.dbfiles.outputs.present == 'true'
        env:
          PIP_NO_CACHE_DIR: "1"
          PIP_DEFAULT_TIMEOUT: "60"
          PIP_INDEX_URL: ${{ secrets.PIP_INDEX_URL }}
          PIP_EXTRA_INDEX_URL: ${{ secrets.PIP_EXTRA_INDEX_URL }}
          HTTP_PROXY: ${{ secrets.HTTP_PROXY }}
          HTTPS_PROXY: ${{ secrets.HTTPS_PROXY }}
        run: |
          set -euo pipefail
          echo "Attempt A: editable install with preloaded build tooling and DuckDB wheel"
          python -m pip install -U pip wheel setuptools "poetry-core>=1.9"
          python -m pip install --only-binary=:all: "duckdb==1.1.3" || true
          if python -m pip install -e ".[db]" --no-build-isolation; then
            echo "mode=editable" >>"$GITHUB_OUTPUT"
            exit 0
          fi
          echo "Attempt B: retry editable install after short backoff"
          sleep 5
          if python -m pip install -e ".[db]" --no-build-isolation; then
            echo "mode=editable" >>"$GITHUB_OUTPUT"
            exit 0
          fi
          echo "Editable install failed; falling back to requirements with PYTHONPATH"
          python -m pip install --only-binary=:all: "duckdb==1.1.3" || true
          if [ -f resolver/requirements.txt ]; then python -m pip install -r resolver/requirements.txt || true; fi
          if [ -f resolver/requirements-dev.txt ]; then python -m pip install -r resolver/requirements-dev.txt || true; fi
          if [ -f resolver/requirements-ci.txt ]; then python -m pip install -r resolver/requirements-ci.txt || true; fi
          python -m pip install httpx pytest || true
          echo "mode=fallback" >>"$GITHUB_OUTPUT"
          exit 0

      - name: Ensure test utilities for diagnostics
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          python -m pip install -U pytest pytest-timeout pytest-xdist
          mkdir -p logs

      - name: Verify DuckDB presence
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          python - <<'PY'
          import importlib.util, sys
          spec = importlib.util.find_spec("duckdb")
          if spec is None:
              print("❌ DuckDB not installed — cannot run DB parity tests.")
              sys.exit(1)
          import duckdb
          print("✅ DuckDB installed:", duckdb.__version__)
          PY

      - name: Snapshot environment
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          set -euo pipefail
          mkdir -p logs
          python -V | tee logs/python_version.txt
          python -c "import duckdb,sys;print(getattr(duckdb, '__version__', 'unknown'))" | tee logs/duckdb_version.txt || true
          pytest --version | tee logs/pytest_version.txt
          pip freeze | tee logs/pip_freeze.txt
          python - <<'PY' | tee logs/repo_tree.txt
import pathlib
p = pathlib.Path('.')
print('CWD:', p.resolve())
print('Files:', len(list(p.rglob('*'))))
PY

      - name: Show environment
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          python -V
          python -c "import duckdb,sys;print('duckdb',duckdb.__version__)"
          echo "BACKEND=$RESOLVER_API_BACKEND"
          echo "DB_URL=$RESOLVER_DB_URL"

      - name: Run full test suite (nightly)
        id: run_db_tests
        if: steps.dbfiles.outputs.present == 'true'
        continue-on-error: true
        timeout-minutes: 45
        env:
          INSTALL_MODE: ${{ steps.robust_install.outputs.mode }}
        run: |
          set -euo pipefail
          mkdir -p logs
          echo "Resolved install mode: ${INSTALL_MODE:-unset}"
          if [ "${INSTALL_MODE}" = "fallback" ]; then
            export PYTHONPATH="${PYTHONPATH:-$GITHUB_WORKSPACE}"
            echo "Using fallback install mode; PYTHONPATH=$PYTHONPATH"
          fi

          PYTEST_JUNIT="logs/pytest-nightly.junit.xml"
          PYTEST_LOG="logs/pytest-nightly.log"

          if [ ! -d resolver/tests ]; then
            echo "resolver/tests directory missing; skipping pytest run."
            printf '%s\n' "0" > logs/pytest-exit-code.txt
            echo "exit_code=0" >> "$GITHUB_OUTPUT"
            {
              echo "## Nightly pytest summary"
              echo
              echo "Exit code: 0"
              echo
              echo "_resolver/tests not found; pytest run skipped._"
            } >> "$GITHUB_STEP_SUMMARY"
            exit 0
          fi

          echo "Collecting resolver test inventory"
          python - <<'PY'
import pathlib
root = pathlib.Path("resolver/tests")
if not root.exists():
    print("resolver/tests directory missing; nothing to run")
    raise SystemExit(0)
tests = sorted(str(path) for path in root.rglob("test_*.py"))
print(f"Discovered {len(tests)} test file(s)")
for path in tests:
    print(f" - {path}")
PY

          TEST_RC=0
          set +e
          (pytest resolver/tests \
                  -n auto \
                  --timeout=180 --timeout-method=thread \
                  --junitxml="${PYTEST_JUNIT}" \
            2>&1 | tee "${PYTEST_LOG}")
          TEST_RC=${PIPESTATUS[0]}
          set -e
          printf '%s\n' "${TEST_RC}" > logs/pytest-exit-code.txt
          echo "exit_code=${TEST_RC}" >> "$GITHUB_OUTPUT"

          {
            echo "## Nightly pytest summary"
            echo
            echo "Exit code: ${TEST_RC}"
            echo
            if [ -f "${PYTEST_LOG}" ]; then
              echo "<details><summary>Last 200 lines of log</summary>"
              tail -n 200 "${PYTEST_LOG}" | sed 's/^/    /'
              echo "</details>"
            else
              echo "_Pytest log not found._"
            fi
          } >> "$GITHUB_STEP_SUMMARY"

          exit "${TEST_RC}"

      - name: DB parity/idempotency tests (if present)
        id: run_db_parity
        if: steps.dbfiles.outputs.present == 'true' && hashFiles('resolver/tests/test_db_parity.py','resolver/tests/test_duckdb_idempotency.py') != ''
        continue-on-error: true
        timeout-minutes: 20
        env:
          INSTALL_MODE: ${{ steps.robust_install.outputs.mode }}
        run: |
          set -euo pipefail
          mkdir -p logs
          if [ "${INSTALL_MODE}" = "fallback" ]; then
            export PYTHONPATH="${PYTHONPATH:-$GITHUB_WORKSPACE}"
            echo "Using fallback install mode for DB parity run; PYTHONPATH=$PYTHONPATH"
          fi

          PYTEST_JUNIT="logs/pytest-db.junit.xml"
          DB_LOG="logs/pytest-db.log"
          DB_RC=0
          set +e
          (pytest resolver/tests/test_db_parity.py resolver/tests/test_duckdb_idempotency.py \
                  -n auto \
                  --timeout=120 --timeout-method=thread \
                  --junitxml="${PYTEST_JUNIT}" \
            2>&1 | tee "${DB_LOG}")
          DB_RC=${PIPESTATUS[0]}
          set -e
          printf '%s\n' "${DB_RC}" > logs/pytest-db-exit-code.txt
          echo "exit_code=${DB_RC}" >> "$GITHUB_OUTPUT"

          {
            echo "## DB tests summary"
            echo
            echo "Exit code: ${DB_RC}"
            echo
            if [ -f "${DB_LOG}" ]; then
              echo "<details><summary>Last 200 lines of DB log</summary>"
              tail -n 200 "${DB_LOG}" | sed 's/^/    /'
              echo "</details>"
            else
              echo "_Pytest DB log not found._"
            fi
          } >> "$GITHUB_STEP_SUMMARY"

          exit "${DB_RC}"

      - name: Always upload nightly artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: nightly-artifacts-${{ env.SAFE_SUFFIX || 'nightly' }}-${{ github.job }}-attempt${{ github.run_attempt }}
          if-no-files-found: warn
          retention-days: 14
          path: |
            logs/**
            **/*.junit.xml
            .ci-resolver.duckdb
            resolver/logs/ingestion/**
            resolver/exports/**
            resolver/staging/**
            **/pytest-*.log
            **/parity_mismatch_expected.csv
            **/parity_mismatch_db.csv
            **/parity_mismatch_cell_diffs.csv

      - name: Evaluate pytest outcomes
        if: ${{ steps.dbfiles.outputs.present == 'true' }}
        env:
          MAIN_EXIT: ${{ steps.run_db_tests.outputs.exit_code }}
          DB_EXIT: ${{ steps.run_db_parity.outputs.exit_code }}
        run: |
          python - <<'PY'
import os
import pathlib
import sys
import xml.etree.ElementTree as ET

issues = []

def has_failures(path: pathlib.Path, label: str) -> bool:
    if not path.exists():
        return False
    try:
        tree = ET.parse(path)
    except ET.ParseError as exc:  # pragma: no cover - diagnostics only
        issues.append(f"{label}: unable to parse {path} ({exc})")
        return True
    total = 0
    for suite in tree.iter("testsuite"):
        total += int(suite.attrib.get("failures", "0")) + int(suite.attrib.get("errors", "0"))
    if total:
        issues.append(f"{label}: {total} recorded failure/error cases in {path}")
        return True
    return False

main_exit = (os.environ.get("MAIN_EXIT") or "").strip()
db_exit = (os.environ.get("DB_EXIT") or "").strip()

has_failures(pathlib.Path("logs/pytest-nightly.junit.xml"), "nightly suite")
has_failures(pathlib.Path("logs/pytest-db.junit.xml"), "db parity suite")

if main_exit and main_exit != "0":
    issues.append(f"nightly pytest exited with {main_exit}")
if db_exit and db_exit != "0":
    issues.append(f"db parity pytest exited with {db_exit}")

if issues:
    print("\n".join(issues))
    sys.exit(1)

print("All pytest runs reported success.")
PY

      - name: Skip DB tests (not present)
        if: steps.dbfiles.outputs.present != 'true'
        run: echo "::notice ::Skipping DB tests (files not present in this repo/branch)."
