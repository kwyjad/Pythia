---
name: resolver-ci-nightly

on:
  schedule:
    - cron: "0 23 * * *"
  workflow_dispatch: {}

permissions:
  contents: read

concurrency:
  group: resolver-nightly
  cancel-in-progress: false

jobs:
  full_connectors:
    if: ${{ github.repository == 'oughtinc/Pythia' && (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch') }}
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        connector:
          [reliefweb, ifrc_go, unhcr, unhcr_odp, dtm, who_phe, hdx, acled, emdat, gdacs, ipc, wfp_mvam, worldpop]
    env:
      ACLED_REFRESH_TOKEN: ${{ secrets.ACLED_REFRESH_TOKEN }}
      ACLED_USERNAME: ${{ secrets.ACLED_USERNAME }}
      ACLED_PASSWORD: ${{ secrets.ACLED_PASSWORD }}
      DTM_API_PRIMARY_KEY: ${{ secrets.DTM_API_PRIMARY_KEY }}
      DTM_API_SECONDARY_KEY: ${{ secrets.DTM_API_SECONDARY_KEY }}
      DTM_API_HEADER_NAME: ${{ vars.DTM_API_HEADER_NAME }}
      PYTHONPATH: ${{ github.workspace }}
      RESOLVER_DEBUG: "0"
      RESOLVER_INCLUDE_STUBS: "0"
      RESOLVER_WINDOW_DAYS: ""
      RESOLVER_MAX_PAGES: ""
      RESOLVER_MAX_RESULTS: ""
      RESOLVER_DUCKDB_DISABLE_MERGE: "1"
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Debug repo context
        run: |
          echo "GITHUB_REPOSITORY=$GITHUB_REPOSITORY"
          echo "GITHUB_REF=$GITHUB_REF"
          echo "GITHUB_SHA=$GITHUB_SHA"
          python -c "import pathlib; p = pathlib.Path().resolve(); print('CWD:', p); print('Tree:', len(list(p.glob('**/*'))))"

      - name: Check DB tests present
        id: dbfiles
        shell: bash
        run: |
          set -euo pipefail
          if [ -f "resolver/tests/test_db_parity.py" ] || [ -f "resolver/tests/test_duckdb_idempotency.py" ]; then
            echo "present=true" >> "$GITHUB_OUTPUT"
            echo "Found DB tests."
          else
            echo "present=false" >> "$GITHUB_OUTPUT"
            echo "No DB tests found; will skip DB test steps."
          fi

      - name: "Anti-drift: assert no legacy repo references"
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          part_a="spa"
          part_b="gbot"
          script_path="scripts/ci/assert_no_${part_a}${part_b}_refs.sh"
          chmod +x "$script_path"
          "$script_path"
      - name: Set up Python
        if: steps.dbfiles.outputs.present == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: |
            resolver/requirements.txt
            resolver/requirements-dev.txt
      - name: Confirm Pythia root
        if: steps.dbfiles.outputs.present == 'true'
        run: ls -la && test -f pyproject.toml
      - name: Install dependencies (project + db + tests)
        if: steps.dbfiles.outputs.present == 'true'
        env:
          PIP_NO_CACHE_DIR: "1"
          PIP_DEFAULT_TIMEOUT: "60"
          PIP_INDEX_URL: ${{ secrets.PIP_INDEX_URL }}
          PIP_EXTRA_INDEX_URL: ${{ secrets.PIP_EXTRA_INDEX_URL }}
          HTTP_PROXY: ${{ secrets.HTTP_PROXY }}
          HTTPS_PROXY: ${{ secrets.HTTPS_PROXY }}
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip wheel setuptools
          pip install -e .[db, test]

      - name: Verify DuckDB presence
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          python - <<'PY'
          import importlib.util, sys
          spec = importlib.util.find_spec("duckdb")
          if spec is None:
              print("❌ DuckDB not installed — cannot run DB parity tests.")
              sys.exit(1)
          import duckdb
          print("✅ DuckDB installed:", duckdb.__version__)
          PY
      - name: Show resolver import location & DuckDB version
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          python - <<'PY'
          import sys, pathlib, resolver, duckdb
          print("Python executable:", sys.executable)
          print("resolver module path:", pathlib.Path(resolver.__file__).resolve())
          print("duckdb version:", getattr(duckdb, "__version__", "n/a"))
          PY
      - name: Run ${{ matrix.connector }} (full)
        if: steps.dbfiles.outputs.present == 'true'
        env:
          RESOLVER_FAIL_ON_STUB_ERROR: "0"
        run: |
          python -m resolver.ingestion.run_all_stubs --mode real --only ${{ matrix.connector }} --log-level INFO --log-format json
      - name: Run staging schema tests
        if: steps.dbfiles.outputs.present == 'true'
        run: pytest -q resolver/tests/test_staging_schema_all.py
      - name: Record job status
        if: always()
        env:
          CONNECTOR: ${{ matrix.connector }}
          JOB_STATUS: ${{ job.status }}
        run: |
          python - <<'PY'
          import json
          import os
          from pathlib import Path

          connector = os.environ["CONNECTOR"]
          status = os.environ.get("JOB_STATUS", "unknown")
          log_dir = Path("resolver/logs/ingestion")
          log_dir.mkdir(parents=True, exist_ok=True)
          summary_path = log_dir / f"{connector}-job-status.json"
          summary_path.write_text(json.dumps({"connector": connector, "job_status": status}))
          PY
      - name: Upload nightly artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: nightly-${{ matrix.connector }}
          path: |
            resolver/logs/ingestion/**
            resolver/exports/**
            resolver/staging/**
          retention-days: 7

      - name: Skip DB tests (not present)
        if: steps.dbfiles.outputs.present != 'true'
        run: echo "::notice ::Skipping nightly connectors (DB tests not present in this repo/branch)."

  aggregate:
    if: ${{ github.repository == 'oughtinc/Pythia' && always() && (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch') }}
    needs: full_connectors
    runs-on: ubuntu-latest
    steps:
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: nightly-artifacts
          merge-multiple: true
      - name: Build summary
        run: |
          python - <<'PY'
          import csv
          import json
          from pathlib import Path

          root = Path("nightly-artifacts")
          records = []
          for status_file in root.rglob("*-job-status.json"):
              try:
                  data = json.loads(status_file.read_text())
              except json.JSONDecodeError:
                  continue
              connector = data.get("connector") or status_file.stem.replace("-job-status", "")
              job_status = data.get("job_status", "unknown")
              record = {
                  "connector": connector,
                  "job_status": job_status,
                  "status": "unknown",
                  "attempts": None,
                  "duration_ms": None,
                  "notes": None,
              }
              log_dir = status_file.parent
              for log_file in sorted(log_dir.glob("*")):
                  if not log_file.is_file():
                      continue
                  try:
                      lines = log_file.read_text().splitlines()
                  except Exception:
                      continue
                  for line in lines:
                      line = line.strip()
                      if not line:
                          continue
                      try:
                          payload = json.loads(line)
                      except json.JSONDecodeError:
                          continue
                      if payload.get("event") == "connector_summary":
                          record.update(
                              {
                                  "status": payload.get("status", record["status"]),
                                  "attempts": payload.get("attempts", record["attempts"]),
                                  "duration_ms": payload.get("duration_ms", record["duration_ms"]),
                                  "notes": payload.get("notes", record["notes"]),
                              }
                          )
              records.append(record)
          records.sort(key=lambda item: item["connector"] or "")
          summary_dir = Path("nightly-summary")
          summary_dir.mkdir(exist_ok=True)
          json_path = summary_dir / "summary.json"
          csv_path = summary_dir / "summary.csv"
          json_path.write_text(json.dumps(records, indent=2, sort_keys=True))
          with csv_path.open("w", newline="", encoding="utf-8") as handle:
              writer = csv.DictWriter(handle, fieldnames=["connector", "job_status", "status", "attempts", "duration_ms", "notes"])
              writer.writeheader()
              for row in records:
                  writer.writerow(row)
          PY
      - name: Upload nightly summary
        uses: actions/upload-artifact@v4
        with:
          name: nightly-summary
          path: nightly-summary
          retention-days: 7

  tests-db:
    name: tests (db backend)
    if: ${{ github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' }}
    runs-on: ubuntu-latest
    env:
      RESOLVER_API_BACKEND: db
      RESOLVER_DB_URL: duckdb:///${{ github.workspace }}/.ci-resolver.duckdb
      RESOLVER_LOG_LEVEL: DEBUG
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Derive sanitized artifact suffix
        if: always()
        run: |
          raw="nightly"
          SAFE_SUFFIX="${raw}"
          SAFE_SUFFIX="${SAFE_SUFFIX//\*/_}"
          SAFE_SUFFIX="${SAFE_SUFFIX// /_}"
          SAFE_SUFFIX="$(printf '%s' "${SAFE_SUFFIX}" | tr -c 'A-Za-z0-9_.-' '_')"
          echo "SAFE_SUFFIX=${SAFE_SUFFIX}" >> "$GITHUB_ENV"

      - name: Debug repo context
        run: |
          echo "GITHUB_REPOSITORY=$GITHUB_REPOSITORY"
          echo "GITHUB_REF=$GITHUB_REF"
          echo "GITHUB_SHA=$GITHUB_SHA"
          python -c "import pathlib; p = pathlib.Path().resolve(); print('CWD:', p); print('Tree:', len(list(p.glob('**/*'))))"

      - name: Check DB tests present
        id: dbfiles
        shell: bash
        run: |
          set -euo pipefail
          if [ -f "resolver/tests/test_db_parity.py" ] || [ -f "resolver/tests/test_duckdb_idempotency.py" ]; then
            echo "present=true" >> "$GITHUB_OUTPUT"
            echo "Found DB tests."
          else
            echo "present=false" >> "$GITHUB_OUTPUT"
            echo "No DB tests found; will skip DB test steps."
          fi

      - name: "Anti-drift: assert no legacy repo references"
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          part_a="spa"
          part_b="gbot"
          script_path="scripts/ci/assert_no_${part_a}${part_b}_refs.sh"
          chmod +x "$script_path"
          "$script_path"

      - name: Set up Python
        if: steps.dbfiles.outputs.present == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Confirm Pythia root
        if: steps.dbfiles.outputs.present == 'true'
        run: ls -la && test -f pyproject.toml

      - name: Install (robust, proxy-safe) with fallback
        id: robust_install
        if: steps.dbfiles.outputs.present == 'true'
        env:
          PIP_NO_CACHE_DIR: "1"
          PIP_DEFAULT_TIMEOUT: "60"
          PIP_INDEX_URL: ${{ secrets.PIP_INDEX_URL }}
          PIP_EXTRA_INDEX_URL: ${{ secrets.PIP_EXTRA_INDEX_URL }}
          HTTP_PROXY: ${{ secrets.HTTP_PROXY }}
          HTTPS_PROXY: ${{ secrets.HTTPS_PROXY }}
        run: |
          set -euo pipefail
          echo "Attempt A: editable install with preloaded build tooling and DuckDB wheel"
          python -m pip install -U pip wheel setuptools "poetry-core>=1.9"
          python -m pip install --only-binary=:all: "duckdb==1.1.3" || true
          if python -m pip install -e ".[db]" --no-build-isolation; then
            echo "mode=editable" >>"$GITHUB_OUTPUT"
            exit 0
          fi
          echo "Attempt B: retry editable install after short backoff"
          sleep 5
          if python -m pip install -e ".[db]" --no-build-isolation; then
            echo "mode=editable" >>"$GITHUB_OUTPUT"
            exit 0
          fi
          echo "Editable install failed; falling back to requirements with PYTHONPATH"
          python -m pip install --only-binary=:all: "duckdb==1.1.3" || true
          if [ -f resolver/requirements.txt ]; then python -m pip install -r resolver/requirements.txt || true; fi
          if [ -f resolver/requirements-dev.txt ]; then python -m pip install -r resolver/requirements-dev.txt || true; fi
          if [ -f resolver/requirements-ci.txt ]; then python -m pip install -r resolver/requirements-ci.txt || true; fi
          python -m pip install httpx pytest || true
          echo "mode=fallback" >>"$GITHUB_OUTPUT"
          exit 0

      - name: Verify DuckDB presence
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          python - <<'PY'
          import importlib.util, sys
          spec = importlib.util.find_spec("duckdb")
          if spec is None:
              print("❌ DuckDB not installed — cannot run DB parity tests.")
              sys.exit(1)
          import duckdb
          print("✅ DuckDB installed:", duckdb.__version__)
          PY

      - name: Show environment
        if: steps.dbfiles.outputs.present == 'true'
        run: |
          python -V
          python -c "import duckdb,sys;print('duckdb',duckdb.__version__)"
          echo "BACKEND=$RESOLVER_API_BACKEND"
          echo "DB_URL=$RESOLVER_DB_URL"

      - name: Run DB tests
        id: run_db_tests
        if: steps.dbfiles.outputs.present == 'true'
        continue-on-error: true
        timeout-minutes: 25
        env:
          INSTALL_MODE: ${{ steps.robust_install.outputs.mode }}
          PYTEST_ADDOPTS: "-vv --maxfail=1 -o log_cli=true -o log_cli_level=INFO --durations=25"
        run: |
          set -euo pipefail
          echo "Resolved install mode: ${INSTALL_MODE:-unset}"
          if [ "${INSTALL_MODE}" = "fallback" ]; then
            export PYTHONPATH="${PYTHONPATH:-$GITHUB_WORKSPACE}"
            echo "Using fallback install mode; PYTHONPATH=$PYTHONPATH"
          fi

          echo "Collecting DB-focused tests (resolver/tests)..."
          python - <<'PY'
            from pathlib import Path

            root = Path("resolver/tests")
            if not root.exists():
                print("resolver/tests directory missing")
                raise SystemExit(0)

            patterns = ["test_db_parity.py", "test_duckdb_idempotency.py"]
            tests = []
            for pattern in patterns:
                tests.extend(sorted(str(p) for p in root.rglob(pattern)))

            print(f"Matched {len(tests)} test file(s)")
            for path in tests:
                print(f" - {path}")
          PY

          echo "Pre-test resource snapshot"
          ulimit -a || true
          free -h || true
          df -h || true
          ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%mem | head -n 20 || true

          echo "Running pytest (timeout 20m)"
          set +e
          timeout --preserve-status 20m pytest resolver/tests -k "db_parity or duckdb_idempotency" 2>&1 | tee "pytest-${SAFE_SUFFIX}.log"
          pytest_rc=${PIPESTATUS[0]}
          set -e
          echo "pytest exit code: ${pytest_rc}"
          printf '%s\n' "${pytest_rc}" > pytest_rc.txt

          echo "Post-test resource snapshot"
          ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%mem | head -n 20 || true

          echo "exit_code=${pytest_rc}" >> "$GITHUB_OUTPUT"
          exit "${pytest_rc}"

      - name: Upload DB test logs
        if: always() && steps.dbfiles.outputs.present == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: db-tests-${{ env.SAFE_SUFFIX }}-${{ github.job }}-attempt${{ github.run_attempt }}
          path: |
            pytest-${{ env.SAFE_SUFFIX }}.log
            pytest_rc.txt
            .pytest_cache
            .ci-resolver.duckdb
            resolver/.coverage
          if-no-files-found: warn
          retention-days: 14

      - name: Debug snapshot (always)
        if: always() && steps.dbfiles.outputs.present == 'true'
        run: |
          python -V
          uname -a
          free -h || true
          df -h || true

      - name: Respect DB test result
        if: ${{ always() && steps.dbfiles.outputs.present == 'true' }}
        run: |
          outcome="${{ steps.run_db_tests.outcome }}"
          exit_code="${{ steps.run_db_tests.outputs.exit_code }}"
          if [ -z "${exit_code}" ]; then
            exit_code="unknown"
          fi
          if [ "${outcome}" = "failure" ]; then
            echo "Detected pytest failure (exit code ${exit_code})."
            exit 1
          fi

      - name: Skip DB tests (not present)
        if: steps.dbfiles.outputs.present != 'true'
        run: echo "::notice ::Skipping DB tests (files not present in this repo/branch)."
      - name: Upload DB parity diagnostics
        if: steps.dbfiles.outputs.present == 'true' && steps.run_db_tests.outcome == 'failure'
        uses: actions/upload-artifact@v4
        with:
          name: db-parity-diagnostics-${{ env.SAFE_SUFFIX }}-${{ github.job }}-attempt${{ github.run_attempt }}
          path: |
            **/parity_mismatch_expected.csv
            **/parity_mismatch_db.csv
            **/parity_mismatch_cell_diffs.csv
          if-no-files-found: ignore
          overwrite: true
