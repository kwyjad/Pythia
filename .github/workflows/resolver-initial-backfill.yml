---
name: Resolver â€” Initial Backfill

on:
  workflow_dispatch:
    inputs:
      months_back:
        description: "Number of months to include (default 12)"
        required: false
        default: "12"
      only:
        description: "Optional connector name for --only"
        required: false

env:
  PYTHONUNBUFFERED: "1"
  BACKFILL_DB_PATH: data/resolver_backfill.duckdb
  BACKFILL_INGEST_ARTIFACT: resolver-backfill-ingest-${{ github.run_id }}-${{ github.run_attempt }}
  BACKFILL_SNAPSHOT_ARTIFACT: resolver-backfill-snapshots-${{ github.run_id }}-${{ github.run_attempt }}
  BACKFILL_CONTEXT_ARTIFACT: resolver-backfill-context-${{ github.run_id }}-${{ github.run_attempt }}

jobs:
  ingest:
    name: Ingest connectors
    runs-on: ubuntu-latest
    outputs:
      months: ${{ steps.window.outputs.months }}
      start_iso: ${{ steps.window.outputs.start_iso }}
      end_iso: ${{ steps.window.outputs.end_iso }}
      month_count: ${{ steps.window.outputs.month_count }}
    env:
      RESOLVER_DB_URL: duckdb:///${{ github.workspace }}/data/resolver_backfill.duckdb
      ACLED_REFRESH_TOKEN: ${{ secrets.ACLED_REFRESH_TOKEN }}
      ACLED_USERNAME: ${{ secrets.ACLED_USERNAME }}
      ACLED_PASSWORD: ${{ secrets.ACLED_PASSWORD }}
      DTM_API_PRIMARY_KEY: ${{ secrets.DTM_API_PRIMARY_KEY }}
      DTM_API_SECONDARY_KEY: ${{ secrets.DTM_API_SECONDARY_KEY }}
      RELIEFWEB_APPNAME: ${{ secrets.RELIEFWEB_APPNAME }}
      RELIEFWEB_USER_AGENT: ${{ secrets.RELIEFWEB_USER_AGENT }}
      ONLY_CONNECTOR: ${{ github.event.inputs.only }}
      RESOLVER_OUTPUT_DIR: data/staging
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip wheel setuptools
          pip install -e .[db]

      - name: Compute backfill window
        id: window
        env:
          MONTHS_INPUT: ${{ inputs.months_back || 12 }}
          TIMEZONE: Europe/Istanbul
        run: |
          set -euo pipefail
          python -m scripts.ci.compute_backfill_window

      - name: Run connectors
        env:
          RESOLVER_START_ISO: ${{ steps.window.outputs.start_iso }}
          RESOLVER_END_ISO: ${{ steps.window.outputs.end_iso }}
        run: |
          set -euo pipefail
          mkdir -p "$(dirname "${BACKFILL_DB_PATH}")"
          ARGS=("--mode" "real" "--retries" "2")
          if [ -n "${ONLY_CONNECTOR:-}" ]; then
            ARGS+=("--only" "${ONLY_CONNECTOR}")
          fi
          python resolver/ingestion/run_all_stubs.py "${ARGS[@]}"

      - name: Prepare diagnostics dir
        run: mkdir -p diagnostics/ingestion

      - name: Summarize connector diagnostics
        if: always()
        run: |
          set -euo pipefail
          python -m scripts.ci.summarize_connectors \
            --report diagnostics/ingestion/connectors_report.jsonl \
            --out diagnostics/ingestion/summary.md \
            --github-step-summary

      - name: Upload connector diagnostics
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: connector-diagnostics
          path: |
            diagnostics/ingestion/summary.md
            diagnostics/ingestion/connectors_report.jsonl
          retention-days: 30

      - name: Upload ingestion outputs
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.BACKFILL_INGEST_ARTIFACT }}
          if-no-files-found: warn
          path: |
            data/
            resolver/staging/
            resolver/logs/ingestion/

  derive-freeze:
    name: Derive & freeze snapshots
    runs-on: ubuntu-latest
    needs: ingest
    env:
      RESOLVER_DB_URL: duckdb:///${{ github.workspace }}/data/resolver_backfill.duckdb
      BACKFILL_MONTHS_CSV: ${{ needs.ingest.outputs.months }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip wheel setuptools
          pip install -e .[db]

      - name: Download ingestion bundle
        uses: actions/download-artifact@v4
        with:
          name: ${{ env.BACKFILL_INGEST_ARTIFACT }}
          path: .

      - name: Export canonical facts
        run: |
          set -euo pipefail
          mkdir -p resolver/exports/backfill
          python -m resolver.tools.export_facts \
            --in resolver/staging \
            --out resolver/exports/backfill \
            --config resolver/tools/export_config.yml

      - name: Derive and freeze monthly snapshots
        env:
          MONTHS: ${{ env.BACKFILL_MONTHS_CSV }}
        run: |
          set -euo pipefail
          python - <<'PY'
          import calendar
          import os
          import subprocess
          import sys
          from pathlib import Path

          import pandas as pd

          months_env = os.environ.get("MONTHS", "")
          months = [m.strip() for m in months_env.split(",") if m.strip()]
          base_csv = Path("resolver/exports/backfill/facts.csv")
          if not base_csv.exists():
              raise SystemExit(f"facts.csv missing at {base_csv}")

          backfill_db = os.environ.get("BACKFILL_DB_PATH", "data/resolver_backfill.duckdb")
          for ym in months:
              print(f"::group::Deriving {ym}")
              month_dir = Path("resolver/exports/backfill") / ym
              month_dir.mkdir(parents=True, exist_ok=True)

              df = pd.read_csv(base_csv)
              if "as_of_date" in df.columns:
                  df["as_of_date"] = pd.to_datetime(df["as_of_date"], errors="coerce")
                  df = df[df["as_of_date"].dt.strftime("%Y-%m") == ym]
              elif "ym" in df.columns:
                  df = df[df["ym"].astype(str) == ym]

              if df.empty:
                  df = df.head(0)
                  df.to_csv(month_dir / "facts.csv", index=False)
                  df.to_parquet(month_dir / "facts.parquet", index=False)
                  print(f"No facts rows for {ym}; skipping snapshot")
                  print("::endgroup::")
                  continue

              df.to_csv(month_dir / "facts.csv", index=False)
              df.to_parquet(month_dir / "facts.parquet", index=False)

              year, month = map(int, ym.split("-"))
              last_day = calendar.monthrange(year, month)[1]
              cutoff = f"{year:04d}-{month:02d}-{last_day:02d}"

              subprocess.run(
                  [
                      sys.executable,
                      "-m",
                      "resolver.tools.precedence_engine",
                      "--facts",
                      str(month_dir / "facts.csv"),
                      "--cutoff",
                      cutoff,
                      "--outdir",
                      str(month_dir),
                  ],
                  check=True,
              )

              resolved_csv = month_dir / "resolved.csv"
              if not resolved_csv.exists():
                  print(f"resolved.csv missing for {ym}; skipping")
                  print("::endgroup::")
                  continue

              subprocess.run(
                  [
                      sys.executable,
                      "-m",
                      "resolver.tools.make_deltas",
                      "--resolved",
                      str(resolved_csv),
                      "--out",
                      str(month_dir / "deltas.csv"),
                  ],
                  check=True,
              )

              subprocess.run(
                  [
                      sys.executable,
                      "-m",
                      "resolver.tools.freeze_snapshot",
                      "--facts",
                      str(month_dir / "facts.csv"),
                      "--deltas",
                      str(month_dir / "deltas.csv"),
                      "--resolved",
                      str(resolved_csv),
                      "--month",
                      ym,
                      "--outdir",
                      "resolver/snapshots",
                      "--write-db",
                      "1",
                      "--db-url",
                      f"duckdb:///{backfill_db}",
                  ],
                  check=True,
              )

              print("::endgroup::")
          PY

      - name: Upload snapshots and database
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.BACKFILL_SNAPSHOT_ARTIFACT }}
          if-no-files-found: warn
          path: |
            resolver/snapshots/
            resolver/exports/backfill/
            ${{ env.BACKFILL_DB_PATH }}

  context:
    name: Build LLM context bundle
    runs-on: ubuntu-latest
    needs:
      - ingest
      - derive-freeze
    env:
      RESOLVER_DB_URL: duckdb:///${{ github.workspace }}/data/resolver_backfill.duckdb
      CONTEXT_MONTHS: ${{ needs.ingest.outputs.month_count }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip wheel setuptools
          pip install -e .[db]

      - name: Download snapshots bundle
        uses: actions/download-artifact@v4
        with:
          name: ${{ env.BACKFILL_SNAPSHOT_ARTIFACT }}
          path: .

      - name: Build context bundle
        run: |
          set -euo pipefail
          mkdir -p context
          python -m resolver.tools.build_llm_context --months "${CONTEXT_MONTHS:-12}" --outdir context

      - name: Upload context artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.BACKFILL_CONTEXT_ARTIFACT }}
          if-no-files-found: warn
          path: context/

  artifacts:
    name: Publish combined artifacts
    runs-on: ubuntu-latest
    needs:
      - derive-freeze
      - context
    steps:
      - name: Download snapshots
        uses: actions/download-artifact@v4
        with:
          name: ${{ env.BACKFILL_SNAPSHOT_ARTIFACT }}
          path: .

      - name: Download context bundle
        uses: actions/download-artifact@v4
        with:
          name: ${{ env.BACKFILL_CONTEXT_ARTIFACT }}
          path: .

      - name: Upload combined bundle
        uses: actions/upload-artifact@v4
        with:
          name: resolver-initial-backfill-${{ github.run_id }}-${{ github.run_attempt }}
          if-no-files-found: error
          path: |
            resolver/snapshots/
            context/
            ${{ env.BACKFILL_DB_PATH }}
