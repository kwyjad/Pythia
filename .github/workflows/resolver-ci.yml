name: resolver-ci

on:
  push:
    branches:
      - "**"
    paths:
      - "resolver/**"
      - ".github/workflows/**"
      - "!Dashboard/**"
  pull_request:
    paths:
      - "resolver/**"
      - ".github/workflows/**"
      - "!Dashboard/**"
  schedule:
    - cron: "17 2 * * *"
  workflow_dispatch: {}

permissions:
  contents: read

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  offline_connector_smoke:
    name: offline-connector-smoke (duckdb=${{ matrix.duckdb_label }})
    strategy:
      fail-fast: false
      matrix:
        include:
          - duckdb_spec: "duckdb==0.10.*"
            duckdb_label: "0_10_x"
          - duckdb_spec: "duckdb"
            duckdb_label: "latest"
    runs-on: ubuntu-latest
    env:
      RESOLVER_DB_URL: duckdb:///${{ runner.temp }}/ci-offline-connector-${{ matrix.duckdb_label }}.duckdb
      RESOLVER_DUCKDB_DISABLE_MERGE: "1"
      RESOLVER_DIAG: ${{ contains(matrix.duckdb_label, '0_10') && '1' || '0' }}
    timeout-minutes: 15
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Show commit context
        run: |
          echo "GITHUB_SHA=${GITHUB_SHA}"
          echo "PR_HEAD_SHA=${{ github.event.pull_request.head.sha || '' }}"
          git rev-parse HEAD
          git show -s --date=iso --format='%H %cd %s'

      - name: "Anti-drift: assert no legacy repo references"
        run: |
          part_a="spa"
          part_b="gbot"
          script_path="scripts/ci/assert_no_${part_a}${part_b}_refs.sh"
          chmod +x "$script_path"
          "$script_path"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: |
            resolver/requirements.txt
            resolver/requirements-dev.txt

      - name: Install project in editable mode
        run: |
          python -m pip install --upgrade pip wheel setuptools
          pip uninstall -y resolver || true
          pip install -e .[db,test]
          python -m pip install "${{ matrix.duckdb_spec }}"

      - name: Print resolver & DuckDB stamps
        run: |
          git rev-parse HEAD
          python - <<'PY'
          import hashlib, inspect, pathlib, sys
          import duckdb, resolver
          import resolver.db.duckdb_io as duckdb_io

          print("Python executable:", sys.executable)
          print("Python version:", sys.version)
          resolver_path = pathlib.Path(resolver.__file__).resolve()
          duckdb_io_path = pathlib.Path(inspect.getfile(duckdb_io)).resolve()
          print("resolver module path:", resolver_path)
          print("duckdb_io.py path:", duckdb_io_path)
          print("duckdb_io.py sha256:", hashlib.sha256(duckdb_io_path.read_bytes()).hexdigest())
          print("duckdb version:", getattr(duckdb, "__version__", "unknown"))
          PY

      - name: Run offline connector smoke tests
        id: run_offline_smoke
        run: |
          set -o pipefail
          pytest -q \
            resolver/tests/test_ingestion_smoke_all_connectors.py \
            resolver/tests/ingestion/test_reliefweb_pdf.py \
            --junitxml=pytest-junit.xml 2>&1 | tee pytest-stdout.txt
          status=${PIPESTATUS[0]}
          echo "PYTEST_EXIT_CODE=${status}" >> "$GITHUB_ENV"
          exit 0

      - name: Docs Link Check (non-blocking)
        continue-on-error: true
        run: |
          python - <<'PY'
          import pathlib
          import re
          import sys

          root = pathlib.Path('.').resolve()
          md_files = [p for p in root.glob('resolver/**/*.md')]
          pattern = re.compile(r'\[[^\]]+\]\(([^)]+)\)')
          broken = []

          for md in md_files:
              text = md.read_text(encoding='utf-8')
              for match in pattern.finditer(text):
                  link = match.group(1)
                  if link.startswith(('http://', 'https://', 'mailto:')):
                      continue
                  if link.startswith('#') or link.startswith('?'):
                      continue
                  target_str = link.split('#', 1)[0]
                  target_path = (md.parent / target_str).resolve()
                  if not target_path.exists():
                      broken.append(f"{md.relative_to(root)} -> {link}")

          if broken:
              print('Broken Markdown links found:')
              for item in broken:
                  print(f" - {item}")
              sys.exit(1)
          else:
              print('No broken intra-repo Markdown links found.')
          PY

      - name: Build diagnostics bundle (per-job)
        if: always()
        run: |
          python -m resolver.tools.ci_diag_bundle \
            --suite "${{ github.job }}" \
            --duckdb-version "$(python -c "import duckdb; print(getattr(duckdb,'__version__','unknown'))")" \
            --db-url "${{ env.RESOLVER_DB_URL }}" \
            --scan-path "${{ github.workspace }}" \
            --scan-path "${{ runner.temp }}" \
            --scan-path "/tmp/pytest-of-runner" \
            --scan-path "/tmp" \
            --pytest-stdout pytest-stdout.txt \
            --out "diagnostics.${{ matrix.duckdb_label }}.zip"

      - name: Upload diagnostics (per-job)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ github.job }}-part-${{ matrix.duckdb_label }}-${{ github.run_id }}-${{ github.run_attempt }}
          path: diagnostics.${{ matrix.duckdb_label }}.zip
          overwrite: true

      - name: Fail if tests failed
        if: ${{ env.PYTEST_EXIT_CODE != '0' }}
        run: exit ${{ env.PYTEST_EXIT_CODE }}
  db_backend:
    name: tests (db backend, duckdb=${{ matrix.duckdb_label }})
    if: ${{ github.event_name == 'pull_request' || github.event_name == 'push' || github.event_name == 'workflow_dispatch' || github.event_name == 'schedule' }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - duckdb_spec: "duckdb==0.10.*"
            duckdb_label: "0_10_x"
          - duckdb_spec: "duckdb"
            duckdb_label: "latest"
    runs-on: ubuntu-latest
    env:
      RESOLVER_API_BACKEND: db
      RESOLVER_DB_URL: duckdb:///${{ runner.temp }}/ci-db-backend-${{ matrix.duckdb_label }}.duckdb
      RESOLVER_LOG_LEVEL: DEBUG
      RESOLVER_DUCKDB_DISABLE_MERGE: "1"
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Show commit context
        run: |
          echo "GITHUB_SHA=${GITHUB_SHA}"
          echo "PR_HEAD_SHA=${{ github.event.pull_request.head.sha || '' }}"
          git rev-parse HEAD
          git show -s --date=iso --format='%H %cd %s'

      - name: "Anti-drift: assert no legacy repo references"
        run: |
          part_a="spa"
          part_b="gbot"
          script_path="scripts/ci/assert_no_${part_a}${part_b}_refs.sh"
          chmod +x "$script_path"
          "$script_path"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install project in editable mode
        env:
          PIP_NO_CACHE_DIR: "1"
          PIP_DEFAULT_TIMEOUT: "60"
          PIP_INDEX_URL: ${{ secrets.PIP_INDEX_URL }}
          PIP_EXTRA_INDEX_URL: ${{ secrets.PIP_EXTRA_INDEX_URL }}
          HTTP_PROXY: ${{ secrets.HTTP_PROXY }}
          HTTPS_PROXY: ${{ secrets.HTTPS_PROXY }}
        run: |
          python -m pip install --upgrade pip wheel setuptools
          pip uninstall -y resolver || true
          pip install -e .[db,test]
          python -m pip install "${{ matrix.duckdb_spec }}"

      - name: Print resolver & DuckDB stamps
        run: |
          git rev-parse HEAD
          echo "DB_URL=$RESOLVER_DB_URL"
          python - <<'PY'
          import hashlib, inspect, pathlib, sys
          import duckdb, resolver
          import resolver.db.duckdb_io as duckdb_io

          print("Python executable:", sys.executable)
          print("Python version:", sys.version)
          resolver_path = pathlib.Path(resolver.__file__).resolve()
          duckdb_io_path = pathlib.Path(inspect.getfile(duckdb_io)).resolve()
          print("resolver module path:", resolver_path)
          print("duckdb_io.py path:", duckdb_io_path)
          print("duckdb_io.py sha256:", hashlib.sha256(duckdb_io_path.read_bytes()).hexdigest())
          print("duckdb version:", getattr(duckdb, "__version__", "unknown"))
          PY

      - name: Run database-backed tests
        id: run_db_tests
        run: |
          set -o pipefail
          python -m pytest -q resolver/tests \
            --maxfail=1 --disable-warnings --junitxml=pytest-junit.xml 2>&1 | tee pytest-stdout.txt
          status=${PIPESTATUS[0]}
          echo "PYTEST_EXIT_CODE=${status}" >> "$GITHUB_ENV"
          exit 0

      - name: Build diagnostics bundle (per-job)
        if: always()
        run: |
          python -m resolver.tools.ci_diag_bundle \
            --suite "${{ github.job }}" \
            --duckdb-version "$(python -c "import duckdb; print(getattr(duckdb,'__version__','unknown'))")" \
            --db-url "${{ env.RESOLVER_DB_URL }}" \
            --scan-path "${{ github.workspace }}" \
            --scan-path "${{ runner.temp }}" \
            --scan-path "/tmp/pytest-of-runner" \
            --scan-path "/tmp" \
            --pytest-stdout pytest-stdout.txt \
            --out "diagnostics.${{ matrix.duckdb_label }}.zip"

      - name: Upload diagnostics (per-job)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ github.job }}-part-${{ matrix.duckdb_label }}-${{ github.run_id }}-${{ github.run_attempt }}
          path: diagnostics.${{ matrix.duckdb_label }}.zip
          overwrite: true

      - name: Fail if tests failed
        if: ${{ env.PYTEST_EXIT_CODE != '0' }}
        run: exit ${{ env.PYTEST_EXIT_CODE }}

  db_backend_nocache:
    name: tests (db backend, cache disabled, duckdb=${{ matrix.duckdb_label }})
    if: ${{ github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' }}
    needs: db_backend
    strategy:
      fail-fast: false
      matrix:
        include:
          - duckdb_spec: "duckdb==0.10.*"
            duckdb_label: "0_10_x"
          - duckdb_spec: "duckdb"
            duckdb_label: "latest"
    runs-on: ubuntu-latest
    env:
      RESOLVER_API_BACKEND: db
      RESOLVER_DB_URL: duckdb:///${{ runner.temp }}/ci-db-backend-nocache-${{ matrix.duckdb_label }}.duckdb
      RESOLVER_LOG_LEVEL: DEBUG
      RESOLVER_DUCKDB_DISABLE_MERGE: "1"
      RESOLVER_DISABLE_CONN_CACHE: "1"
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Show commit context
        run: |
          echo "GITHUB_SHA=${GITHUB_SHA}"
          echo "PR_HEAD_SHA=${{ github.event.pull_request.head.sha || '' }}"
          git rev-parse HEAD
          git show -s --date=iso --format='%H %cd %s'

      - name: "Anti-drift: assert no legacy repo references"
        run: |
          part_a="spa"
          part_b="gbot"
          script_path="scripts/ci/assert_no_${part_a}${part_b}_refs.sh"
          chmod +x "$script_path"
          "$script_path"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install project in editable mode
        env:
          PIP_NO_CACHE_DIR: "1"
          PIP_DEFAULT_TIMEOUT: "60"
          PIP_INDEX_URL: ${{ secrets.PIP_INDEX_URL }}
          PIP_EXTRA_INDEX_URL: ${{ secrets.PIP_EXTRA_INDEX_URL }}
          HTTP_PROXY: ${{ secrets.HTTP_PROXY }}
          HTTPS_PROXY: ${{ secrets.HTTPS_PROXY }}
        run: |
          python -m pip install --upgrade pip wheel setuptools
          pip uninstall -y resolver || true
          pip install -e .[db,test]
          python -m pip install "${{ matrix.duckdb_spec }}"

      - name: Print resolver & DuckDB stamps
        run: |
          git rev-parse HEAD
          echo "DB_URL=$RESOLVER_DB_URL"
          echo "CACHE_DISABLED=$RESOLVER_DISABLE_CONN_CACHE"
          python - <<'PY'
          import hashlib, inspect, pathlib, sys
          import duckdb, resolver
          import resolver.db.duckdb_io as duckdb_io

          print("Python executable:", sys.executable)
          print("Python version:", sys.version)
          resolver_path = pathlib.Path(resolver.__file__).resolve()
          duckdb_io_path = pathlib.Path(inspect.getfile(duckdb_io)).resolve()
          print("resolver module path:", resolver_path)
          print("duckdb_io.py path:", duckdb_io_path)
          print("duckdb_io.py sha256:", hashlib.sha256(duckdb_io_path.read_bytes()).hexdigest())
          print("duckdb version:", getattr(duckdb, "__version__", "unknown"))
          PY

      - name: Run database-backed tests (cache disabled)
        id: run_db_tests_nocache
        run: |
          set -o pipefail
          python -m pytest -q resolver/tests \
            --maxfail=1 --disable-warnings --junitxml=pytest-junit.xml 2>&1 | tee pytest-stdout.txt
          status=${PIPESTATUS[0]}
          echo "PYTEST_EXIT_CODE=${status}" >> "$GITHUB_ENV"
          exit 0

      - name: Build diagnostics bundle (per-job)
        if: always()
        run: |
          python -m resolver.tools.ci_diag_bundle \
            --suite "${{ github.job }}" \
            --duckdb-version "$(python -c "import duckdb; print(getattr(duckdb,'__version__','unknown'))")" \
            --db-url "${{ env.RESOLVER_DB_URL }}" \
            --scan-path "${{ github.workspace }}" \
            --scan-path "${{ runner.temp }}" \
            --scan-path "/tmp/pytest-of-runner" \
            --scan-path "/tmp" \
            --pytest-stdout pytest-stdout.txt \
            --out "diagnostics.${{ matrix.duckdb_label }}.zip"

      - name: Upload diagnostics (per-job)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ github.job }}-part-${{ matrix.duckdb_label }}-${{ github.run_id }}-${{ github.run_attempt }}
          path: diagnostics.${{ matrix.duckdb_label }}.zip
          overwrite: true

      - name: Fail if tests failed
        if: ${{ env.PYTEST_EXIT_CODE != '0' }}
        run: exit ${{ env.PYTEST_EXIT_CODE }}

  ci_aggregate:
    name: CI aggregate (fast-tests + db-backend)
    needs:
      - offline_connector_smoke
      - db_backend
      - db_backend_nocache
    if: ${{ always() }}
    runs-on: ubuntu-latest
    steps:
      - name: Download in-workflow artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: "*-part-*"
          merge-multiple: true
          if-no-artifact: ignore
          path: downloads

      - name: Fetch fast-tests artifacts from resolver-ci-fast
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          python - <<'PY'
          import io
          import json
          import os
          import pathlib
          import time
          import urllib.error
          import urllib.request
          import zipfile

          repo = os.environ.get("GITHUB_REPOSITORY")
          sha = os.environ.get("GITHUB_SHA")
          workflow = "resolver-ci-fast.yml"
          token = os.environ.get("GH_TOKEN")
          downloads = pathlib.Path("downloads/fast-workflow")
          downloads.mkdir(parents=True, exist_ok=True)

          if not (repo and sha and token):
              raise SystemExit(0)

          def api(url: str) -> dict:
              req = urllib.request.Request(
                  url,
                  headers={
                      "Authorization": f"Bearer {token}",
                      "Accept": "application/vnd.github+json",
                  },
              )
              try:
                  with urllib.request.urlopen(req) as resp:
                      return json.loads(resp.read().decode("utf-8"))
              except urllib.error.HTTPError:
                  return {}

          run_id = None
          for attempt in range(10):
              data = api(f"https://api.github.com/repos/{repo}/actions/workflows/{workflow}/runs?per_page=20")
              candidates = [run for run in data.get("workflow_runs", []) if run.get("head_sha") == sha]
              if candidates:
                  run = candidates[0]
                  status = run.get("status")
                  if status != "completed":
                      time.sleep(30)
                      continue
                  run_id = run.get("id")
                  break
              time.sleep(15)

          if not run_id:
              raise SystemExit(0)

          artifacts = api(f"https://api.github.com/repos/{repo}/actions/runs/{run_id}/artifacts?per_page=100")
          for artifact in artifacts.get("artifacts", []):
              name = artifact.get("name", "")
              if not name.startswith("fast-tests-part-"):
                  continue
              if artifact.get("expired"):
                  continue
              url = artifact.get("archive_download_url")
              if not url:
                  continue
              req = urllib.request.Request(
                  url,
                  headers={
                      "Authorization": f"Bearer {token}",
                      "Accept": "application/vnd.github+zip",
                  },
              )
              try:
                  with urllib.request.urlopen(req) as resp:
                      payload = resp.read()
              except urllib.error.URLError:
                  continue

              with zipfile.ZipFile(io.BytesIO(payload)) as bundle:
                  for member in bundle.infolist():
                      target = downloads / member.filename
                      target.parent.mkdir(parents=True, exist_ok=True)
                      with bundle.open(member) as src, open(target, "wb") as dst:
                          dst.write(src.read())
          PY

      - name: Create consolidated bundle and SUMMARY.md
        run: |
          python - <<'PY'
          import os
          import pathlib
          import zipfile

          downloads = pathlib.Path('downloads')
          zip_paths = sorted(downloads.rglob('*.zip'))
          run_id = os.environ.get('GITHUB_RUN_ID', 'unknown')
          run_attempt = os.environ.get('GITHUB_RUN_ATTEMPT', 'unknown')
          out_path = pathlib.Path(f'diagnostics-consolidated-{run_id}-{run_attempt}.zip')

          summary_chunks = [
              '# Resolver â€” Consolidated SUMMARY',
              '',
              f'Run: {run_id} attempt {run_attempt}',
          ]

          if not zip_paths:
              summary_chunks.append('')
              summary_chunks.append('(No diagnostics artifacts were found.)')
          else:
              summary_chunks.append('')
              summary_chunks.append('Collected parts:')
              for path in zip_paths:
                  summary_chunks.append(f'- {path.relative_to(downloads)}')

          with zipfile.ZipFile(out_path, 'w', zipfile.ZIP_DEFLATED) as archive:
              for path in zip_paths:
                  rel = path.relative_to(downloads)
                  archive.write(path, f'parts/{rel.as_posix()}')
                  try:
                      with zipfile.ZipFile(path, 'r') as part_zip:
                          if 'diagnostics/SUMMARY.md' in part_zip.namelist():
                              text = part_zip.read('diagnostics/SUMMARY.md').decode('utf-8', 'ignore').strip()
                              summary_chunks.append('\n---\n')
                              summary_chunks.append(f'# From: {path.name}')
                              summary_chunks.append('')
                              summary_chunks.append(text)
                  except zipfile.BadZipFile:
                      summary_chunks.append('\n---\n')
                      summary_chunks.append(f'# From: {path.name}')
                      summary_chunks.append('')
                      summary_chunks.append('(corrupt zip file)')

              archive.writestr('SUMMARY.md', '\n'.join(summary_chunks) + '\n')

          print(f'Wrote {out_path}')
          PY

      - name: Upload consolidated diagnostics
        uses: actions/upload-artifact@v4
        with:
          name: diagnostics-consolidated-${{ github.run_id }}-${{ github.run_attempt }}
          path: diagnostics-consolidated-${{ github.run_id }}-${{ github.run_attempt }}.zip
          overwrite: true

